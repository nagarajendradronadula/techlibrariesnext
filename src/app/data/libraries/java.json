[
    {
      "id": "spring-boot",
      "name": "Spring Boot",
      "category": "Web",
      "description": "Spring Boot is a framework for building production-ready Java applications quickly. It simplifies configuration, provides embedded servers, and integrates easily with Spring ecosystem projects like Spring Data, Spring Security, and Spring MVC.",
      "story": "Spring Boot was created by Pivotal (now VMware) to simplify Spring application setup and development. Its goal was to reduce boilerplate code, provide sensible defaults, and enable rapid development of standalone, production-grade applications with minimal configuration.",
      "installation": {
        "maven": "Add Spring Boot starter dependencies in your pom.xml",
        "gradle": "Add Spring Boot starter dependencies in your build.gradle"
      },
      "usage": {
        "overview": "Spring Boot allows developers to quickly create REST APIs, web applications, and microservices. It provides auto-configuration, embedded servers, and ready-to-use starters for common functionalities like data access, security, and messaging.",
        "basic_examples": [
          {
            "title": "Creating a Spring Boot application",
            "code": "// MainApplication.java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class MainApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(MainApplication.class, args);\n    }\n}",
            "explanation": "This is the entry point of a Spring Boot application. The `@SpringBootApplication` annotation enables auto-configuration and component scanning."
          },
          {
            "title": "Simple REST Controller",
            "code": "// HelloController.java\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class HelloController {\n\n    @GetMapping(\"/hello\")\n    public String sayHello() {\n        return \"Hello, Spring Boot!\";\n    }\n}",
            "explanation": "Defines a REST endpoint `/hello` that returns a simple greeting string."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Spring Data JPA",
            "code": "// User.java\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.Id;\n\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    private String name;\n    // getters and setters\n}\n\n// UserRepository.java\nimport org.springframework.data.jpa.repository.JpaRepository;\npublic interface UserRepository extends JpaRepository<User, Long> {}",
            "explanation": "Demonstrates creating an entity and repository using Spring Data JPA for database operations."
          },
          {
            "title": "Exception Handling with @ControllerAdvice",
            "code": "import org.springframework.web.bind.annotation.ControllerAdvice;\nimport org.springframework.web.bind.annotation.ExceptionHandler;\nimport org.springframework.http.ResponseEntity;\n\n@ControllerAdvice\npublic class GlobalExceptionHandler {\n\n    @ExceptionHandler(Exception.class)\n    public ResponseEntity<String> handleException(Exception e) {\n        return ResponseEntity.status(500).body(\"Error: \" + e.getMessage());\n    }\n}",
            "explanation": "Provides centralized exception handling for all controllers using `@ControllerAdvice`."
          },
          {
            "title": "Using application.properties",
            "code": "# application.properties\nserver.port=8081\nspring.datasource.url=jdbc:mysql://localhost:3306/testdb\nspring.datasource.username=root\nspring.datasource.password=pass",
            "explanation": "Configuration properties for server port and database connection."
          }
        ],
        "best_practices": [
          "Use Spring Boot starters to avoid boilerplate dependency configurations.",
          "Leverage `@Configuration` and `@Bean` for custom configurations.",
          "Externalize configurations using `application.properties` or `application.yml`.",
          "Write unit and integration tests using Spring Boot Test utilities.",
          "Use profiles (`@Profile`) for environment-specific configurations."
        ],
        "error_handling": [
          {
            "error": "ApplicationContextException",
            "solution": "Occurs when Spring context fails to start. Check bean definitions and dependency injections."
          },
          {
            "error": "DataAccessException",
            "solution": "Occurs during database operations. Ensure correct configuration and valid queries."
          },
          {
            "error": "HttpMessageNotReadableException",
            "solution": "Occurs when JSON request body cannot be parsed. Validate input and request payload."
          }
        ]
      },
      "references": {
        "official_docs": "https://spring.io/projects/spring-boot",
        "github": "https://github.com/spring-projects/spring-boot"
      }
    },
    {
      "id": "spring-security",
      "name": "Spring Security",
      "category": "Security",
      "description": "Spring Security is a powerful and highly customizable framework for authentication, authorization, and protection against common security threats in Java applications.",
      "story": "Spring Security was created to provide a comprehensive security solution for Java applications, seamlessly integrating with the Spring ecosystem. It supports features like authentication, authorization, password encoding, CSRF protection, session management, and more.",
      "installation": {
        "maven": "Add spring-boot-starter-security dependency in pom.xml",
        "gradle": "Add implementation 'org.springframework.boot:spring-boot-starter-security' in build.gradle"
      },
      "usage": {
        "overview": "Spring Security allows developers to secure web applications and APIs by managing authentication and authorization. It provides out-of-the-box security filters, supports custom user services, and integrates with OAuth2, JWT, LDAP, and more.",
        "basic_examples": [
          {
            "title": "Securing all endpoints with HTTP Basic",
            "code": "// SecurityConfig.java\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\n\n@Configuration\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n            .authorizeRequests()\n            .anyRequest().authenticated()\n            .and()\n            .httpBasic();\n    }\n}",
            "explanation": "This configuration secures all endpoints and uses HTTP Basic authentication."
          },
          {
            "title": "Creating an in-memory user",
            "code": "// SecurityConfig.java snippet\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\n\n@Override\nprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\n    auth.inMemoryAuthentication()\n        .withUser(\"user\")\n        .password(\"{noop}password\") // {noop} for plain text\n        .roles(\"USER\");\n}",
            "explanation": "Defines a simple in-memory user with username, password, and role."
          }
        ],
        "advanced_examples": [
          {
            "title": "Securing endpoints with roles",
            "code": "// SecurityConfig.java snippet\nhttp.authorizeRequests()\n    .antMatchers(\"/admin/**\").hasRole(\"ADMIN\")\n    .antMatchers(\"/user/**\").hasAnyRole(\"USER\",\"ADMIN\")\n    .anyRequest().authenticated();",
            "explanation": "Restricts access to specific endpoints based on user roles."
          },
          {
            "title": "Using JWT for stateless authentication",
            "code": "// JWTFilter.java snippet\npublic class JWTFilter extends OncePerRequestFilter {\n    @Override\n    protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) {\n        String token = extractToken(request);\n        // validate and set authentication\n        filterChain.doFilter(request, response);\n    }\n}",
            "explanation": "Illustrates a custom filter to authenticate requests using JWT tokens."
          },
          {
            "title": "Custom UserDetailsService",
            "code": "import org.springframework.security.core.userdetails.UserDetailsService;\nimport org.springframework.security.core.userdetails.UserDetails;\n\n@Service\npublic class CustomUserDetailsService implements UserDetailsService {\n    @Override\n    public UserDetails loadUserByUsername(String username) {\n        // fetch user from DB and return UserDetails object\n    }\n}",
            "explanation": "Allows authentication against a database or external source by implementing `UserDetailsService`."
          }
        ],
        "best_practices": [
          "Never store plain-text passwords; use encoders like BCryptPasswordEncoder.",
          "Use method-level security annotations (`@PreAuthorize`, `@Secured`) for fine-grained control.",
          "Externalize security configurations using properties or profiles.",
          "Monitor failed login attempts and implement account lockout policies.",
          "Leverage OAuth2 or JWT for stateless authentication in APIs."
        ],
        "error_handling": [
          {
            "error": "AccessDeniedException",
            "solution": "Occurs when a user tries to access a resource without sufficient permissions. Check roles and authorities."
          },
          {
            "error": "BadCredentialsException",
            "solution": "Thrown when authentication fails due to invalid username or password. Ensure correct credentials are provided."
          },
          {
            "error": "AuthenticationCredentialsNotFoundException",
            "solution": "Occurs when no authentication is present in the security context. Ensure security filters are configured correctly."
          }
        ]
      },
      "references": {
        "official_docs": "https://spring.io/projects/spring-security",
        "github": "https://github.com/spring-projects/spring-security"
      }
    },
    {
      "id": "hibernate",
      "name": "Hibernate",
      "category": "Data",
      "description": "Hibernate is a powerful Object-Relational Mapping (ORM) framework for Java that simplifies database interactions by mapping Java objects to relational database tables.",
      "story": "Hibernate was created to solve the problem of manual JDBC code and boilerplate SQL queries. It provides a high-level abstraction for database operations, supports caching, lazy loading, and transaction management, making Java applications more maintainable and scalable.",
      "installation": {
        "maven": "Add hibernate-core dependency in pom.xml",
        "gradle": "Add implementation 'org.hibernate:hibernate-core:5.6.15.Final' in build.gradle"
      },
      "usage": {
        "overview": "Hibernate allows developers to interact with databases using Java objects rather than SQL. It provides features like automatic table generation, HQL (Hibernate Query Language), transaction management, and caching.",
        "basic_examples": [
          {
            "title": "Mapping an entity",
            "code": "// User.java\nimport jakarta.persistence.Entity;\nimport jakarta.persistence.Id;\n\n@Entity\npublic class User {\n    @Id\n    private Long id;\n    private String name;\n    private String email;\n    // getters and setters\n}",
            "explanation": "Defines a simple `User` entity that maps to a database table using JPA annotations."
          },
          {
            "title": "Creating Hibernate SessionFactory",
            "code": "// HibernateUtil.java\nimport org.hibernate.SessionFactory;\nimport org.hibernate.cfg.Configuration;\n\npublic class HibernateUtil {\n    private static final SessionFactory sessionFactory =\n        new Configuration().configure().buildSessionFactory();\n\n    public static SessionFactory getSessionFactory() {\n        return sessionFactory;\n    }\n}",
            "explanation": "Creates a singleton `SessionFactory` which is used to open sessions for database operations."
          }
        ],
        "advanced_examples": [
          {
            "title": "Saving an entity",
            "code": "import org.hibernate.Session;\nimport org.hibernate.Transaction;\n\nSession session = HibernateUtil.getSessionFactory().openSession();\nTransaction tx = session.beginTransaction();\nUser user = new User();\nuser.setId(1L);\nuser.setName(\"Alice\");\nsession.save(user);\ntx.commit();\nsession.close();",
            "explanation": "Demonstrates saving a `User` entity to the database using Hibernate session and transaction."
          },
          {
            "title": "Querying with HQL",
            "code": "Session session = HibernateUtil.getSessionFactory().openSession();\nList<User> users = session.createQuery(\"FROM User WHERE name = :name\", User.class)\n    .setParameter(\"name\", \"Alice\")\n    .list();\nsession.close();",
            "explanation": "Uses Hibernate Query Language (HQL) to fetch users with a specific name."
          },
          {
            "title": "Updating an entity",
            "code": "Session session = HibernateUtil.getSessionFactory().openSession();\nTransaction tx = session.beginTransaction();\nUser user = session.get(User.class, 1L);\nuser.setEmail(\"alice@example.com\");\nsession.update(user);\ntx.commit();\nsession.close();",
            "explanation": "Updates an existing user entity in the database."
          },
          {
            "title": "Deleting an entity",
            "code": "Session session = HibernateUtil.getSessionFactory().openSession();\nTransaction tx = session.beginTransaction();\nUser user = session.get(User.class, 1L);\nsession.delete(user);\ntx.commit();\nsession.close();",
            "explanation": "Deletes a user entity from the database."
          }
        ],
        "best_practices": [
          "Use JPA annotations for entity mapping for portability.",
          "Always manage transactions explicitly for consistency.",
          "Close sessions to release database connections.",
          "Use caching (first-level and second-level) to improve performance.",
          "Prefer parameterized queries or HQL to prevent SQL injection."
        ],
        "error_handling": [
          {
            "error": "org.hibernate.LazyInitializationException",
            "solution": "Occurs when accessing uninitialized lazy-loaded associations outside of session. Ensure session is open or fetch eagerly."
          },
          {
            "error": "org.hibernate.HibernateException",
            "solution": "General Hibernate exception. Check configuration, mappings, and session handling."
          },
          {
            "error": "ConstraintViolationException",
            "solution": "Occurs when database constraints (e.g., unique, not null) are violated. Validate data before saving."
          }
        ]
      },
      "references": {
        "official_docs": "https://hibernate.org/orm/documentation/",
        "github": "https://github.com/hibernate/hibernate-orm"
      }
    },
    {
      "id": "jackson",
      "name": "Jackson",
      "category": "Web",
      "description": "Jackson is a high-performance JSON processor for Java. It allows for parsing, generating, and transforming JSON data, and integrates seamlessly with Java objects using annotations and data binding.",
      "story": "Jackson was created to provide a flexible, efficient, and feature-rich library for working with JSON in Java. It supports streaming, tree model, and data-binding approaches, making it popular for REST APIs, configuration parsing, and data serialization.",
      "installation": {
        "maven": "Add com.fasterxml.jackson.core:jackson-databind dependency in pom.xml",
        "gradle": "Add implementation 'com.fasterxml.jackson.core:jackson-databind:2.15.2' in build.gradle"
      },
      "usage": {
        "overview": "Jackson allows Java developers to serialize Java objects to JSON and deserialize JSON into Java objects. It supports annotations for customizing serialization, ignores unknown properties, and integrates with frameworks like Spring Boot.",
        "basic_examples": [
          {
            "title": "Serializing a Java object to JSON",
            "code": "import com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class Main {\n    public static void main(String[] args) throws Exception {\n        ObjectMapper mapper = new ObjectMapper();\n        User user = new User(1, \"Alice\");\n        String json = mapper.writeValueAsString(user);\n        System.out.println(json);\n    }\n}\n\nclass User {\n    public int id;\n    public String name;\n    public User(int id, String name) { this.id = id; this.name = name; }\n}",
            "explanation": "Converts a Java object `User` into a JSON string using `ObjectMapper`."
          },
          {
            "title": "Deserializing JSON to a Java object",
            "code": "String json = \"{\\\"id\\\":1,\\\"name\\\":\\\"Alice\\\"}\";\nUser user = mapper.readValue(json, User.class);\nSystem.out.println(user.name);",
            "explanation": "Converts a JSON string into a Java `User` object using Jackson."
          }
        ],
        "advanced_examples": [
          {
            "title": "Ignoring unknown properties",
            "code": "import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n\n@JsonIgnoreProperties(ignoreUnknown = true)\nclass User {...}",
            "explanation": "Prevents Jackson from failing when extra fields exist in JSON that are not in the Java class."
          },
          {
            "title": "Custom serialization",
            "code": "import com.fasterxml.jackson.core.JsonGenerator;\nimport com.fasterxml.jackson.databind.SerializerProvider;\nimport com.fasterxml.jackson.databind.ser.std.StdSerializer;\n\nclass CustomUserSerializer extends StdSerializer<User> {\n    public void serialize(User user, JsonGenerator gen, SerializerProvider provider) throws IOException {\n        gen.writeStartObject();\n        gen.writeStringField(\"full_name\", user.name);\n        gen.writeEndObject();\n    }\n}",
            "explanation": "Demonstrates customizing how a Java object is serialized to JSON."
          },
          {
            "title": "Working with Collections",
            "code": "List<User> users = Arrays.asList(new User(1,\"Alice\"), new User(2,\"Bob\"));\nString json = mapper.writeValueAsString(users);\nList<User> deserialized = mapper.readValue(json, new TypeReference<List<User>>() {});",
            "explanation": "Shows serialization and deserialization of lists of Java objects."
          },
          {
            "title": "Tree model for dynamic JSON",
            "code": "JsonNode rootNode = mapper.readTree(json);\nString name = rootNode.get(\"name\").asText();",
            "explanation": "Allows parsing JSON into a tree structure for dynamic access without mapping to a Java class."
          }
        ],
        "best_practices": [
          "Use `ObjectMapper` as a singleton to avoid performance overhead.",
          "Leverage annotations like `@JsonProperty`, `@JsonIgnore`, and `@JsonInclude` for fine-grained control.",
          "Handle unknown properties gracefully with `@JsonIgnoreProperties`.",
          "Use TypeReference for deserializing generic types like lists and maps.",
          "Integrate with Spring Bootâ€™s `MappingJackson2HttpMessageConverter` for REST APIs."
        ],
        "error_handling": [
          {
            "error": "JsonMappingException",
            "solution": "Occurs when JSON cannot be mapped to Java object. Ensure field names and types match."
          },
          {
            "error": "JsonParseException",
            "solution": "Occurs when JSON is invalid or malformed. Validate JSON input before deserialization."
          },
          {
            "error": "IOException",
            "solution": "Occurs during I/O operations. Handle file/stream errors when reading or writing JSON."
          }
        ]
      },
      "references": {
        "official_docs": "https://github.com/FasterXML/jackson",
        "github": "https://github.com/FasterXML/jackson"
      }
    },
    {
      "id": "gson",
      "name": "Gson",
      "category": "Web",
      "description": "Gson is a Java library by Google for converting Java objects to JSON and vice versa. It supports serialization and deserialization of Java objects, including collections, generics, and nested objects.",
      "story": "Gson was created by Google to provide a simple and efficient way to handle JSON in Java applications. It emphasizes ease-of-use, flexibility, and compatibility with standard Java types, making it popular for REST APIs and configuration handling.",
      "installation": {
        "maven": "Add com.google.code.gson:gson dependency in pom.xml",
        "gradle": "Add implementation 'com.google.code.gson:gson:2.10.1' in build.gradle"
      },
      "usage": {
        "overview": "Gson allows developers to serialize Java objects into JSON strings and deserialize JSON strings into Java objects. It supports custom serializers, deserializers, and works well with collections and complex object hierarchies.",
        "basic_examples": [
          {
            "title": "Serializing a Java object to JSON",
            "code": "import com.google.gson.Gson;\n\npublic class Main {\n    public static void main(String[] args) {\n        Gson gson = new Gson();\n        User user = new User(1, \"Alice\");\n        String json = gson.toJson(user);\n        System.out.println(json);\n    }\n}\n\nclass User {\n    int id;\n    String name;\n    User(int id, String name) { this.id = id; this.name = name; }\n}",
            "explanation": "Converts a Java object `User` into a JSON string using Gson."
          },
          {
            "title": "Deserializing JSON to a Java object",
            "code": "String json = \"{\\\"id\\\":1,\\\"name\\\":\\\"Alice\\\"}\";\nUser user = gson.fromJson(json, User.class);\nSystem.out.println(user.name);",
            "explanation": "Converts a JSON string into a Java `User` object using Gson."
          }
        ],
        "advanced_examples": [
          {
            "title": "Working with Lists",
            "code": "List<User> users = Arrays.asList(new User(1,\"Alice\"), new User(2,\"Bob\"));\nString json = gson.toJson(users);\nList<User> deserialized = gson.fromJson(json, new TypeToken<List<User>>(){}.getType());",
            "explanation": "Demonstrates serialization and deserialization of lists of Java objects using `TypeToken`."
          },
          {
            "title": "Custom serialization",
            "code": "import com.google.gson.JsonElement;\nimport com.google.gson.JsonSerializationContext;\nimport com.google.gson.JsonSerializer;\nimport java.lang.reflect.Type;\n\nclass UserSerializer implements JsonSerializer<User> {\n    public JsonElement serialize(User user, Type typeOfSrc, JsonSerializationContext context) {\n        return context.serialize(user.name); // only serialize the name field\n    }\n}",
            "explanation": "Shows how to customize serialization by implementing `JsonSerializer`."
          },
          {
            "title": "Excluding fields with @Expose",
            "code": "import com.google.gson.annotations.Expose;\n\nclass User {\n    @Expose private int id;\n    @Expose private String name;\n    private String password;\n}",
            "explanation": "Only fields annotated with `@Expose` will be serialized when using `GsonBuilder().excludeFieldsWithoutExposeAnnotation()`."
          },
          {
            "title": "Pretty printing JSON",
            "code": "Gson gson = new GsonBuilder().setPrettyPrinting().create();\nString prettyJson = gson.toJson(user);\nSystem.out.println(prettyJson);",
            "explanation": "Formats JSON output for readability."
          }
        ],
        "best_practices": [
          "Use `Gson` as a singleton to improve performance.",
          "Use `TypeToken` when deserializing generic types like collections.",
          "Leverage `@Expose` and `GsonBuilder` for field-level control.",
          "Handle null values explicitly with `serializeNulls()` if needed.",
          "Prefer Gson for simple JSON processing; use Jackson for complex or high-performance scenarios."
        ],
        "error_handling": [
          {
            "error": "JsonSyntaxException",
            "solution": "Occurs when the JSON is malformed or doesn't match the Java object structure. Validate JSON input."
          },
          {
            "error": "JsonIOException",
            "solution": "Occurs during I/O operations. Handle stream/file errors when reading or writing JSON."
          },
          {
            "error": "JsonParseException",
            "solution": "Occurs when parsing fails. Ensure JSON format is correct and compatible with the target class."
          }
        ]
      },
      "references": {
        "official_docs": "https://github.com/google/gson",
        "github": "https://github.com/google/gson"
      }
    },
    {
      "id": "okhttp",
      "name": "OkHttp",
      "category": "Web",
      "description": "OkHttp is a modern, efficient, and feature-rich HTTP client for Java and Android. It supports HTTP/1.1, HTTP/2, WebSocket, connection pooling, and transparent GZIP compression.",
      "story": "OkHttp was created by Square to provide a reliable and performant HTTP client for Java applications. It handles connection management, retries, caching, and asynchronous requests efficiently, making it popular for REST API clients.",
      "installation": {
        "maven": "Add com.squareup.okhttp3:okhttp dependency in pom.xml",
        "gradle": "Add implementation 'com.squareup.okhttp3:okhttp:4.11.0' in build.gradle"
      },
      "usage": {
        "overview": "OkHttp allows developers to send synchronous and asynchronous HTTP requests, manage headers and cookies, handle redirects, and stream responses. It integrates seamlessly with JSON libraries like Gson or Jackson.",
        "basic_examples": [
          {
            "title": "Simple GET request",
            "code": "import okhttp3.OkHttpClient;\nimport okhttp3.Request;\nimport okhttp3.Response;\n\nOkHttpClient client = new OkHttpClient();\nRequest request = new Request.Builder()\n    .url(\"https://api.github.com\")\n    .build();\n\ntry (Response response = client.newCall(request).execute()) {\n    System.out.println(response.body().string());\n}",
            "explanation": "Sends a synchronous GET request to a URL and prints the response body."
          },
          {
            "title": "Simple POST request with JSON",
            "code": "import okhttp3.MediaType;\nimport okhttp3.OkHttpClient;\nimport okhttp3.Request;\nimport okhttp3.RequestBody;\nimport okhttp3.Response;\n\nOkHttpClient client = new OkHttpClient();\nMediaType JSON = MediaType.get(\"application/json; charset=utf-8\");\nString json = \"{\\\"name\\\":\\\"Alice\\\"}\";\nRequestBody body = RequestBody.create(json, JSON);\nRequest request = new Request.Builder()\n    .url(\"https://httpbin.org/post\")\n    .post(body)\n    .build();\n\ntry (Response response = client.newCall(request).execute()) {\n    System.out.println(response.body().string());\n}",
            "explanation": "Sends a POST request with a JSON payload."
          }
        ],
        "advanced_examples": [
          {
            "title": "Asynchronous request",
            "code": "client.newCall(request).enqueue(new okhttp3.Callback() {\n    @Override\n    public void onFailure(okhttp3.Call call, IOException e) {\n        e.printStackTrace();\n    }\n    @Override\n    public void onResponse(okhttp3.Call call, Response response) throws IOException {\n        System.out.println(response.body().string());\n    }\n});",
            "explanation": "Executes an HTTP request asynchronously using a callback."
          },
          {
            "title": "Adding headers",
            "code": "Request request = new Request.Builder()\n    .url(\"https://api.example.com\")\n    .addHeader(\"Authorization\", \"Bearer TOKEN\")\n    .build();",
            "explanation": "Demonstrates adding custom HTTP headers to a request."
          },
          {
            "title": "Connection pooling and timeouts",
            "code": "OkHttpClient client = new OkHttpClient.Builder()\n    .connectTimeout(10, TimeUnit.SECONDS)\n    .readTimeout(30, TimeUnit.SECONDS)\n    .build();",
            "explanation": "Configures OkHttp client with custom timeouts for connection and reading."
          },
          {
            "title": "Using interceptors",
            "code": "OkHttpClient client = new OkHttpClient.Builder()\n    .addInterceptor(chain -> {\n        Request request = chain.request().newBuilder()\n            .addHeader(\"X-Custom-Header\", \"value\")\n            .build();\n        return chain.proceed(request);\n    })\n    .build();",
            "explanation": "Uses an interceptor to modify requests globally."
          }
        ],
        "best_practices": [
          "Reuse `OkHttpClient` instances to leverage connection pooling.",
          "Use asynchronous calls for network operations to avoid blocking the main thread.",
          "Use interceptors for logging, authentication, or request/response modification.",
          "Handle network exceptions gracefully and implement retries if necessary.",
          "Integrate with JSON libraries like Gson or Jackson for payload serialization/deserialization."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when network request fails. Check connectivity, URL, or request configuration."
          },
          {
            "error": "TimeoutException",
            "solution": "Occurs if a request exceeds the specified timeout. Adjust timeouts based on network conditions."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Occurs when request parameters (URL, headers, body) are invalid. Validate inputs before sending requests."
          }
        ]
      },
      "references": {
        "official_docs": "https://square.github.io/okhttp/",
        "github": "https://github.com/square/okhttp"
      }
    },
    {
      "id": "retrofit",
      "name": "Retrofit",
      "category": "Web",
      "description": "Retrofit is a type-safe HTTP client for Java and Android, developed by Square. It allows you to define REST API endpoints as Java interfaces and automatically converts HTTP responses into Java objects using converters like Gson or Jackson.",
      "story": "Retrofit was created by Square to simplify the process of consuming REST APIs in Java applications. By leveraging annotations, it abstracts network calls, handles serialization/deserialization, and supports synchronous and asynchronous requests.",
      "installation": {
        "maven": "Add com.squareup.retrofit2:retrofit dependency in pom.xml",
        "gradle": "Add implementation 'com.squareup.retrofit2:retrofit:2.9.0' in build.gradle"
      },
      "usage": {
        "overview": "Retrofit allows developers to define API endpoints in Java interfaces, handle requests and responses easily, and integrate with JSON converters. It supports query parameters, path variables, headers, and multipart requests.",
        "basic_examples": [
          {
            "title": "Defining a simple API interface",
            "code": "import retrofit2.Call;\nimport retrofit2.http.GET;\n\npublic interface ApiService {\n    @GET(\"users\")\n    Call<List<User>> getUsers();\n}",
            "explanation": "Defines a GET request to fetch a list of users from the `/users` endpoint."
          },
          {
            "title": "Creating Retrofit instance",
            "code": "import retrofit2.Retrofit;\nimport retrofit2.converter.gson.GsonConverterFactory;\n\nRetrofit retrofit = new Retrofit.Builder()\n    .baseUrl(\"https://api.example.com/\")\n    .addConverterFactory(GsonConverterFactory.create())\n    .build();\n\nApiService service = retrofit.create(ApiService.class);",
            "explanation": "Creates a Retrofit instance with a base URL and a Gson converter for JSON parsing."
          }
        ],
        "advanced_examples": [
          {
            "title": "Making synchronous requests",
            "code": "Call<List<User>> call = service.getUsers();\ntry {\n    List<User> users = call.execute().body();\n    System.out.println(users);\n} catch (IOException e) {\n    e.printStackTrace();\n}",
            "explanation": "Executes a request synchronously and retrieves the response body."
          },
          {
            "title": "Making asynchronous requests",
            "code": "call.enqueue(new retrofit2.Callback<List<User>>() {\n    @Override\n    public void onResponse(Call<List<User>> call, retrofit2.Response<List<User>> response) {\n        System.out.println(response.body());\n    }\n    @Override\n    public void onFailure(Call<List<User>> call, Throwable t) {\n        t.printStackTrace();\n    }\n});",
            "explanation": "Executes a request asynchronously using a callback."
          },
          {
            "title": "Using path and query parameters",
            "code": "import retrofit2.http.Path;\nimport retrofit2.http.Query;\n\n@GET(\"users/{id}\")\nCall<User> getUser(@Path(\"id\") int id, @Query(\"expand\") boolean expandDetails);",
            "explanation": "Shows how to pass dynamic path variables and query parameters in API calls."
          },
          {
            "title": "Adding headers",
            "code": "@GET(\"users\")\n@Headers({\"Authorization: Bearer TOKEN\"})\nCall<List<User>> getUsersWithAuth();",
            "explanation": "Demonstrates setting static headers for a specific API request."
          }
        ],
        "best_practices": [
          "Reuse Retrofit instances to leverage connection pooling.",
          "Use converters like Gson, Jackson, or Moshi for serialization/deserialization.",
          "Handle errors and HTTP status codes in the callback.",
          "Prefer asynchronous requests for network operations to avoid blocking threads.",
          "Leverage OkHttp interceptors for logging, authentication, and retries."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when a network request fails. Check connectivity and URL."
          },
          {
            "error": "HttpException",
            "solution": "Thrown when the HTTP response is not successful (non-2xx). Check status code and response body."
          },
          {
            "error": "JsonSyntaxException",
            "solution": "Occurs when JSON response cannot be parsed into the specified Java object. Ensure matching fields and types."
          }
        ]
      },
      "references": {
        "official_docs": "https://square.github.io/retrofit/",
        "github": "https://github.com/square/retrofit"
      }
    },
    {
      "id": "feign",
      "name": "Feign",
      "category": "Web",
      "description": "Feign is a declarative HTTP client for Java, primarily used with Spring Cloud to simplify REST API calls. It allows developers to define API clients using interfaces and annotations.",
      "story": "Feign was created by Netflix to provide a type-safe and declarative way to call REST services in Java. It integrates seamlessly with Spring Boot and Spring Cloud, supporting load balancing, circuit breakers, and automatic request/response mapping.",
      "installation": {
        "maven": "Add org.springframework.cloud:spring-cloud-starter-openfeign dependency in pom.xml",
        "gradle": "Add implementation 'org.springframework.cloud:spring-cloud-starter-openfeign' in build.gradle"
      },
      "usage": {
        "overview": "Feign allows developers to define Java interfaces annotated with HTTP methods, paths, and parameters. Spring Boot automatically generates the implementation and handles serialization/deserialization, making API calls simple and readable.",
        "basic_examples": [
          {
            "title": "Defining a Feign client",
            "code": "import org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport java.util.List;\n\n@FeignClient(name = \"user-service\", url = \"https://api.example.com\")\npublic interface UserClient {\n    @GetMapping(\"/users\")\n    List<User> getUsers();\n}",
            "explanation": "Defines a Feign client interface to fetch a list of users from the `/users` endpoint."
          },
          {
            "title": "Enabling Feign in Spring Boot",
            "code": "import org.springframework.cloud.openfeign.EnableFeignClients;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\n@EnableFeignClients\npublic class Application {\n    public static void main(String[] args) {\n        SpringApplication.run(Application.class, args);\n    }\n}",
            "explanation": "Enables Feign support in a Spring Boot application."
          }
        ],
        "advanced_examples": [
          {
            "title": "Passing query parameters",
            "code": "@GetMapping(\"/users\")\nList<User> getUsersByRole(@RequestParam(\"role\") String role);",
            "explanation": "Demonstrates sending query parameters in Feign client calls."
          },
          {
            "title": "Handling path variables",
            "code": "@GetMapping(\"/users/{id}\")\nUser getUserById(@PathVariable(\"id\") Long id);",
            "explanation": "Demonstrates sending path variables in Feign client calls."
          },
          {
            "title": "Custom headers",
            "code": "@GetMapping(\"/users\")\n@Headers(\"Authorization: Bearer {token}\")\nList<User> getUsers(@Param(\"token\") String token);",
            "explanation": "Shows how to pass custom headers dynamically in Feign requests."
          },
          {
            "title": "Using fallback for error handling",
            "code": "import org.springframework.stereotype.Component;\n\n@Component\npublic class UserClientFallback implements UserClient {\n    @Override\n    public List<User> getUsers() {\n        return Collections.emptyList(); // fallback response\n    }\n}",
            "explanation": "Provides a fallback implementation when the Feign client call fails."
          }
        ],
        "best_practices": [
          "Use Feign clients as interfaces to improve testability and maintainability.",
          "Leverage Spring Cloud load balancing and resilience features (e.g., Hystrix or Resilience4j) with Feign.",
          "Handle exceptions and fallback responses gracefully.",
          "Prefer declarative annotations over manual HTTP calls for cleaner code.",
          "Use DTOs and proper serialization libraries (Gson, Jackson) for request/response objects."
        ],
        "error_handling": [
          {
            "error": "FeignException",
            "solution": "Occurs when the Feign client receives a non-successful HTTP response. Check status code and error body."
          },
          {
            "error": "HttpClientErrorException",
            "solution": "Thrown when a 4xx HTTP error occurs. Validate request parameters and headers."
          },
          {
            "error": "HttpServerErrorException",
            "solution": "Thrown when a 5xx HTTP error occurs. Retry or use fallback mechanisms for resilience."
          }
        ]
      },
      "references": {
        "official_docs": "https://spring.io/projects/spring-cloud-openfeign",
        "github": "https://github.com/OpenFeign/feign"
      }
    },
    {
      "id": "mapstruct",
      "name": "MapStruct",
      "category": "CLI/Utils",
      "description": "MapStruct is a Java annotation processor for generating type-safe and performant mappers that automatically convert between Java beans (DTOs and entities).",
      "story": "MapStruct was created to eliminate the boilerplate code of writing manual mapping logic between Java objects. By generating mapper implementations at compile-time, it ensures type safety, high performance, and easy maintenance.",
      "installation": {
        "maven": "Add org.mapstruct:mapstruct dependency and mapstruct-processor annotationProcessor in pom.xml",
        "gradle": "Add implementation 'org.mapstruct:mapstruct:1.6.14.Final' and annotationProcessor 'org.mapstruct:mapstruct-processor:1.6.14.Final' in build.gradle"
      },
      "usage": {
        "overview": "MapStruct allows developers to define mapper interfaces annotated with `@Mapper`. At compile-time, MapStruct generates the implementation class for converting between source and target objects.",
        "basic_examples": [
          {
            "title": "Defining a simple mapper",
            "code": "import org.mapstruct.Mapper;\nimport org.mapstruct.factory.Mappers;\n\n@Mapper\npublic interface UserMapper {\n    UserMapper INSTANCE = Mappers.getMapper(UserMapper.class);\n    UserDTO userToUserDTO(User user);\n}",
            "explanation": "Defines a mapper interface for converting a `User` entity to `UserDTO`. MapStruct generates the implementation automatically."
          },
          {
            "title": "Using the mapper",
            "code": "User user = new User(1, \"Alice\", \"alice@example.com\");\nUserDTO dto = UserMapper.INSTANCE.userToUserDTO(user);\nSystem.out.println(dto.getName());",
            "explanation": "Uses the generated mapper to convert a `User` object to a `UserDTO` object."
          }
        ],
        "advanced_examples": [
          {
            "title": "Mapping collections",
            "code": "List<UserDTO> dtos = UserMapper.INSTANCE.usersToUserDTOs(usersList);",
            "explanation": "MapStruct can convert collections of objects automatically."
          },
          {
            "title": "Custom field mapping",
            "code": "@Mapping(source = \"email\", target = \"contactEmail\")\nUserDTO userToUserDTO(User user);",
            "explanation": "Maps fields with different names using `@Mapping` annotation."
          },
          {
            "title": "Nested object mapping",
            "code": "@Mapping(source = \"address.street\", target = \"streetName\")\nUserDTO userToUserDTO(User user);",
            "explanation": "Maps nested fields from source object to target object."
          },
          {
            "title": "Mapping with expressions",
            "code": "@Mapping(target = \"fullName\", expression = \"java(user.getFirstName() + ' ' + user.getLastName())\")\nUserDTO userToUserDTO(User user);",
            "explanation": "Uses Java expressions for complex field transformations during mapping."
          }
        ],
        "best_practices": [
          "Keep mapping interfaces simple and modular.",
          "Use `@Mapper` with componentModel = 'spring' for Spring Boot integration.",
          "Prefer compile-time mappings over reflection-based mapping for performance.",
          "Leverage `@Mapping` for fields with different names or types.",
          "Validate mapping results in unit tests to ensure correctness."
        ],
        "error_handling": [
          {
            "error": "UnmappedTargetPropertyException",
            "solution": "Occurs when a target field does not have a corresponding mapping. Add `@Mapping` or `@Mappings` annotations or ignore unmapped fields."
          },
          {
            "error": "AnnotationProcessingException",
            "solution": "Occurs if MapStruct annotation processor is not configured correctly. Ensure proper dependencies and annotationProcessor setup."
          },
          {
            "error": "IncompatibleTypesException",
            "solution": "Occurs when source and target types cannot be mapped. Use type conversions or custom mapping methods."
          }
        ]
      },
      "references": {
        "official_docs": "https://mapstruct.org/documentation/stable/reference/html/",
        "github": "https://github.com/mapstruct/mapstruct"
      }
    },
    {
      "id": "lombok",
      "name": "Lombok",
      "category": "CLI/Utils",
      "description": "Lombok is a Java library that reduces boilerplate code by generating commonly used methods like getters, setters, constructors, `toString`, `equals`, and `hashCode` using annotations.",
      "story": "Lombok was created to simplify Java development by automating repetitive coding tasks. It uses annotation processing to generate code at compile-time, keeping the source code clean and readable while maintaining full type safety.",
      "installation": {
        "maven": "Add org.projectlombok:lombok dependency in pom.xml and enable annotation processing in IDE",
        "gradle": "Add implementation 'org.projectlombok:lombok:1.18.30' in build.gradle and enable annotation processing"
      },
      "usage": {
        "overview": "Lombok provides annotations like `@Getter`, `@Setter`, `@NoArgsConstructor`, `@AllArgsConstructor`, `@Builder`, `@Data`, and more. These annotations automatically generate code during compilation, reducing boilerplate while keeping Java code clean.",
        "basic_examples": [
          {
            "title": "Using @Getter and @Setter",
            "code": "import lombok.Getter;\nimport lombok.Setter;\n\n@Getter\n@Setter\npublic class User {\n    private int id;\n    private String name;\n}",
            "explanation": "Automatically generates getter and setter methods for `id` and `name` fields."
          },
          {
            "title": "Using @NoArgsConstructor and @AllArgsConstructor",
            "code": "import lombok.NoArgsConstructor;\nimport lombok.AllArgsConstructor;\n\n@NoArgsConstructor\n@AllArgsConstructor\npublic class User {\n    private int id;\n    private String name;\n}",
            "explanation": "Generates a no-argument constructor and an all-argument constructor automatically."
          },
          {
            "title": "Using @ToString and @EqualsAndHashCode",
            "code": "import lombok.ToString;\nimport lombok.EqualsAndHashCode;\n\n@ToString\n@EqualsAndHashCode\npublic class User {\n    private int id;\n    private String name;\n}",
            "explanation": "Automatically generates `toString()`, `equals()`, and `hashCode()` methods."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using @Builder",
            "code": "import lombok.Builder;\n\n@Builder\npublic class User {\n    private int id;\n    private String name;\n}\n\nUser user = User.builder().id(1).name(\"Alice\").build();",
            "explanation": "Enables the builder pattern for creating instances of `User`."
          },
          {
            "title": "Using @Data",
            "code": "import lombok.Data;\n\n@Data\npublic class User {\n    private int id;\n    private String name;\n}",
            "explanation": "`@Data` generates getters, setters, `toString()`, `equals()`, `hashCode()`, and required constructors in a single annotation."
          },
          {
            "title": "Using @Value for immutable objects",
            "code": "import lombok.Value;\n\n@Value\npublic class User {\n    private int id;\n    private String name;\n}",
            "explanation": "`@Value` creates immutable classes with final fields, getters, `toString()`, `equals()`, `hashCode()`, and a constructor."
          },
          {
            "title": "Customizing generated methods",
            "code": "import lombok.Getter;\n@Getter(onMethod_ = {@Deprecated})\nprivate int id;",
            "explanation": "Demonstrates adding custom annotations or behaviors to generated methods using Lombok features."
          }
        ],
        "best_practices": [
          "Use Lombok annotations to reduce boilerplate but avoid overusing `@Data` on entities with sensitive fields.",
          "Enable annotation processing in your IDE for proper code generation.",
          "Combine `@Builder` with `@AllArgsConstructor` for flexible object creation.",
          "Prefer immutable classes (`@Value`) where possible for safer code.",
          "Use `@Getter` and `@Setter` selectively for better control over field access."
        ],
        "error_handling": [
          {
            "error": "Compilation errors related to Lombok",
            "solution": "Ensure annotation processing is enabled in the IDE and Maven/Gradle plugins are configured correctly."
          },
          {
            "error": "IDE does not recognize generated methods",
            "solution": "Rebuild the project or refresh IDE caches; ensure Lombok plugin is installed."
          }
        ]
      },
      "references": {
        "official_docs": "https://projectlombok.org/",
        "github": "https://github.com/projectlombok/lombok"
      }
    },
    {
      "id": "slf4j",
      "name": "SLF4J",
      "category": "CLI/Utils",
      "description": "SLF4J (Simple Logging Facade for Java) is a logging abstraction that allows developers to plug in various logging frameworks such as Logback, Log4j, or java.util.logging without changing application code.",
      "story": "SLF4J was created to standardize logging in Java applications. Instead of tying code to a specific logging framework, SLF4J provides a facade that decouples logging API usage from the underlying logging implementation, enabling flexibility and consistency.",
      "installation": {
        "maven": "Add org.slf4j:slf4j-api dependency in pom.xml and include a binding like ch.qos.logback:logback-classic",
        "gradle": "Add implementation 'org.slf4j:slf4j-api:2.0.9' and implementation 'ch.qos.logback:logback-classic:1.4.11' in build.gradle"
      },
      "usage": {
        "overview": "SLF4J allows developers to write logging code independent of the logging framework. Logging levels like TRACE, DEBUG, INFO, WARN, and ERROR are supported, with support for parameterized messages and exception logging.",
        "basic_examples": [
          {
            "title": "Creating a logger",
            "code": "import org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class MyApp {\n    private static final Logger logger = LoggerFactory.getLogger(MyApp.class);\n\n    public static void main(String[] args) {\n        logger.info(\"Application started\");\n    }\n}",
            "explanation": "Initializes an SLF4J logger for the class and logs an INFO level message."
          },
          {
            "title": "Logging with parameters",
            "code": "String user = \"Alice\";\nlogger.debug(\"User {} has logged in\", user);",
            "explanation": "Demonstrates parameterized logging to avoid string concatenation overhead."
          }
        ],
        "advanced_examples": [
          {
            "title": "Logging exceptions",
            "code": "try {\n    int result = 10 / 0;\n} catch (ArithmeticException e) {\n    logger.error(\"Error occurred: {}\", e.getMessage(), e);\n}",
            "explanation": "Logs an exception with a message and stack trace."
          },
          {
            "title": "Using different log levels",
            "code": "logger.trace(\"Trace message\");\nlogger.debug(\"Debug message\");\nlogger.info(\"Info message\");\nlogger.warn(\"Warning message\");\nlogger.error(\"Error message\");",
            "explanation": "Demonstrates all standard logging levels in SLF4J."
          },
          {
            "title": "Externalizing configuration with Logback",
            "code": "<configuration>\n  <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n    <encoder>\n      <pattern>%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n</pattern>\n    </encoder>\n  </appender>\n  <root level=\"debug\">\n    <appender-ref ref=\"STDOUT\" />\n  </root>\n</configuration>",
            "explanation": "Configures Logback as the underlying logging framework for SLF4J, including log format and level."
          }
        ],
        "best_practices": [
          "Use parameterized logging to improve performance and readability.",
          "Avoid hard-coded logging levels; configure them externally with the logging framework.",
          "Log exceptions with stack traces for easier debugging.",
          "Use class-specific loggers rather than a global logger for better context.",
          "Prefer SLF4J facade over direct dependency on a logging implementation for flexibility."
        ],
        "error_handling": [
          {
            "error": "NoClassDefFoundError for LoggerFactory",
            "solution": "Ensure the SLF4J API and an appropriate binding (like Logback) are included in the classpath."
          },
          {
            "error": "Multiple bindings warning",
            "solution": "Ensure only one SLF4J binding is present in the project dependencies."
          }
        ]
      },
      "references": {
        "official_docs": "http://www.slf4j.org/",
        "github": "https://github.com/qos-ch/slf4j"
      }
    },
    {
      "id": "log4j2",
      "name": "Log4j2",
      "category": "CLI/Utils",
      "description": "Log4j2 is a high-performance, flexible, and reliable logging framework for Java applications. It is the successor to Log4j and provides advanced features such as asynchronous logging, custom log levels, and plugin support.",
      "story": "Log4j2 was created by the Apache Software Foundation to address performance and flexibility limitations in Log4j 1.x. It leverages a plugin architecture, supports various appenders and layouts, and provides better performance through asynchronous logging and garbage-free design.",
      "installation": {
        "maven": "Add org.apache.logging.log4j:log4j-core and org.apache.logging.log4j:log4j-api dependencies in pom.xml",
        "gradle": "Add implementation 'org.apache.logging.log4j:log4j-api:2.20.0' and implementation 'org.apache.logging.log4j:log4j-core:2.20.0' in build.gradle"
      },
      "usage": {
        "overview": "Log4j2 allows developers to log messages at different levels (TRACE, DEBUG, INFO, WARN, ERROR, FATAL). It supports configuration through XML, JSON, YAML, or properties files and integrates with SLF4J for logging abstraction.",
        "basic_examples": [
          {
            "title": "Creating a logger",
            "code": "import org.apache.logging.log4j.LogManager;\nimport org.apache.logging.log4j.Logger;\n\npublic class MyApp {\n    private static final Logger logger = LogManager.getLogger(MyApp.class);\n\n    public static void main(String[] args) {\n        logger.info(\"Application started\");\n    }\n}",
            "explanation": "Initializes a Log4j2 logger and logs an INFO level message."
          },
          {
            "title": "Logging with parameters",
            "code": "String user = \"Alice\";\nlogger.debug(\"User {} has logged in\", user);",
            "explanation": "Shows parameterized logging to avoid string concatenation overhead."
          }
        ],
        "advanced_examples": [
          {
            "title": "Logging exceptions",
            "code": "try {\n    int result = 10 / 0;\n} catch (ArithmeticException e) {\n    logger.error(\"An error occurred: {}\", e.getMessage(), e);\n}",
            "explanation": "Logs an exception with a message and stack trace."
          },
          {
            "title": "Asynchronous logging",
            "code": "<Configuration status=\"WARN\">\n  <Appenders>\n    <Async name=\"AsyncConsole\">\n      <Console />\n    </Async>\n  </Appenders>\n  <Loggers>\n    <Root level=\"info\">\n      <AppenderRef ref=\"AsyncConsole\" />\n    </Root>\n  </Loggers>\n</Configuration>",
            "explanation": "Demonstrates asynchronous logging configuration for better performance."
          },
          {
            "title": "Custom log levels and appenders",
            "code": "<Logger name=\"com.example\" level=\"debug\" additivity=\"false\">\n  <AppenderRef ref=\"FileAppender\" />\n</Logger>",
            "explanation": "Defines a logger with a specific level and appender for fine-grained control."
          },
          {
            "title": "Using SLF4J with Log4j2",
            "code": "import org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nLogger logger = LoggerFactory.getLogger(MyApp.class);\nlogger.info(\"Message through SLF4J facade\");",
            "explanation": "Integrates Log4j2 with SLF4J for logging abstraction."
          }
        ],
        "best_practices": [
          "Use asynchronous logging for high-throughput applications.",
          "Externalize configuration in XML, JSON, YAML, or properties files for flexibility.",
          "Use parameterized logging instead of string concatenation for performance.",
          "Organize loggers per package or class for clarity.",
          "Leverage multiple appenders (console, file, rolling file, etc.) for different logging needs."
        ],
        "error_handling": [
          {
            "error": "NoClassDefFoundError for LogManager or Logger",
            "solution": "Ensure both log4j-api and log4j-core are present in the classpath."
          },
          {
            "error": "StatusLogger warnings",
            "solution": "Check configuration file format and location; Log4j2 may fallback to default configuration if it cannot find the custom config."
          }
        ]
      },
      "references": {
        "official_docs": "https://logging.apache.org/log4j/2.x/",
        "github": "https://github.com/apache/logging-log4j2"
      }
    },
    {
      "id": "junit5",
      "name": "JUnit 5",
      "category": "Testing",
      "description": "JUnit 5 is a modern testing framework for Java, designed to write unit and integration tests. It provides a modular architecture, rich annotations, and support for lambda expressions and assertions.",
      "story": "JUnit 5 was created to address limitations in JUnit 4 and provide a more flexible, extensible, and powerful testing framework. It consists of three modules: JUnit Platform, JUnit Jupiter, and JUnit Vintage, allowing developers to write modern tests and integrate with build tools and IDEs.",
      "installation": {
        "maven": "Add org.junit.jupiter:junit-jupiter dependency in pom.xml",
        "gradle": "Add testImplementation 'org.junit.jupiter:junit-jupiter:5.10.0' in build.gradle"
      },
      "usage": {
        "overview": "JUnit 5 allows developers to write tests using annotations such as `@Test`, `@BeforeEach`, `@AfterEach`, `@BeforeAll`, `@AfterAll`. It supports assertions, assumptions, parameterized tests, nested tests, and extensions for advanced testing scenarios.",
        "basic_examples": [
          {
            "title": "Simple test case",
            "code": "import org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\npublic class CalculatorTest {\n    @Test\n    void additionTest() {\n        assertEquals(5, 2 + 3);\n    }\n}",
            "explanation": "Defines a basic JUnit 5 test that checks if the addition of 2 + 3 equals 5."
          },
          {
            "title": "Setup and teardown",
            "code": "import org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.AfterEach;\n\n@BeforeEach\nvoid setup() {\n    // Code executed before each test\n}\n\n@AfterEach\nvoid teardown() {\n    // Code executed after each test\n}",
            "explanation": "Demonstrates methods that run before and after each test case for setup and cleanup."
          }
        ],
        "advanced_examples": [
          {
            "title": "Parameterized test",
            "code": "import org.junit.jupiter.params.ParameterizedTest;\nimport org.junit.jupiter.params.provider.ValueSource;\n\n@ParameterizedTest\n@ValueSource(ints = {1, 2, 3})\nvoid testWithValues(int value) {\n    assertTrue(value > 0);\n}",
            "explanation": "Runs the same test multiple times with different input values."
          },
          {
            "title": "Testing exceptions",
            "code": "@Test\nvoid divisionByZeroTest() {\n    assertThrows(ArithmeticException.class, () -> { int result = 10 / 0; });\n}",
            "explanation": "Verifies that a specific exception is thrown during execution."
          },
          {
            "title": "Nested tests",
            "code": "import org.junit.jupiter.api.Nested;\n\n@Nested\nclass InnerTests {\n    @Test\n    void innerTest() {\n        assertEquals(4, 2 * 2);\n    }\n}",
            "explanation": "Organizes tests hierarchically using nested classes for better readability."
          },
          {
            "title": "Conditional test execution",
            "code": "@Test\n@EnabledOnOs(OS.WINDOWS)\nvoid runOnlyOnWindows() {\n    // Test logic specific to Windows\n}",
            "explanation": "Runs tests conditionally based on operating system, environment, or custom conditions."
          }
        ],
        "best_practices": [
          "Write small, focused test cases for each functionality.",
          "Use parameterized tests to avoid code duplication.",
          "Leverage assertions to validate expected outcomes clearly.",
          "Use `@BeforeEach` and `@AfterEach` for setup/cleanup and `@BeforeAll`/`@AfterAll` for global setup.",
          "Integrate JUnit 5 with build tools like Maven/Gradle for automated testing pipelines."
        ],
        "error_handling": [
          {
            "error": "Test failures",
            "solution": "Check assertions and expected results; ensure the test logic matches the intended functionality."
          },
          {
            "error": "NoClassDefFoundError for JUnit classes",
            "solution": "Ensure JUnit 5 dependencies are correctly added and annotation processing is enabled if needed."
          }
        ]
      },
      "references": {
        "official_docs": "https://junit.org/junit5/docs/current/user-guide/",
        "github": "https://github.com/junit-team/junit5"
      }
    },
    {
      "id": "mockito",
      "name": "Mockito",
      "category": "Testing",
      "description": "Mockito is a popular Java testing framework used to create mock objects for unit testing. It allows developers to simulate the behavior of real objects and verify interactions, enabling isolated and controlled tests.",
      "story": "Mockito was created to simplify unit testing in Java by providing an easy-to-use API for mocking dependencies. It allows developers to focus on testing the class under test without needing real implementations of its collaborators.",
      "installation": {
        "maven": "Add org.mockito:mockito-core dependency in pom.xml",
        "gradle": "Add testImplementation 'org.mockito:mockito-core:5.6.0' in build.gradle"
      },
      "usage": {
        "overview": "Mockito allows creating mock objects, stubbing methods, verifying interactions, and capturing arguments. It integrates well with JUnit and supports annotations such as `@Mock`, `@InjectMocks`, and `@Spy` for cleaner test code.",
        "basic_examples": [
          {
            "title": "Creating a mock object",
            "code": "import static org.mockito.Mockito.*;\n\nList<String> mockedList = mock(List.class);\nmockedList.add(\"one\");\nverify(mockedList).add(\"one\");",
            "explanation": "Creates a mock List, calls a method, and verifies that the method was invoked with the correct argument."
          },
          {
            "title": "Stubbing method behavior",
            "code": "when(mockedList.get(0)).thenReturn(\"first\");\nSystem.out.println(mockedList.get(0)); // prints 'first'",
            "explanation": "Defines a return value for a method when called on a mock object."
          }
        ],
        "advanced_examples": [
          {
            "title": "Injecting mocks into a class",
            "code": "import org.mockito.InjectMocks;\nimport org.mockito.Mock;\nimport org.mockito.MockitoAnnotations;\n\npublic class UserServiceTest {\n\n    @Mock\n    private UserRepository userRepository;\n\n    @InjectMocks\n    private UserService userService;\n\n    @BeforeEach\n    void init() {\n        MockitoAnnotations.openMocks(this);\n    }\n}",
            "explanation": "Injects mock dependencies into the class under test automatically using `@InjectMocks`."
          },
          {
            "title": "Using @Spy for partial mocks",
            "code": "@Spy\nList<String> spyList = new ArrayList<>();\nspyList.add(\"one\");\nverify(spyList).add(\"one\");",
            "explanation": "Allows calling real methods while still being able to verify interactions or stub certain methods."
          },
          {
            "title": "Argument captor",
            "code": "import org.mockito.ArgumentCaptor;\nArgumentCaptor<String> captor = ArgumentCaptor.forClass(String.class);\nverify(mockedList).add(captor.capture());\nSystem.out.println(captor.getValue());",
            "explanation": "Captures arguments passed to mock methods for detailed verification."
          },
          {
            "title": "Verifying number of invocations",
            "code": "verify(mockedList, times(2)).add(\"one\");",
            "explanation": "Verifies that a method was called a specific number of times."
          }
        ],
        "best_practices": [
          "Use mocks only for external dependencies, not the class under test.",
          "Prefer `@Mock` and `@InjectMocks` annotations for cleaner tests.",
          "Use `verify` to ensure critical interactions with dependencies.",
          "Keep tests focused and independent; avoid relying on actual implementations of collaborators.",
          "Leverage argument captors to validate the actual data passed to mocks."
        ],
        "error_handling": [
          {
            "error": "UnnecessaryStubbingException",
            "solution": "Occurs when a stubbed method is never called. Remove unused stubs or set Mockito to lenient mode."
          },
          {
            "error": "MockitoException",
            "solution": "Ensure that mock objects are initialized properly using `MockitoAnnotations.openMocks()` or the `@ExtendWith(MockitoExtension.class)` JUnit 5 integration."
          },
          {
            "error": "NullPointerException on mock",
            "solution": "Verify that the mock object is created using `mock()` or `@Mock` and not null before use."
          }
        ]
      },
      "references": {
        "official_docs": "https://site.mockito.org/",
        "github": "https://github.com/mockito/mockito"
      }
    },
    {
      "id": "assertj",
      "name": "AssertJ",
      "category": "Testing",
      "description": "AssertJ is a fluent and rich assertion library for Java that allows developers to write readable and expressive unit test assertions. It provides a wide variety of assertions for core Java types, collections, exceptions, and more.",
      "story": "AssertJ was created to improve the readability and expressiveness of assertions in Java tests compared to standard JUnit assertions. Its fluent API allows for clear, chainable, and descriptive assertions, making tests easier to write and maintain.",
      "installation": {
        "maven": "Add org.assertj:assertj-core dependency in pom.xml",
        "gradle": "Add testImplementation 'org.assertj:assertj-core:3.26.2' in build.gradle"
      },
      "usage": {
        "overview": "AssertJ provides a fluent API for assertions, allowing chaining of methods, clear error messages, and a wide range of assertions for objects, collections, maps, exceptions, and more. It integrates seamlessly with JUnit or TestNG.",
        "basic_examples": [
          {
            "title": "Simple assertions",
            "code": "import static org.assertj.core.api.Assertions.*;\n\nint result = 5;\nassertThat(result).isEqualTo(5).isPositive();",
            "explanation": "Asserts that `result` is equal to 5 and positive using fluent chaining."
          },
          {
            "title": "String assertions",
            "code": "String text = \"Hello World\";\nassertThat(text).startsWith(\"Hello\").endsWith(\"World\").contains(\"lo Wo\");",
            "explanation": "Performs multiple string checks in a readable fluent style."
          }
        ],
        "advanced_examples": [
          {
            "title": "Collection assertions",
            "code": "List<Integer> numbers = Arrays.asList(1, 2, 3, 4);\nassertThat(numbers).hasSize(4).contains(2, 3).doesNotContain(5);",
            "explanation": "Performs assertions on collections including size, contents, and absence of elements."
          },
          {
            "title": "Exception assertions",
            "code": "assertThatThrownBy(() -> { Integer.parseInt(\"abc\"); }).isInstanceOf(NumberFormatException.class).hasMessageContaining(\"For input string\");",
            "explanation": "Checks that a block of code throws a specific exception with a message containing a given string."
          },
          {
            "title": "Extracting and asserting on properties",
            "code": "class User { String name; int age; }\nList<User> users = List.of(new User(\"Alice\", 25), new User(\"Bob\", 30));\nassertThat(users).extracting(User::getName).containsExactly(\"Alice\", \"Bob\");",
            "explanation": "Extracts properties from objects in a collection and asserts on their values."
          },
          {
            "title": "Using soft assertions",
            "code": "SoftAssertions softly = new SoftAssertions();\nsoftly.assertThat(1).isEqualTo(2);\nsoftly.assertThat(\"abc\").startsWith(\"a\");\nsoftly.assertAll();",
            "explanation": "Allows multiple assertions to be evaluated and reported together without stopping at the first failure."
          }
        ],
        "best_practices": [
          "Prefer AssertJ for readable and fluent assertions over standard JUnit assertions.",
          "Use chaining to combine multiple assertions on the same object for clarity.",
          "Leverage collection and property extraction methods for complex data structures.",
          "Use soft assertions when you want to evaluate multiple assertions and report all failures.",
          "Integrate with JUnit 5 or TestNG for seamless test execution."
        ],
        "error_handling": [
          {
            "error": "AssertionError",
            "solution": "Occurs when the actual value does not meet the expected condition. Check the test logic and input values."
          },
          {
            "error": "ClassNotFoundException for Assertions",
            "solution": "Ensure AssertJ core dependency is included in your project classpath."
          }
        ]
      },
      "references": {
        "official_docs": "https://assertj.github.io/doc/",
        "github": "https://github.com/assertj/assertj-core"
      }
    },
    {
      "id": "testcontainers",
      "name": "Testcontainers",
      "category": "Testing",
      "description": "Testcontainers is a Java library that provides lightweight, disposable Docker containers for running integration tests. It allows developers to test against databases, message brokers, or any containerized service in a reproducible way.",
      "story": "Testcontainers was created to simplify integration testing by providing real, isolated environments using Docker containers. It eliminates the need for complex local setup and ensures tests run consistently across different machines and CI environments.",
      "installation": {
        "maven": "Add org.testcontainers:testcontainers dependency in pom.xml",
        "gradle": "Add testImplementation 'org.testcontainers:testcontainers:1.20.3' in build.gradle"
      },
      "usage": {
        "overview": "Testcontainers allows developers to spin up Docker containers for databases, message queues, or other services during test execution. It supports JUnit 5 extensions, lifecycle management, reusable containers, and pre-configured modules for common services like PostgreSQL, MySQL, Kafka, and Redis.",
        "basic_examples": [
          {
            "title": "Starting a PostgreSQL container",
            "code": "import org.testcontainers.containers.PostgreSQLContainer;\n\nPostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\"postgres:15.3\")\n    .withDatabaseName(\"testdb\")\n    .withUsername(\"user\")\n    .withPassword(\"password\");\npostgres.start();",
            "explanation": "Starts a PostgreSQL container with a database name, username, and password for integration testing."
          },
          {
            "title": "Using container JDBC URL",
            "code": "String jdbcUrl = postgres.getJdbcUrl();\nString username = postgres.getUsername();\nString password = postgres.getPassword();\nConnection conn = DriverManager.getConnection(jdbcUrl, username, password);",
            "explanation": "Retrieves connection details from the container to connect your application to the test database."
          }
        ],
        "advanced_examples": [
          {
            "title": "JUnit 5 integration with @Testcontainers and @Container",
            "code": "import org.testcontainers.junit.jupiter.Container;\nimport org.testcontainers.junit.jupiter.Testcontainers;\n\n@Testcontainers\npublic class MyDatabaseTest {\n\n    @Container\n    public static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>(\"postgres:15.3\");\n\n    @Test\n    void testDatabaseConnection() {\n        assertNotNull(postgres.getJdbcUrl());\n    }\n}",
            "explanation": "Uses annotations to automatically manage container lifecycle with JUnit 5 tests."
          },
          {
            "title": "Reusable containers",
            "code": "postgres.withReuse(true);\n// container can be reused across multiple test runs for faster execution",
            "explanation": "Enables container reuse to reduce startup time during repeated test executions."
          },
          {
            "title": "Using Testcontainers for Kafka",
            "code": "import org.testcontainers.containers.KafkaContainer;\nKafkaContainer kafka = new KafkaContainer(\"confluentinc/cp-kafka:7.6.1\");\nkafka.start();",
            "explanation": "Starts a Kafka container for testing messaging functionality in applications."
          },
          {
            "title": "Custom container configuration",
            "code": "postgres.withInitScript(\"init.sql\").withExposedPorts(5432);",
            "explanation": "Demonstrates how to initialize a container with a custom SQL script and expose ports."
          }
        ],
        "best_practices": [
          "Use `@Testcontainers` and `@Container` annotations for automatic lifecycle management.",
          "Prefer lightweight containers for faster test execution.",
          "Reuse containers when possible to reduce startup time.",
          "Externalize configuration and credentials to environment variables for security.",
          "Combine Testcontainers with JUnit 5 for seamless integration testing in CI/CD pipelines."
        ],
        "error_handling": [
          {
            "error": "Docker not found",
            "solution": "Ensure Docker is installed and running on your system before running Testcontainers."
          },
          {
            "error": "Container startup timeout",
            "solution": "Increase startup timeout or verify the Docker image is available and compatible."
          },
          {
            "error": "Networking issues connecting to container",
            "solution": "Check Docker network configuration and exposed ports; ensure the test code uses the container's dynamic ports."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.testcontainers.org/",
        "github": "https://github.com/testcontainers/testcontainers-java"
      }
    },
    {
      "id": "vertx",
      "name": "Vert.x",
      "category": "Web",
      "description": "Vert.x is a toolkit for building reactive, non-blocking, and polyglot applications on the JVM. It supports asynchronous programming, event-driven architecture, and high-performance microservices.",
      "story": "Vert.x was created to provide a lightweight and scalable platform for building reactive applications. It leverages the event loop model, similar to Node.js, for handling concurrent I/O operations efficiently, making it ideal for web, microservices, and real-time applications.",
      "installation": {
        "maven": "Add io.vertx:vertx-core dependency in pom.xml",
        "gradle": "Add implementation 'io.vertx:vertx-core:4.4.6' in build.gradle"
      },
      "usage": {
        "overview": "Vert.x allows developers to create HTTP servers, clients, event buses, and reactive streams using an asynchronous API. It supports multiple JVM languages, modular architecture, and clustering for high availability.",
        "basic_examples": [
          {
            "title": "Creating a simple HTTP server",
            "code": "import io.vertx.core.Vertx;\n\nVertx vertx = Vertx.vertx();\nvertx.createHttpServer().requestHandler(req -> {\n    req.response().end(\"Hello Vert.x!\");\n}).listen(8080);",
            "explanation": "Creates a basic HTTP server that responds with 'Hello Vert.x!' on port 8080."
          },
          {
            "title": "Deploying a Verticle",
            "code": "import io.vertx.core.AbstractVerticle;\n\npublic class MyVerticle extends AbstractVerticle {\n    @Override\n    public void start() {\n        vertx.createHttpServer().requestHandler(req -> {\n            req.response().end(\"Hello from verticle!\");\n        }).listen(8081);\n    }\n}\n\nvertx.deployVerticle(new MyVerticle());",
            "explanation": "Deploys a verticle, the core unit of deployment in Vert.x, which handles server logic asynchronously."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Event Bus",
            "code": "vertx.eventBus().consumer(\"news\", message -> {\n    System.out.println(\"Received: \" + message.body());\n});\nvertx.eventBus().publish(\"news\", \"Breaking news!\");",
            "explanation": "Demonstrates publishing and consuming messages via Vert.x event bus for inter-verticle communication."
          },
          {
            "title": "Asynchronous HTTP client",
            "code": "vertx.createHttpClient().getNow(8080, \"localhost\", \"/\", response -> {\n    response.bodyHandler(body -> {\n        System.out.println(\"Received: \" + body.toString());\n    });\n});",
            "explanation": "Shows how to make non-blocking HTTP requests using Vert.x asynchronous client."
          },
          {
            "title": "Reactive Streams with Vert.x",
            "code": "import io.vertx.core.streams.Pump;\nPump.pump(source, destination).start();",
            "explanation": "Demonstrates bridging streams for backpressure-aware data flow using Vert.x reactive APIs."
          },
          {
            "title": "Clustering Vert.x",
            "code": "Vertx.clusteredVertx(new VertxOptions().setClustered(true), res -> {\n    if (res.succeeded()) {\n        Vertx vertxClustered = res.result();\n    }\n});",
            "explanation": "Enables Vert.x clustering for distributed event bus and high availability."
          }
        ],
        "best_practices": [
          "Use verticles to encapsulate logic and deploy independently.",
          "Leverage the event bus for communication between verticles.",
          "Avoid blocking operations; use asynchronous APIs for I/O tasks.",
          "Use configuration files or environment variables for deployment settings.",
          "Organize code modularly for maintainability in microservices architectures."
        ],
        "error_handling": [
          {
            "error": "Handler not called",
            "solution": "Ensure the event loop is not blocked and the handler is registered before events are published."
          },
          {
            "error": "Port already in use",
            "solution": "Use a different port or ensure no other process is listening on the same port."
          },
          {
            "error": "Verticle deployment failed",
            "solution": "Check for exceptions in start() method; verify dependencies and configurations."
          }
        ]
      },
      "references": {
        "official_docs": "https://vertx.io/docs/",
        "github": "https://github.com/eclipse-vertx/vert.x"
      }
    },
    {
      "id": "micronaut",
      "name": "Micronaut",
      "category": "Web",
      "description": "Micronaut is a modern, JVM-based framework for building modular, easily testable microservices and serverless applications. It emphasizes low memory footprint, fast startup time, and dependency injection with compile-time optimizations.",
      "story": "Micronaut was created to address limitations in traditional Java frameworks for microservices and serverless environments. It uses ahead-of-time (AOT) compilation to generate dependency injection and configuration metadata at compile time, reducing reflection usage and improving startup performance.",
      "installation": {
        "maven": "Add io.micronaut:micronaut-bom and dependencies like micronaut-runtime, micronaut-inject in pom.xml",
        "gradle": "Add implementation platform('io.micronaut:micronaut-bom:3.10.0') and dependencies like implementation 'io.micronaut:micronaut-runtime'"
      },
      "usage": {
        "overview": "Micronaut allows developers to build HTTP servers, clients, and microservices with minimal boilerplate. It supports reactive programming, dependency injection, declarative HTTP clients, and seamless integration with databases, messaging systems, and cloud services.",
        "basic_examples": [
          {
            "title": "Creating a simple HTTP controller",
            "code": "import io.micronaut.http.annotation.*;\n\n@Controller(\"/hello\")\npublic class HelloController {\n    @Get\n    public String index() {\n        return \"Hello Micronaut!\";\n    }\n}",
            "explanation": "Defines a basic HTTP controller that responds to GET requests at `/hello`."
          },
          {
            "title": "Starting a Micronaut application",
            "code": "import io.micronaut.runtime.Micronaut;\n\npublic class Application {\n    public static void main(String[] args) {\n        Micronaut.run(Application.class);\n    }\n}",
            "explanation": "Bootstraps a Micronaut application using the main method."
          }
        ],
        "advanced_examples": [
          {
            "title": "Dependency Injection",
            "code": "import jakarta.inject.Singleton;\n\n@Singleton\npublic class MyService {\n    public String getMessage() { return \"Service Message\"; }\n}\n\n@Controller(\"/service\")\npublic class ServiceController {\n    private final MyService myService;\n\n    public ServiceController(MyService myService) {\n        this.myService = myService;\n    }\n\n    @Get\n    public String message() {\n        return myService.getMessage();\n    }\n}",
            "explanation": "Demonstrates constructor-based dependency injection using `@Singleton` service."
          },
          {
            "title": "Reactive HTTP client",
            "code": "import io.micronaut.http.client.annotation.*;\nimport io.micronaut.http.annotation.*;\nimport reactor.core.publisher.Mono;\n\n@Client(\"https://api.example.com\")\ninterface ExampleClient {\n    @Get(\"/data\")\n    Mono<String> getData();\n}",
            "explanation": "Defines a declarative HTTP client using Micronaut's reactive HTTP client support."
          },
          {
            "title": "Configuration properties",
            "code": "import io.micronaut.context.annotation.*;\n\n@Singleton\n@ConfigurationProperties(\"app\")\npublic class AppConfig {\n    private String name;\n\n    public String getName() { return name; }\n    public void setName(String name) { this.name = name; }\n}",
            "explanation": "Binds configuration properties to a Java class for type-safe access."
          },
          {
            "title": "Handling exceptions globally",
            "code": "import io.micronaut.http.annotation.*;\nimport io.micronaut.http.*;\n\n@Error(global = true)\npublic HttpResponse<String> handleException(Exception e) {\n    return HttpResponse.<String>serverError(\"Error: \" + e.getMessage());\n}",
            "explanation": "Defines a global error handler for exceptions in the application."
          }
        ],
        "best_practices": [
          "Use compile-time dependency injection and AOT compilation to improve performance.",
          "Leverage declarative HTTP clients for clean microservice communication.",
          "Keep controllers thin and delegate business logic to services.",
          "Use configuration properties classes for type-safe access to application settings.",
          "Write reactive and non-blocking code when dealing with I/O for scalability."
        ],
        "error_handling": [
          {
            "error": "BeanInstantiationException",
            "solution": "Occurs when a bean cannot be created. Check constructor parameters and dependency injection setup."
          },
          {
            "error": "ConfigurationPropertyNotFoundException",
            "solution": "Ensure all required configuration properties are defined in application.yml or application.properties."
          },
          {
            "error": "Port already in use",
            "solution": "Change the server port in configuration or ensure no other service is running on the same port."
          }
        ]
      },
      "references": {
        "official_docs": "https://micronaut.io/documentation.html",
        "github": "https://github.com/micronaut-projects/micronaut-core"
      }
    },
    {
      "id": "quarkus",
      "name": "Quarkus",
      "category": "Web",
      "description": "Quarkus is a Kubernetes-native Java framework designed for building cloud-native, reactive, and serverless applications with fast startup times and low memory footprint.",
      "story": "Quarkus was created to optimize Java for containerized environments and serverless deployments. It leverages compile-time boot, GraalVM native image support, and reactive programming to provide a high-performance and developer-friendly framework for modern applications.",
      "installation": {
        "maven": "Add io.quarkus:quarkus-bom and required extensions in pom.xml",
        "gradle": "Add implementation platform('io.quarkus:quarkus-bom:3.3.0.Final') and dependencies like implementation 'io.quarkus:quarkus-resteasy'"
      },
      "usage": {
        "overview": "Quarkus allows building REST APIs, reactive services, microservices, and serverless applications. It provides seamless integration with Hibernate, JPA, messaging systems, and cloud-native features, with support for reactive and imperative programming models.",
        "basic_examples": [
          {
            "title": "Creating a simple REST endpoint",
            "code": "import jakarta.ws.rs.*;\nimport jakarta.ws.rs.core.MediaType;\n\n@Path(\"/hello\")\npublic class HelloResource {\n    @GET\n    @Produces(MediaType.TEXT_PLAIN)\n    public String hello() {\n        return \"Hello Quarkus!\";\n    }\n}",
            "explanation": "Defines a basic REST endpoint that responds with 'Hello Quarkus!' on GET requests to `/hello`."
          },
          {
            "title": "Starting a Quarkus application",
            "code": "import io.quarkus.runtime.Quarkus;\nimport io.quarkus.runtime.annotations.QuarkusMain;\n\n@QuarkusMain\npublic class MainApp {\n    public static void main(String... args) {\n        Quarkus.run(args);\n    }\n}",
            "explanation": "Bootstraps a Quarkus application using the main method."
          }
        ],
        "advanced_examples": [
          {
            "title": "Dependency Injection",
            "code": "import jakarta.inject.Inject;\nimport jakarta.inject.Singleton;\n\n@Singleton\npublic class MyService {\n    public String getMessage() { return \"Service Message\"; }\n}\n\n@Path(\"/service\")\npublic class ServiceResource {\n    @Inject\n    MyService myService;\n\n    @GET\n    public String message() {\n        return myService.getMessage();\n    }\n}",
            "explanation": "Demonstrates injecting a service into a REST resource using Quarkus and Jakarta DI."
          },
          {
            "title": "Reactive REST endpoint with Mutiny",
            "code": "import io.smallrye.mutiny.Uni;\nimport jakarta.ws.rs.*;\nimport jakarta.ws.rs.core.MediaType;\n\n@Path(\"/reactive\")\npublic class ReactiveResource {\n    @GET\n    @Produces(MediaType.TEXT_PLAIN)\n    public Uni<String> hello() {\n        return Uni.createFrom().item(\"Hello Reactive Quarkus!\");\n    }\n}",
            "explanation": "Defines a reactive REST endpoint using Mutiny for asynchronous, non-blocking responses."
          },
          {
            "title": "Using Hibernate ORM with Panache",
            "code": "import io.quarkus.hibernate.orm.panache.PanacheEntity;\nimport jakarta.persistence.Entity;\n\n@Entity\npublic class Person extends PanacheEntity {\n    public String name;\n    public int age;\n}",
            "explanation": "Defines a simple entity with Quarkus Panache for ORM support with minimal boilerplate."
          },
          {
            "title": "Configuration properties",
            "code": "import io.quarkus.arc.config.ConfigProperties;\n\n@ConfigProperties(prefix=\"app\")\npublic class AppConfig {\n    public String name;\n}",
            "explanation": "Maps configuration properties from application.properties or application.yml into a Java class."
          }
        ],
        "best_practices": [
          "Use reactive programming with Mutiny for high-performance non-blocking services.",
          "Leverage Panache for simpler and efficient ORM operations.",
          "Externalize configuration and use type-safe config classes.",
          "Organize code with REST resources, services, and entities for modularity.",
          "Integrate Quarkus with CI/CD pipelines for containerized deployments."
        ],
        "error_handling": [
          {
            "error": "Port already in use",
            "solution": "Change the HTTP port in application.properties or ensure no other service is running on the same port."
          },
          {
            "error": "Dependency injection failure",
            "solution": "Check for missing beans, circular dependencies, or misconfigured @Inject annotations."
          },
          {
            "error": "GraalVM native image build failure",
            "solution": "Ensure all reflection and dynamic proxies are properly registered or use Quarkus native image extensions."
          }
        ]
      },
      "references": {
        "official_docs": "https://quarkus.io/guides/",
        "github": "https://github.com/quarkusio/quarkus"
      }
    },
    {
      "id": "kafka",
      "name": "Apache Kafka",
      "category": "Data",
      "description": "Apache Kafka is a distributed streaming platform used for building real-time data pipelines and streaming applications. It provides high-throughput, fault-tolerant, and scalable messaging between producers and consumers.",
      "story": "Kafka was originally developed at LinkedIn to handle real-time activity stream data and later became an open-source project under the Apache Software Foundation. It enables applications to process and react to streams of events efficiently and reliably.",
      "installation": {
        "maven": "Add org.apache.kafka:kafka-clients dependency in pom.xml",
        "gradle": "Add implementation 'org.apache.kafka:kafka-clients:3.6.1' in build.gradle"
      },
      "usage": {
        "overview": "Kafka allows developers to produce and consume messages to topics, stream processing using Kafka Streams, and integrate with other systems using Kafka Connect. It supports distributed, fault-tolerant, and scalable messaging architecture.",
        "basic_examples": [
          {
            "title": "Creating a Kafka producer",
            "code": "import org.apache.kafka.clients.producer.*;\nimport java.util.Properties;\n\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\nKafkaProducer<String, String> producer = new KafkaProducer<>(props);\nproducer.send(new ProducerRecord<>(\"test-topic\", \"key1\", \"Hello Kafka\"));\nproducer.close();",
            "explanation": "Creates a Kafka producer and sends a simple message to a topic."
          },
          {
            "title": "Creating a Kafka consumer",
            "code": "import org.apache.kafka.clients.consumer.*;\nimport java.util.*;\n\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test-group\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"test-topic\"));\nwhile(true) {\n    for (ConsumerRecord<String, String> record : consumer.poll(Duration.ofMillis(100))) {\n        System.out.println(\"Received: \" + record.value());\n    }\n}",
            "explanation": "Creates a Kafka consumer that subscribes to a topic and continuously polls for messages."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Kafka Streams",
            "code": "import org.apache.kafka.streams.*;\nimport org.apache.kafka.streams.kstream.*;\n\nProperties props = new Properties();\nprops.put(StreamsConfig.APPLICATION_ID_CONFIG, \"streams-app\");\nprops.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nStreamsBuilder builder = new StreamsBuilder();\nKStream<String, String> source = builder.stream(\"input-topic\");\nsource.mapValues(value -> value.toUpperCase()).to(\"output-topic\");\nKafkaStreams streams = new KafkaStreams(builder.build(), props);\nstreams.start();",
            "explanation": "Demonstrates a simple Kafka Streams application that transforms messages to uppercase and writes to another topic."
          },
          {
            "title": "Configuring partitions and keys",
            "code": "producer.send(new ProducerRecord<>(\"test-topic\", \"key1\", \"Message 1\"));\nproducer.send(new ProducerRecord<>(\"test-topic\", \"key2\", \"Message 2\"));",
            "explanation": "Specifies keys to control message partitioning for ordered processing per key."
          },
          {
            "title": "Using consumer groups",
            "code": "// Multiple consumers in the same group share messages from partitions, enabling parallel processing.",
            "explanation": "Kafka allows scaling consumption by adding consumers to a group; messages are distributed across group members."
          },
          {
            "title": "Handling offsets",
            "code": "consumer.commitSync();",
            "explanation": "Manually commit offsets to track processed messages and ensure fault-tolerance."
          }
        ],
        "best_practices": [
          "Use appropriate key selection to control partitioning and ordering.",
          "Configure producer retries and acknowledgments for reliability.",
          "Use consumer groups for scaling processing.",
          "Monitor consumer lag to detect processing bottlenecks.",
          "Leverage Kafka Streams for complex transformations and stateful processing."
        ],
        "error_handling": [
          {
            "error": "TimeoutException",
            "solution": "Occurs when the producer cannot send a message in time. Check broker availability and network connectivity."
          },
          {
            "error": "SerializationException",
            "solution": "Ensure that the key and value serializers/deserializers match the data types."
          },
          {
            "error": "GroupRebalanceException",
            "solution": "Occurs when consumers in a group are rebalancing. Handle gracefully in the consumer application."
          }
        ]
      },
      "references": {
        "official_docs": "https://kafka.apache.org/documentation/",
        "github": "https://github.com/apache/kafka"
      }
    },
    {
      "id": "netty",
      "name": "Netty",
      "category": "Web",
      "description": "Netty is an asynchronous, event-driven network application framework for rapid development of maintainable high-performance protocol servers and clients.",
      "story": "Netty was created to simplify the development of scalable and high-performance network applications in Java. It abstracts low-level I/O operations, providing an easy-to-use API for TCP/UDP protocols and enabling event-driven architectures.",
      "installation": {
        "maven": "Add io.netty:netty-all dependency in pom.xml",
        "gradle": "Add implementation 'io.netty:netty-all:4.1.94.Final' in build.gradle"
      },
      "usage": {
        "overview": "Netty provides abstractions for building servers and clients, handling connections, pipelines, codecs, and event-driven processing. It supports TCP, UDP, HTTP, WebSockets, and custom protocols.",
        "basic_examples": [
          {
            "title": "Creating a simple TCP server",
            "code": "import io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.*;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\n\npublic class SimpleServer {\n    public static void main(String[] args) throws Exception {\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup();\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n            b.group(bossGroup, workerGroup)\n             .channel(NioServerSocketChannel.class)\n             .childHandler(new ChannelInitializer<Channel>() {\n                 @Override\n                 protected void initChannel(Channel ch) {\n                     ch.pipeline().addLast(new SimpleServerHandler());\n                 }\n             });\n            ChannelFuture f = b.bind(8080).sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}",
            "explanation": "Sets up a simple TCP server on port 8080 using Netty with a handler for incoming connections."
          },
          {
            "title": "Creating a simple TCP client",
            "code": "import io.netty.bootstrap.Bootstrap;\nimport io.netty.channel.*;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.nio.NioSocketChannel;\n\npublic class SimpleClient {\n    public static void main(String[] args) throws Exception {\n        EventLoopGroup group = new NioEventLoopGroup();\n        try {\n            Bootstrap b = new Bootstrap();\n            b.group(group)\n             .channel(NioSocketChannel.class)\n             .handler(new ChannelInitializer<Channel>() {\n                 @Override\n                 protected void initChannel(Channel ch) {\n                     ch.pipeline().addLast(new SimpleClientHandler());\n                 }\n             });\n            ChannelFuture f = b.connect(\"localhost\", 8080).sync();\n            f.channel().closeFuture().sync();\n        } finally {\n            group.shutdownGracefully();\n        }\n    }\n}",
            "explanation": "Creates a simple TCP client connecting to a server on localhost:8080."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using pipeline and handlers",
            "code": "ch.pipeline().addLast(new StringDecoder(), new StringEncoder(), new CustomHandler());",
            "explanation": "Configures a pipeline with decoders, encoders, and custom handlers for processing messages."
          },
          {
            "title": "Handling WebSocket connections",
            "code": "// Add WebSocketServerProtocolHandler to pipeline for WebSocket upgrade and frame handling",
            "explanation": "Demonstrates handling WebSocket connections and frames using Nettyâ€™s built-in WebSocket support."
          },
          {
            "title": "Event-driven architecture",
            "code": "channel.read();\nchannel.writeAndFlush(msg);",
            "explanation": "Illustrates asynchronous read/write operations to handle high concurrency efficiently."
          },
          {
            "title": "TLS/SSL support",
            "code": "SslContext sslCtx = SslContextBuilder.forServer(certFile, keyFile).build();\npipeline.addLast(sslCtx.newHandler(ch.alloc()));",
            "explanation": "Adds SSL/TLS encryption to a Netty pipeline for secure communication."
          }
        ],
        "best_practices": [
          "Use separate EventLoopGroups for boss and worker threads to handle connections and I/O efficiently.",
          "Leverage the pipeline for modular and reusable handlers.",
          "Avoid blocking operations in event handlers; delegate to separate threads if necessary.",
          "Use proper resource cleanup to prevent memory leaks and dangling connections.",
          "Monitor and tune thread pools and buffers for high-performance network applications."
        ],
        "error_handling": [
          {
            "error": "ChannelException",
            "solution": "Occurs when there is a problem binding or connecting a channel. Verify port availability and network configuration."
          },
          {
            "error": "Decoder/Encoder errors",
            "solution": "Ensure message formats match decoders/encoders in the pipeline."
          },
          {
            "error": "OutOfMemoryError",
            "solution": "Tune Netty buffer allocation and release resources properly to avoid memory leaks."
          }
        ]
      },
      "references": {
        "official_docs": "https://netty.io/wiki/user-guide-for-4.x.html",
        "github": "https://github.com/netty/netty"
      }
    },
    {
      "id": "jersey",
      "name": "Jersey",
      "category": "Web",
      "description": "Jersey is the reference implementation of JAX-RS (Java API for RESTful Web Services) for building RESTful web services in Java. It simplifies creating web services with annotations, dependency injection, and automatic JSON/XML support.",
      "story": "Jersey was developed by Oracle (originally as part of GlassFish) to provide a standard, annotation-driven framework for creating RESTful web services on the Java platform. It supports both client-side and server-side APIs, integrates with CDI (Contexts and Dependency Injection), and provides filters, exception handling, and advanced features such as asynchronous processing. Over the years, Jersey has become a widely used framework in enterprise and microservice applications due to its adherence to standards and ease of integration.",
      "installation": {
        "maven": "Add the following dependencies in your pom.xml:\n<dependency>\n  <groupId>org.glassfish.jersey.core</groupId>\n  <artifactId>jersey-server</artifactId>\n  <version>3.2.0</version>\n</dependency>\n<dependency>\n  <groupId>org.glassfish.jersey.containers</groupId>\n  <artifactId>jersey-container-servlet</artifactId>\n  <version>3.2.0</version>\n</dependency>\n<dependency>\n  <groupId>org.glassfish.jersey.media</groupId>\n  <artifactId>jersey-media-json-binding</artifactId>\n  <version>3.2.0</version>\n</dependency>",
        "gradle": "Add the following dependencies in build.gradle:\nimplementation 'org.glassfish.jersey.core:jersey-server:3.2.0'\nimplementation 'org.glassfish.jersey.containers:jersey-container-servlet:3.2.0'\nimplementation 'org.glassfish.jersey.media:jersey-media-json-binding:3.2.0'"
      },
      "usage": {
        "overview": "Jersey allows you to define REST endpoints using annotations such as @Path, @GET, @POST, @PUT, @DELETE, and @Produces/@Consumes for content negotiation. It supports JSON/XML serialization, request/response filtering, exception mapping, dependency injection via CDI, asynchronous endpoints, and client-side APIs for consuming other REST services.",
        "basic_examples": [
          {
            "title": "Simple REST GET endpoint",
            "code": "import jakarta.ws.rs.GET;\nimport jakarta.ws.rs.Path;\nimport jakarta.ws.rs.Produces;\nimport jakarta.ws.rs.core.MediaType;\n\n@Path(\"/hello\")\npublic class HelloResource {\n    @GET\n    @Produces(MediaType.TEXT_PLAIN)\n    public String hello() {\n        return \"Hello Jersey!\";\n    }\n}",
            "explanation": "Defines a basic GET endpoint that returns a plain text response at the path `/hello`."
          },
          {
            "title": "POST endpoint with JSON input",
            "code": "import jakarta.ws.rs.POST;\nimport jakarta.ws.rs.Path;\nimport jakarta.ws.rs.Consumes;\nimport jakarta.ws.rs.Produces;\nimport jakarta.ws.rs.core.MediaType;\n\n@Path(\"/users\")\npublic class UserResource {\n    @POST\n    @Consumes(MediaType.APPLICATION_JSON)\n    @Produces(MediaType.APPLICATION_JSON)\n    public User createUser(User user) {\n        // save user to database or service\n        return user;\n    }\n}",
            "explanation": "Defines a POST endpoint that accepts a JSON object, processes it, and returns a JSON response."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Dependency Injection (CDI)",
            "code": "import jakarta.inject.Inject;\nimport jakarta.ws.rs.GET;\nimport jakarta.ws.rs.Path;\n\n@Path(\"/service\")\npublic class ServiceResource {\n    @Inject\n    MyService myService;\n\n    @GET\n    public String getMessage() {\n        return myService.getMessage();\n    }\n}",
            "explanation": "Demonstrates injecting a service bean into a Jersey resource using CDI."
          },
          {
            "title": "Exception Mapping",
            "code": "import jakarta.ws.rs.ext.ExceptionMapper;\nimport jakarta.ws.rs.ext.Provider;\nimport jakarta.ws.rs.core.Response;\n\n@Provider\npublic class GenericExceptionMapper implements ExceptionMapper<Exception> {\n    @Override\n    public Response toResponse(Exception exception) {\n        return Response.status(Response.Status.INTERNAL_SERVER_ERROR)\n                       .entity(exception.getMessage())\n                       .build();\n    }\n}",
            "explanation": "Custom exception mapper that catches all exceptions thrown by endpoints and returns a structured HTTP response."
          },
          {
            "title": "Filtering Requests and Responses",
            "code": "import jakarta.ws.rs.container.ContainerRequestContext;\nimport jakarta.ws.rs.container.ContainerRequestFilter;\nimport jakarta.ws.rs.ext.Provider;\n\n@Provider\npublic class LoggingFilter implements ContainerRequestFilter {\n    @Override\n    public void filter(ContainerRequestContext requestContext) {\n        System.out.println(\"Incoming request: \" + requestContext.getUriInfo().getRequestUri());\n    }\n}",
            "explanation": "Implements a request filter to log all incoming requests."
          },
          {
            "title": "Asynchronous Endpoint",
            "code": "import jakarta.ws.rs.GET;\nimport jakarta.ws.rs.Path;\nimport jakarta.ws.rs.container.AsyncResponse;\nimport jakarta.ws.rs.container.Suspended;\nimport java.util.concurrent.CompletableFuture;\n\n@Path(\"/async\")\npublic class AsyncResource {\n    @GET\n    public void asyncHello(@Suspended AsyncResponse response) {\n        CompletableFuture.supplyAsync(() -> \"Hello Async Jersey!\")\n                         .thenAccept(response::resume);\n    }\n}",
            "explanation": "Demonstrates asynchronous processing with @Suspended AsyncResponse and CompletableFuture."
          }
        ],
        "best_practices": [
          "Use standard JAX-RS annotations for REST endpoints to maintain portability.",
          "Leverage CDI for dependency injection and modular design.",
          "Use ExceptionMappers to handle errors consistently.",
          "Use Filters and Interceptors for cross-cutting concerns like logging, authentication, and metrics.",
          "Separate resource classes, services, and domain models for maintainable architecture."
        ],
        "error_handling": [
          {
            "error": "WebApplicationException",
            "solution": "Thrown when you want to return a specific HTTP status code. Use proper response codes and messages."
          },
          {
            "error": "BadRequestException",
            "solution": "Thrown when the request cannot be processed due to client error (400). Validate inputs before processing."
          },
          {
            "error": "ProcessingException",
            "solution": "Occurs during client-side API calls. Check network connectivity and request configuration."
          }
        ]
      },
      "references": {
        "official_docs": "https://eclipse-ee4j.github.io/jersey/",
        "github": "https://github.com/eclipse-ee4j/jersey"
      }
    },
    {
      "id": "resteasy",
      "name": "RestEasy",
      "category": "Web",
      "description": "RestEasy is a JAX-RS implementation for building RESTful web services in Java. It provides tools to create REST APIs easily with annotations, dependency injection, exception handling, and integrates well with JBoss/WildFly or standalone servlet containers.",
      "story": "RestEasy was developed by JBoss to provide a lightweight, flexible, and robust REST framework for Java applications. It fully implements the JAX-RS specification and offers extensions for client and server APIs, asynchronous processing, filters, interceptors, and integration with CDI and EJB. RestEasy is widely used in enterprise Java applications, microservices, and projects requiring high-performance REST APIs.",
      "installation": {
        "maven": "Add the following dependency in pom.xml:\n<dependency>\n  <groupId>org.jboss.resteasy</groupId>\n  <artifactId>resteasy-jaxrs</artifactId>\n  <version>6.2.4.Final</version>\n</dependency>",
        "gradle": "Add the following dependency in build.gradle:\nimplementation 'org.jboss.resteasy:resteasy-jaxrs:6.2.4.Final'"
      },
      "usage": {
        "overview": "RestEasy allows developers to define REST endpoints using JAX-RS annotations like @Path, @GET, @POST, @PUT, @DELETE, and supports JSON/XML serialization, request/response filters, exception mapping, and asynchronous endpoints. It also provides a client API for consuming REST services programmatically.",
        "basic_examples": [
          {
            "title": "Simple GET endpoint",
            "code": "import jakarta.ws.rs.GET;\nimport jakarta.ws.rs.Path;\nimport jakarta.ws.rs.Produces;\nimport jakarta.ws.rs.core.MediaType;\n\n@Path(\"/hello\")\npublic class HelloResource {\n    @GET\n    @Produces(MediaType.TEXT_PLAIN)\n    public String hello() {\n        return \"Hello RestEasy!\";\n    }\n}",
            "explanation": "Defines a basic GET endpoint at `/hello` that returns a plain text response."
          },
          {
            "title": "POST endpoint with JSON input",
            "code": "import jakarta.ws.rs.POST;\nimport jakarta.ws.rs.Path;\nimport jakarta.ws.rs.Consumes;\nimport jakarta.ws.rs.Produces;\nimport jakarta.ws.rs.core.MediaType;\n\n@Path(\"/users\")\npublic class UserResource {\n    @POST\n    @Consumes(MediaType.APPLICATION_JSON)\n    @Produces(MediaType.APPLICATION_JSON)\n    public User createUser(User user) {\n        // Process and return user\n        return user;\n    }\n}",
            "explanation": "Defines a POST endpoint that accepts a JSON object, processes it, and returns a JSON response."
          }
        ],
        "advanced_examples": [
          {
            "title": "Exception Mapper",
            "code": "import jakarta.ws.rs.ext.ExceptionMapper;\nimport jakarta.ws.rs.ext.Provider;\nimport jakarta.ws.rs.core.Response;\n\n@Provider\npublic class GenericExceptionMapper implements ExceptionMapper<Exception> {\n    @Override\n    public Response toResponse(Exception exception) {\n        return Response.status(Response.Status.INTERNAL_SERVER_ERROR)\n                       .entity(exception.getMessage())\n                       .build();\n    }\n}",
            "explanation": "Maps exceptions globally and returns a structured HTTP response."
          },
          {
            "title": "Request/Response Filter",
            "code": "import jakarta.ws.rs.container.ContainerRequestContext;\nimport jakarta.ws.rs.container.ContainerRequestFilter;\nimport jakarta.ws.rs.ext.Provider;\n\n@Provider\npublic class LoggingFilter implements ContainerRequestFilter {\n    @Override\n    public void filter(ContainerRequestContext requestContext) {\n        System.out.println(\"Incoming request: \" + requestContext.getUriInfo().getRequestUri());\n    }\n}",
            "explanation": "Implements a request filter that logs incoming requests."
          },
          {
            "title": "Asynchronous Endpoint",
            "code": "import jakarta.ws.rs.GET;\nimport jakarta.ws.rs.Path;\nimport jakarta.ws.rs.container.AsyncResponse;\nimport jakarta.ws.rs.container.Suspended;\nimport java.util.concurrent.CompletableFuture;\n\n@Path(\"/async\")\npublic class AsyncResource {\n    @GET\n    public void asyncHello(@Suspended AsyncResponse response) {\n        CompletableFuture.supplyAsync(() -> \"Hello Async RestEasy!\")\n                         .thenAccept(response::resume);\n    }\n}",
            "explanation": "Demonstrates asynchronous request processing using @Suspended AsyncResponse."
          },
          {
            "title": "Client API Example",
            "code": "import org.jboss.resteasy.client.jaxrs.ResteasyClient;\nimport org.jboss.resteasy.client.jaxrs.ResteasyClientBuilder;\nimport org.jboss.resteasy.client.jaxrs.ResteasyWebTarget;\n\nResteasyClient client = new ResteasyClientBuilder().build();\nResteasyWebTarget target = client.target(\"http://localhost:8080/hello\");\nString response = target.request().get(String.class);\nSystem.out.println(response);",
            "explanation": "Shows how to use RestEasy client to send a GET request to a REST service."
          }
        ],
        "best_practices": [
          "Organize resource classes, DTOs, and services for maintainable code structure.",
          "Use ExceptionMappers for consistent error handling.",
          "Use Filters and Interceptors for cross-cutting concerns like logging, authentication, and metrics.",
          "Leverage CDI for dependency injection and modular design.",
          "Document your endpoints clearly using OpenAPI or Swagger integration."
        ],
        "error_handling": [
          {
            "error": "NotFoundException",
            "solution": "Thrown when a requested resource path does not exist. Ensure correct @Path mappings."
          },
          {
            "error": "BadRequestException",
            "solution": "Thrown when the client sends invalid data (HTTP 400). Validate input properly."
          },
          {
            "error": "ProcessingException",
            "solution": "Occurs during client-side API calls, often due to network issues or misconfigured requests."
          }
        ]
      },
      "references": {
        "official_docs": "https://resteasy.github.io/",
        "github": "https://github.com/resteasy/Resteasy"
      }
    },
    {
      "id": "cxf",
      "name": "Apache CXF",
      "category": "Web",
      "description": "Apache CXF is a framework for building robust web services in Java. It supports both RESTful (JAX-RS) and SOAP-based (JAX-WS) services, providing tools for service creation, client generation, and integration with various transports and data bindings.",
      "story": "Apache CXF was developed to simplify building and deploying web services in Java. It offers a flexible architecture supporting multiple protocols (HTTP, JMS, TCP), pluggable data bindings (JAXB, JSON, XML), and integration with Spring and CDI. CXF is widely used in enterprise applications that require interoperability, SOAP-based services, or hybrid REST/SOAP architectures.",
      "installation": {
        "maven": "Add dependencies in pom.xml:\n<dependency>\n  <groupId>org.apache.cxf</groupId>\n  <artifactId>cxf-rt-frontend-jaxrs</artifactId>\n  <version>3.6.1</version>\n</dependency>\n<dependency>\n  <groupId>org.apache.cxf</groupId>\n  <artifactId>cxf-rt-transports-http</artifactId>\n  <version>3.6.1</version>\n</dependency>",
        "gradle": "Add dependencies in build.gradle:\nimplementation 'org.apache.cxf:cxf-rt-frontend-jaxrs:3.6.1'\nimplementation 'org.apache.cxf:cxf-rt-transports-http:3.6.1'"
      },
      "usage": {
        "overview": "CXF allows developers to create REST or SOAP services using annotations, XML configuration, or Spring integration. It supports automatic WSDL generation for SOAP, JSON/XML marshalling for REST, exception handling, interceptors, and client APIs for consuming services.",
        "basic_examples": [
          {
            "title": "Simple JAX-RS REST service",
            "code": "import jakarta.ws.rs.GET;\nimport jakarta.ws.rs.Path;\nimport jakarta.ws.rs.Produces;\nimport jakarta.ws.rs.core.MediaType;\n\n@Path(\"/hello\")\npublic class HelloService {\n    @GET\n    @Produces(MediaType.TEXT_PLAIN)\n    public String hello() {\n        return \"Hello Apache CXF!\";\n    }\n}",
            "explanation": "Defines a basic GET endpoint at `/hello` that returns plain text."
          },
          {
            "title": "Creating a SOAP endpoint",
            "code": "import jakarta.jws.WebService;\n@WebService(endpointInterface = \"com.example.HelloService\")\npublic class HelloServiceImpl implements HelloService {\n    public String sayHello(String name) {\n        return \"Hello, \" + name;\n    }\n}",
            "explanation": "Defines a simple SOAP web service using JAX-WS annotations."
          }
        ],
        "advanced_examples": [
          {
            "title": "Publishing REST service programmatically",
            "code": "import org.apache.cxf.jaxrs.JAXRSServerFactoryBean;\n\nJAXRSServerFactoryBean factory = new JAXRSServerFactoryBean();\nfactory.setResourceClasses(HelloService.class);\nfactory.setAddress(\"http://localhost:8080/\");\nfactory.create();",
            "explanation": "Shows how to publish a REST service programmatically using CXF."
          },
          {
            "title": "SOAP client example",
            "code": "import org.apache.cxf.jaxws.JaxWsProxyFactoryBean;\n\nJaxWsProxyFactoryBean factory = new JaxWsProxyFactoryBean();\nfactory.setServiceClass(HelloService.class);\nfactory.setAddress(\"http://localhost:8080/HelloService\");\nHelloService client = (HelloService) factory.create();\nString response = client.sayHello(\"Alice\");",
            "explanation": "Creates a SOAP client for a CXF service using JaxWsProxyFactoryBean."
          },
          {
            "title": "Using CXF interceptors",
            "code": "import org.apache.cxf.interceptor.LoggingInInterceptor;\nimport org.apache.cxf.interceptor.LoggingOutInterceptor;\nfactory.getInInterceptors().add(new LoggingInInterceptor());\nfactory.getOutInterceptors().add(new LoggingOutInterceptor());",
            "explanation": "Adds logging interceptors to log inbound and outbound messages for debugging."
          },
          {
            "title": "Exception handling in REST",
            "code": "import jakarta.ws.rs.ext.ExceptionMapper;\nimport jakarta.ws.rs.ext.Provider;\nimport jakarta.ws.rs.core.Response;\n\n@Provider\npublic class GenericExceptionMapper implements ExceptionMapper<Exception> {\n    public Response toResponse(Exception e) {\n        return Response.status(500).entity(e.getMessage()).build();\n    }\n}",
            "explanation": "Maps exceptions to structured HTTP responses for REST endpoints."
          }
        ],
        "best_practices": [
          "Use annotations (@Path, @GET, @POST, @WebService) for clarity and standardization.",
          "Leverage CXF interceptors for cross-cutting concerns like logging, metrics, and security.",
          "Separate service interfaces and implementations for maintainability.",
          "Use Spring or CDI integration for dependency injection.",
          "Document REST endpoints using OpenAPI and SOAP services using WSDL."
        ],
        "error_handling": [
          {
            "error": "WebApplicationException",
            "solution": "Use for returning specific HTTP status codes in REST endpoints."
          },
          {
            "error": "SOAPFaultException",
            "solution": "Thrown when a SOAP request fails. Inspect fault code and message for debugging."
          },
          {
            "error": "EndpointException",
            "solution": "Occurs when the service endpoint fails to start or bind. Verify port availability and configuration."
          }
        ]
      },
      "references": {
        "official_docs": "https://cxf.apache.org/",
        "github": "https://github.com/apache/cxf"
      }
    },
    {
      "id": "mybatis",
      "name": "MyBatis",
      "category": "Database/ORM",
      "description": "MyBatis is a persistence framework that simplifies working with relational databases in Java. Unlike full ORM frameworks, it focuses on mapping SQL queries to Java objects, giving developers control over SQL while reducing boilerplate code.",
      "story": "MyBatis was created to provide a flexible persistence framework for Java applications that allows developers to write SQL directly while mapping results to Java objects. It emphasizes simplicity, maintainability, and performance. MyBatis is popular in enterprise applications where complex queries, stored procedures, or fine-grained control over SQL is required.",
      "installation": {
        "maven": "Add dependencies in pom.xml:\n<dependency>\n  <groupId>org.mybatis</groupId>\n  <artifactId>mybatis</artifactId>\n  <version>3.5.13</version>\n</dependency>\n<dependency>\n  <groupId>org.mybatis</groupId>\n  <artifactId>mybatis-spring</artifactId>\n  <version>2.0.11</version>\n</dependency>",
        "gradle": "Add dependencies in build.gradle:\nimplementation 'org.mybatis:mybatis:3.5.13'\nimplementation 'org.mybatis:mybatis-spring:2.0.11'"
      },
      "usage": {
        "overview": "MyBatis allows mapping SQL statements, stored procedures, and results to Java objects. You define mappers via XML or annotations, and the framework handles parameter substitution, result mapping, and caching. It integrates seamlessly with Spring for transaction management.",
        "basic_examples": [
          {
            "title": "Simple Mapper XML",
            "code": "<mapper namespace=\"com.example.UserMapper\">\n  <select id=\"getUser\" parameterType=\"int\" resultType=\"User\">\n    SELECT id, name, email FROM users WHERE id = #{id}\n  </select>\n</mapper>",
            "explanation": "Defines an XML mapper to fetch a User object by ID."
          },
          {
            "title": "Mapper Interface",
            "code": "public interface UserMapper {\n    User getUser(int id);\n}",
            "explanation": "Java interface matching the XML mapper to access database methods."
          }
        ],
        "advanced_examples": [
          {
            "title": "Annotation-based Mapper",
            "code": "import org.apache.ibatis.annotations.Select;\n\npublic interface UserMapper {\n    @Select(\"SELECT id, name, email FROM users WHERE id = #{id}\")\n    User getUser(int id);\n}",
            "explanation": "Defines the mapper using annotations instead of XML."
          },
          {
            "title": "Insert and Update",
            "code": "<insert id=\"insertUser\" parameterType=\"User\">\n  INSERT INTO users(name, email) VALUES(#{name}, #{email})\n</insert>\n<update id=\"updateUser\" parameterType=\"User\">\n  UPDATE users SET name=#{name}, email=#{email} WHERE id=#{id}\n</update>",
            "explanation": "Shows how to insert and update records using MyBatis XML mappers."
          },
          {
            "title": "Integration with Spring",
            "code": "@Configuration\n@MapperScan(\"com.example.mappers\")\npublic class MyBatisConfig {\n    @Bean\n    public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception {\n        SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean();\n        factoryBean.setDataSource(dataSource);\n        return factoryBean.getObject();\n    }\n}",
            "explanation": "Configures MyBatis with Spring Boot and enables automatic mapper scanning."
          },
          {
            "title": "Result Mapping for Nested Objects",
            "code": "<resultMap id=\"UserWithAddressMap\" type=\"User\">\n  <id property=\"id\" column=\"id\" />\n  <result property=\"name\" column=\"name\" />\n  <association property=\"address\" javaType=\"Address\">\n    <id property=\"id\" column=\"address_id\" />\n    <result property=\"city\" column=\"city\" />\n  </association>\n</resultMap>",
            "explanation": "Maps a nested Address object inside the User object using a resultMap."
          }
        ],
        "best_practices": [
          "Use XML or annotation mapping consistently throughout the project.",
          "Define reusable resultMaps for complex object mappings.",
          "Integrate with Spring for transaction management and dependency injection.",
          "Use caching wisely to improve performance for frequently accessed data.",
          "Write unit tests for mappers with an in-memory database like H2."
        ],
        "error_handling": [
          {
            "error": "BindingException",
            "solution": "Occurs when SQL parameters do not match the mapper method. Verify parameter names and types."
          },
          {
            "error": "PersistenceException",
            "solution": "General database error. Check SQL syntax, connection configuration, and transactions."
          },
          {
            "error": "TooManyResultsException",
            "solution": "Occurs when a query expected a single result but returned multiple. Adjust SQL or resultType accordingly."
          }
        ]
      },
      "references": {
        "official_docs": "https://mybatis.org/mybatis-3/",
        "github": "https://github.com/mybatis/mybatis-3"
      }
    },
    {
      "id": "jooq",
      "name": "jOOQ",
      "category": "Database/ORM",
      "description": "jOOQ (Java Object Oriented Querying) is a fluent API for typesafe SQL query construction in Java. It allows developers to write SQL in a natural, type-checked way while mapping results directly to Java objects, combining the flexibility of SQL with the safety of Java.",
      "story": "jOOQ was developed to bridge the gap between relational databases and Java by providing a domain-specific language for SQL. Unlike traditional ORM frameworks, jOOQ emphasizes writing actual SQL statements while ensuring compile-time safety, making it ideal for complex queries, reporting, and enterprise applications. jOOQ also provides code generation tools to generate Java classes from database schemas.",
      "installation": {
        "maven": "Add dependencies in pom.xml:\n<dependency>\n  <groupId>org.jooq</groupId>\n  <artifactId>jooq</artifactId>\n  <version>3.20.5</version>\n</dependency>\n<dependency>\n  <groupId>org.jooq</groupId>\n  <artifactId>jooq-meta</artifactId>\n  <version>3.20.5</version>\n</dependency>\n<dependency>\n  <groupId>org.jooq</groupId>\n  <artifactId>jooq-codegen</artifactId>\n  <version>3.20.5</version>\n</dependency>",
        "gradle": "Add dependencies in build.gradle:\nimplementation 'org.jooq:jooq:3.20.5'\nimplementation 'org.jooq:jooq-meta:3.20.5'\nimplementation 'org.jooq:jooq-codegen:3.20.5'"
      },
      "usage": {
        "overview": "jOOQ allows developers to build SQL queries using a fluent Java API. Queries are typesafe, and code generation ensures table and column references match the database schema. jOOQ supports SELECT, INSERT, UPDATE, DELETE, joins, transactions, and advanced SQL features like window functions and CTEs.",
        "basic_examples": [
          {
            "title": "Simple SELECT query",
            "code": "DSLContext create = DSL.using(connection, SQLDialect.POSTGRES);\nResult<Record> result = create.select().from(USERS).where(USERS.ID.eq(1)).fetch();\nfor (Record r : result) {\n    System.out.println(r.getValue(USERS.NAME));\n}",
            "explanation": "Fetches a user with ID 1 from the USERS table using jOOQâ€™s fluent API."
          },
          {
            "title": "INSERT example",
            "code": "create.insertInto(USERS)\n      .columns(USERS.NAME, USERS.EMAIL)\n      .values(\"Alice\", \"alice@example.com\")\n      .execute();",
            "explanation": "Inserts a new record into the USERS table."
          }
        ],
        "advanced_examples": [
          {
            "title": "UPDATE with condition",
            "code": "create.update(USERS)\n      .set(USERS.EMAIL, \"newemail@example.com\")\n      .where(USERS.ID.eq(1))\n      .execute();",
            "explanation": "Updates the email of the user with ID 1."
          },
          {
            "title": "JOIN query",
            "code": "Result<Record> result = create.select()\n    .from(USERS)\n    .join(ORDERS).on(USERS.ID.eq(ORDERS.USER_ID))\n    .fetch();",
            "explanation": "Performs an inner join between USERS and ORDERS tables."
          },
          {
            "title": "Transactions",
            "code": "create.transaction(configuration -> {\n    DSLContext ctx = DSL.using(configuration);\n    ctx.insertInto(USERS).columns(USERS.NAME).values(\"Bob\").execute();\n    ctx.insertInto(ORDERS).columns(ORDERS.USER_ID, ORDERS.AMOUNT).values(1, 100).execute();\n});",
            "explanation": "Executes multiple queries in a single transaction."
          },
          {
            "title": "Code generation from schema",
            "code": "org.jooq.codegen.GenerationTool.generate(new Configuration()\n    .withJdbc(new Jdbc().withDriver(\"org.postgresql.Driver\")\n                     .withUrl(\"jdbc:postgresql://localhost:5432/mydb\")\n                     .withUser(\"user\")\n                     .withPassword(\"pass\"))\n    .withGenerator(new Generator()\n        .withDatabase(new Database().withName(\"org.jooq.meta.postgres.PostgresDatabase\"))\n        .withTarget(new Target().withPackageName(\"com.example.jooq\")\n                                  .withDirectory(\"src/main/java\"))));",
            "explanation": "Generates Java classes for database tables for type-safe queries."
          }
        ],
        "best_practices": [
          "Use code generation for compile-time type safety.",
          "Use DSLContext for all queries instead of raw SQL.",
          "Keep complex queries readable with method chaining.",
          "Use transactions for multi-step operations to ensure data integrity.",
          "Combine jOOQ with Spring Boot for easier dependency injection and transaction management."
        ],
        "error_handling": [
          {
            "error": "DataAccessException",
            "solution": "Occurs for database access errors. Check SQL syntax, connection, and transaction configuration."
          },
          {
            "error": "InvalidResultException",
            "solution": "Occurs when result mapping fails. Ensure column names/types match the generated Java classes."
          },
          {
            "error": "SQLDialectNotSupportedException",
            "solution": "Ensure the correct SQLDialect is configured for your database."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.jooq.org/doc/latest/",
        "github": "https://github.com/jOOQ/jOOQ"
      }
    },
    {
      "id": "guava",
      "name": "Guava",
      "category": "Utilities/Collections",
      "description": "Guava is a set of core Java libraries developed by Google. It provides powerful utilities for collections, caching, concurrency, string manipulation, I/O, hashing, functional programming, and more, enhancing productivity and code readability.",
      "story": "Guava was created by Google to simplify common programming tasks in Java and to provide a high-quality, well-tested library for developers. It extends the capabilities of the standard Java library with immutable collections, advanced collection utilities, caching frameworks, functional idioms, and helper classes for strings, I/O, concurrency, and more. Guava is widely used in enterprise applications, open-source projects, and internal Google projects.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.google.guava</groupId>\n  <artifactId>guava</artifactId>\n  <version>32.1.2-jre</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'com.google.guava:guava:32.1.2-jre'"
      },
      "usage": {
        "overview": "Guava provides utilities for collections, caching, functional programming, string operations, concurrency, hashing, I/O, and more. Key features include immutable collections, Multimap, BiMap, Range, caching with CacheBuilder, and functional idioms using Predicates, Functions, and Suppliers.",
        "basic_examples": [
          {
            "title": "Immutable List",
            "code": "import com.google.common.collect.ImmutableList;\n\nImmutableList<String> list = ImmutableList.of(\"A\", \"B\", \"C\");\nSystem.out.println(list);",
            "explanation": "Creates an immutable list that cannot be modified after creation."
          },
          {
            "title": "Multimap usage",
            "code": "import com.google.common.collect.ArrayListMultimap;\nimport com.google.common.collect.Multimap;\n\nMultimap<String, String> multimap = ArrayListMultimap.create();\nmultimap.put(\"fruit\", \"apple\");\nmultimap.put(\"fruit\", \"banana\");\nSystem.out.println(multimap.get(\"fruit\"));",
            "explanation": "Stores multiple values for a single key using a Multimap."
          }
        ],
        "advanced_examples": [
          {
            "title": "BiMap for bidirectional mapping",
            "code": "import com.google.common.collect.BiMap;\nimport com.google.common.collect.HashBiMap;\n\nBiMap<Integer, String> bimap = HashBiMap.create();\nbimap.put(1, \"one\");\nbimap.put(2, \"two\");\nSystem.out.println(bimap.inverse().get(\"one\"));",
            "explanation": "Allows bidirectional lookup between keys and values."
          },
          {
            "title": "Caching with CacheBuilder",
            "code": "import com.google.common.cache.Cache;\nimport com.google.common.cache.CacheBuilder;\n\nCache<String, String> cache = CacheBuilder.newBuilder()\n    .maximumSize(100)\n    .build();\ncache.put(\"key1\", \"value1\");\nSystem.out.println(cache.getIfPresent(\"key1\"));",
            "explanation": "Demonstrates in-memory caching with eviction policies using Guava Cache."
          },
          {
            "title": "String utilities",
            "code": "import com.google.common.base.Joiner;\nimport com.google.common.base.Splitter;\n\nString joined = Joiner.on(\", \").join(\"A\", \"B\", \"C\");\nIterable<String> split = Splitter.on(\",\").split(\"A,B,C\");\nSystem.out.println(joined);\nSystem.out.println(split);",
            "explanation": "Shows string joining and splitting utilities provided by Guava."
          },
          {
            "title": "Functional idioms",
            "code": "import com.google.common.base.Function;\nimport com.google.common.collect.Lists;\n\nList<String> strings = Lists.newArrayList(\"a\", \"b\", \"c\");\nList<Integer> lengths = Lists.transform(strings, (String s) -> s.length());\nSystem.out.println(lengths);",
            "explanation": "Applies a function to transform elements of a collection."
          },
          {
            "title": "Range usage",
            "code": "import com.google.common.collect.Range;\n\nRange<Integer> range = Range.closed(1, 10);\nSystem.out.println(range.contains(5));",
            "explanation": "Represents a range of values and checks if a number is within the range."
          }
        ],
        "best_practices": [
          "Use immutable collections for thread safety and readability.",
          "Leverage caching for expensive computations to improve performance.",
          "Use functional idioms (Predicates, Functions) to simplify collection transformations.",
          "Apply Guava utilities like Joiner, Splitter, and CharMatcher for clean string manipulation.",
          "Avoid overusing Guava when standard Java 8+ streams and collections are sufficient."
        ],
        "error_handling": [
          {
            "error": "UnsupportedOperationException",
            "solution": "Occurs when attempting to modify immutable collections. Always use ImmutableList/Set/Map appropriately."
          },
          {
            "error": "NullPointerException",
            "solution": "Guavaâ€™s immutable collections and utilities often disallow nulls. Check inputs before adding to collections."
          }
        ]
      },
      "references": {
        "official_docs": "https://guava.dev/",
        "github": "https://github.com/google/guava"
      }
    },
    {
      "id": "commons-lang",
      "name": "Apache Commons Lang",
      "category": "Utilities",
      "description": "Apache Commons Lang provides a host of helper utilities for the java.lang API, making everyday Java development easier. It includes functionality for String manipulation, object reflection, concurrency, number handling, date/time, and more.",
      "story": "Commons Lang was created to fill the gaps in the standard Java library by providing reusable, well-tested, and reliable utilities. It simplifies common tasks such as string manipulation, reflection, object comparison, and exception handling, improving productivity and code readability. It is widely used in enterprise Java applications and open-source projects.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.commons</groupId>\n  <artifactId>commons-lang3</artifactId>\n  <version>3.13.0</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'org.apache.commons:commons-lang3:3.13.0'"
      },
      "usage": {
        "overview": "Commons Lang offers utilities for String operations, Object utilities, Number utilities, Reflection, Builders, Random generation, concurrency helpers, and more. It reduces boilerplate and simplifies common coding patterns.",
        "basic_examples": [
          {
            "title": "StringUtils example",
            "code": "import org.apache.commons.lang3.StringUtils;\n\nString str = \"  Hello World  \";\nSystem.out.println(StringUtils.strip(str)); // Trims whitespace\nSystem.out.println(StringUtils.isEmpty(str));",
            "explanation": "Uses StringUtils to trim whitespace and check for empty strings."
          },
          {
            "title": "ObjectUtils example",
            "code": "import org.apache.commons.lang3.ObjectUtils;\n\nInteger result = ObjectUtils.defaultIfNull(null, 42);\nSystem.out.println(result);",
            "explanation": "Provides a default value when the object is null."
          }
        ],
        "advanced_examples": [
          {
            "title": "RandomStringUtils",
            "code": "import org.apache.commons.lang3.RandomStringUtils;\n\nString randomStr = RandomStringUtils.randomAlphanumeric(10);\nSystem.out.println(randomStr);",
            "explanation": "Generates a random alphanumeric string of length 10."
          },
          {
            "title": "ReflectionUtils",
            "code": "import org.apache.commons.lang3.reflect.FieldUtils;\n\nclass User { private String name; }\nUser user = new User();\nFieldUtils.writeField(user, \"name\", \"Alice\", true);\nSystem.out.println(FieldUtils.readField(user, \"name\", true));",
            "explanation": "Uses reflection to read and write private fields."
          },
          {
            "title": "Compare and Hash",
            "code": "import org.apache.commons.lang3.builder.EqualsBuilder;\nimport org.apache.commons.lang3.builder.HashCodeBuilder;\n\nclass User { private int id; private String name; }",
            "explanation": "Simplifies implementing equals() and hashCode() using builders."
          },
          {
            "title": "DateUtils example",
            "code": "import org.apache.commons.lang3.time.DateUtils;\nimport java.util.Date;\n\nDate now = new Date();\nDate truncated = DateUtils.truncate(now, java.util.Calendar.DAY_OF_MONTH);\nSystem.out.println(truncated);",
            "explanation": "Truncates the time component of a Date to the start of the day."
          }
        ],
        "best_practices": [
          "Use StringUtils for null-safe string operations instead of manually checking nulls.",
          "Leverage ObjectUtils and ArrayUtils for handling nulls and defaults.",
          "Use builder classes for equals(), hashCode(), and toString() implementations.",
          "Utilize DateUtils and DurationFormatUtils for date/time operations.",
          "Avoid reinventing common utilities that Commons Lang already provides."
        ],
        "error_handling": [
          {
            "error": "NullPointerException",
            "solution": "Use null-safe methods like StringUtils.isEmpty(), ObjectUtils.defaultIfNull(), etc."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Occurs when input parameters are invalid. Validate inputs before using utility methods."
          }
        ]
      },
      "references": {
        "official_docs": "https://commons.apache.org/proper/commons-lang/",
        "github": "https://github.com/apache/commons-lang"
      }
    },
    {
      "id": "commons-io",
      "name": "Apache Commons IO",
      "category": "Utilities/IO",
      "description": "Apache Commons IO provides utilities for working with Java I/O, including file and directory manipulation, file filters, input/output stream handling, and file monitoring. It simplifies common I/O operations and reduces boilerplate code.",
      "story": "Commons IO was created to provide a robust set of tools for file, stream, and directory operations in Java. It includes classes to copy files, read/write content, monitor directories, apply filters, and work with streams efficiently. It is widely used in Java applications where I/O operations are frequent and complex, making code cleaner and safer.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>commons-io</groupId>\n  <artifactId>commons-io</artifactId>\n  <version>2.15.0</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'commons-io:commons-io:2.15.0'"
      },
      "usage": {
        "overview": "Commons IO provides utilities for file operations (copy, move, delete), directory traversal, filters, input/output streams, and monitoring. It helps avoid manual boilerplate code for common I/O tasks.",
        "basic_examples": [
          {
            "title": "Copying a file",
            "code": "import org.apache.commons.io.FileUtils;\nimport java.io.File;\n\nFile source = new File(\"source.txt\");\nFile dest = new File(\"dest.txt\");\nFileUtils.copyFile(source, dest);",
            "explanation": "Copies a file from source to destination."
          },
          {
            "title": "Reading file content",
            "code": "String content = FileUtils.readFileToString(new File(\"example.txt\"), \"UTF-8\");\nSystem.out.println(content);",
            "explanation": "Reads the entire content of a file as a String."
          }
        ],
        "advanced_examples": [
          {
            "title": "Directory traversal",
            "code": "import org.apache.commons.io.FileUtils;\nimport java.io.File;\nimport java.util.Collection;\n\nCollection<File> files = FileUtils.listFiles(new File(\"/path/to/dir\"), new String[]{\"txt\", \"java\"}, true);\nfor (File file : files) {\n    System.out.println(file.getName());\n}",
            "explanation": "Lists all files with specified extensions in a directory recursively."
          },
          {
            "title": "File monitoring",
            "code": "import org.apache.commons.io.monitor.FileAlterationMonitor;\nimport org.apache.commons.io.monitor.FileAlterationObserver;\n\nFileAlterationObserver observer = new FileAlterationObserver(\"/path/to/dir\");\nobserver.addListener(new MyFileListener());\nFileAlterationMonitor monitor = new FileAlterationMonitor(5000, observer);\nmonitor.start();",
            "explanation": "Monitors a directory for changes using FileAlterationMonitor."
          },
          {
            "title": "Stream utilities",
            "code": "import org.apache.commons.io.IOUtils;\nimport java.io.FileInputStream;\n\ntry (FileInputStream fis = new FileInputStream(\"input.txt\")) {\n    String content = IOUtils.toString(fis, \"UTF-8\");\n    System.out.println(content);\n}",
            "explanation": "Reads the content of an InputStream into a String safely using IOUtils."
          },
          {
            "title": "Deleting directories",
            "code": "FileUtils.deleteDirectory(new File(\"/path/to/delete\"));",
            "explanation": "Recursively deletes a directory and its contents."
          }
        ],
        "best_practices": [
          "Use FileUtils and IOUtils to reduce boilerplate and improve readability.",
          "Always close streams or use try-with-resources to avoid resource leaks.",
          "Use FileAlterationMonitor for efficient directory monitoring instead of polling manually.",
          "Validate paths before performing delete or write operations to prevent accidental data loss.",
          "Combine Commons IO with NIO2 APIs for performance-critical applications."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when file or stream operations fail. Ensure paths exist, have correct permissions, and streams are properly handled."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Thrown when invalid arguments like null files are passed. Validate inputs before calling utility methods."
          }
        ]
      },
      "references": {
        "official_docs": "https://commons.apache.org/proper/commons-io/",
        "github": "https://github.com/apache/commons-io"
      }
    },
    {
      "id": "commons-collections",
      "name": "Apache Commons Collections",
      "category": "Utilities/Collections",
      "description": "Apache Commons Collections extends the Java Collections Framework with additional interfaces, implementations, and utilities for manipulating and transforming collections. It includes features like Bag, MultiMap, BidiMap, and advanced iterators.",
      "story": "Commons Collections was developed to provide powerful, reusable collection utilities beyond the standard Java Collections Framework. It simplifies tasks such as grouping, counting, bidirectional mapping, transforming, and filtering collections. It is widely used in enterprise Java applications, open-source projects, and frameworks that need enhanced collection handling.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.commons</groupId>\n  <artifactId>commons-collections4</artifactId>\n  <version>4.4</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'org.apache.commons:commons-collections4:4.4'"
      },
      "usage": {
        "overview": "Commons Collections provides enhanced collection types like Bag, MultiMap, BidiMap, and utilities for transforming, filtering, and decorating collections. It also offers specialized iterators and predicates for collection manipulation.",
        "basic_examples": [
          {
            "title": "Bag example",
            "code": "import org.apache.commons.collections4.Bag;\nimport org.apache.commons.collections4.bag.HashBag;\n\nBag<String> bag = new HashBag<>();\nbag.add(\"apple\", 3);\nbag.add(\"banana\");\nSystem.out.println(bag.getCount(\"apple\")); // 3",
            "explanation": "A Bag counts the occurrences of each element in the collection."
          },
          {
            "title": "MultiMap example",
            "code": "import org.apache.commons.collections4.MultiMap;\nimport org.apache.commons.collections4.multimap.ArrayListValuedHashMap;\n\nMultiMap<String, String> multiMap = new ArrayListValuedHashMap<>();\nmultiMap.put(\"fruit\", \"apple\");\nmultiMap.put(\"fruit\", \"banana\");\nSystem.out.println(multiMap.get(\"fruit\"));",
            "explanation": "Stores multiple values for a single key."
          }
        ],
        "advanced_examples": [
          {
            "title": "BidiMap example",
            "code": "import org.apache.commons.collections4.BidiMap;\nimport org.apache.commons.collections4.bidimap.HashBidiMap;\n\nBidiMap<Integer, String> bidi = new HashBidiMap<>();\nbidi.put(1, \"one\");\nbidi.put(2, \"two\");\nSystem.out.println(bidi.getKey(\"two\")); // 2",
            "explanation": "Allows bidirectional lookup between keys and values."
          },
          {
            "title": "Transforming collections",
            "code": "import org.apache.commons.collections4.CollectionUtils;\nimport org.apache.commons.collections4.Transformer;\n\nCollection<String> input = Arrays.asList(\"a\", \"bb\", \"ccc\");\nCollection<String> output = CollectionUtils.collect(input, (Transformer<String, String>) String::toUpperCase);\nSystem.out.println(output);",
            "explanation": "Transforms all elements in a collection using a function."
          },
          {
            "title": "Filtering collections",
            "code": "import org.apache.commons.collections4.Predicate;\nimport org.apache.commons.collections4.CollectionUtils;\n\nCollection<String> input = Arrays.asList(\"apple\", \"banana\", \"cherry\");\nCollection<String> result = CollectionUtils.select(input, (Predicate<String>) s -> s.startsWith(\"a\"));\nSystem.out.println(result);",
            "explanation": "Selects elements from a collection based on a predicate."
          },
          {
            "title": "LazyList example",
            "code": "import org.apache.commons.collections4.list.LazyList;\nimport org.apache.commons.collections4.FactoryUtils;\nimport java.util.ArrayList;\n\nList<String> lazy = LazyList.lazyList(new ArrayList<>(), FactoryUtils.constantFactory(\"default\"));\nlazy.add(0, \"first\");\nlazy.add(2, null);\nSystem.out.println(lazy);",
            "explanation": "Creates a list that generates default elements lazily when accessed."
          }
        ],
        "best_practices": [
          "Use Bag for counting occurrences instead of manual maps.",
          "Use MultiMap for key-to-multiple-values mappings.",
          "Use BidiMap for two-way lookup between keys and values.",
          "Use CollectionUtils for transformations, filtering, and null-safe operations.",
          "Avoid overusing legacy iterators when Java 8 streams provide equivalent functionality."
        ],
        "error_handling": [
          {
            "error": "NullPointerException",
            "solution": "Ensure collections are initialized and predicates are not null."
          },
          {
            "error": "UnsupportedOperationException",
            "solution": "Occurs when modifying immutable collections. Use modifiable variants or decorators."
          }
        ]
      },
      "references": {
        "official_docs": "https://commons.apache.org/proper/commons-collections/",
        "github": "https://github.com/apache/commons-collections"
      }
    },
    {
      "id": "commons-configuration",
      "name": "Apache Commons Configuration",
      "category": "Utilities/Configuration",
      "description": "Apache Commons Configuration provides a unified API for accessing configuration data from various sources, including properties files, XML, INI, JSON, and databases. It supports hierarchical configurations, automatic reloading, and combined configuration sources.",
      "story": "Commons Configuration was created to simplify managing configuration data in Java applications. It abstracts the details of different configuration formats, allowing developers to read, write, and monitor configurations consistently. Features like hierarchical structures, interpolated variables, and reloading strategies make it ideal for enterprise and complex applications where configuration management is critical.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.commons</groupId>\n  <artifactId>commons-configuration2</artifactId>\n  <version>2.9.1</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'org.apache.commons:commons-configuration2:2.9.1'"
      },
      "usage": {
        "overview": "Commons Configuration allows reading and writing configurations from multiple sources, combining different sources, handling hierarchical data, and monitoring changes. It supports properties, XML, JSON, INI, database-backed configurations, and more.",
        "basic_examples": [
          {
            "title": "Loading a properties file",
            "code": "import org.apache.commons.configuration2.PropertiesConfiguration;\nimport org.apache.commons.configuration2.builder.fluent.Configurations;\n\nConfigurations configs = new Configurations();\nPropertiesConfiguration config = configs.properties(new File(\"config.properties\"));\nString value = config.getString(\"app.name\");\nSystem.out.println(value);",
            "explanation": "Loads a properties file and reads a configuration value."
          },
          {
            "title": "Reading an XML configuration",
            "code": "import org.apache.commons.configuration2.XMLConfiguration;\nXMLConfiguration xmlConfig = configs.xml(new File(\"config.xml\"));\nString dbUrl = xmlConfig.getString(\"database.url\");\nSystem.out.println(dbUrl);",
            "explanation": "Reads a value from an XML configuration file."
          }
        ],
        "advanced_examples": [
          {
            "title": "Hierarchical configuration",
            "code": "import org.apache.commons.configuration2.HierarchicalConfiguration;\nimport org.apache.commons.configuration2.tree.ImmutableNode;\n\nHierarchicalConfiguration<ImmutableNode> subConfig = xmlConfig.configurationAt(\"database\");\nString user = subConfig.getString(\"username\");\nSystem.out.println(user);",
            "explanation": "Accesses a subsection of a hierarchical configuration."
          },
          {
            "title": "Combining multiple configuration sources",
            "code": "import org.apache.commons.configuration2.CompositeConfiguration;\nCompositeConfiguration composite = new CompositeConfiguration();\ncomposite.addConfiguration(propertiesConfig);\ncomposite.addConfiguration(xmlConfig);\nString value = composite.getString(\"app.name\");\nSystem.out.println(value);",
            "explanation": "Combines multiple configuration sources into one unified view."
          },
          {
            "title": "Automatic reloading",
            "code": "import org.apache.commons.configuration2.builder.ReloadingFileBasedConfigurationBuilder;\nimport org.apache.commons.configuration2.builder.fluent.Parameters;\nimport org.apache.commons.configuration2.reloading.PeriodicReloadingTrigger;\n\nReloadingFileBasedConfigurationBuilder<PropertiesConfiguration> builder =\n    new ReloadingFileBasedConfigurationBuilder<>(PropertiesConfiguration.class)\n    .configure(new Parameters().fileBased().setFile(new File(\"config.properties\")));\n// Trigger reload every 5 seconds\nPeriodicReloadingTrigger trigger = new PeriodicReloadingTrigger(builder.getReloadingController(), null, 5, TimeUnit.SECONDS);\ntrigger.start();",
            "explanation": "Sets up automatic reloading of a properties file every 5 seconds."
          },
          {
            "title": "Interpolated values",
            "code": "config.addProperty(\"app.home\", \"/usr/local/app\");\nconfig.addProperty(\"app.log\", \"${app.home}/logs\");\nSystem.out.println(config.getString(\"app.log\")); // Outputs /usr/local/app/logs",
            "explanation": "Supports variable interpolation within configuration values."
          }
        ],
        "best_practices": [
          "Use CompositeConfiguration to merge multiple configuration sources cleanly.",
          "Use hierarchical configurations for structured data like XML or JSON.",
          "Leverage automatic reloading to update configuration without restarting the application.",
          "Validate configuration values during startup to catch errors early.",
          "Keep sensitive configuration (like passwords) in secure sources or environment variables."
        ],
        "error_handling": [
          {
            "error": "ConfigurationException",
            "solution": "Occurs when a configuration file cannot be read or parsed. Check file paths, syntax, and permissions."
          },
          {
            "error": "NoSuchElementException",
            "solution": "Occurs when attempting to access a missing configuration key. Use getString with a default value or validate keys."
          }
        ]
      },
      "references": {
        "official_docs": "https://commons.apache.org/proper/commons-configuration/",
        "github": "https://github.com/apache/commons-configuration"
      }
    },
    {
      "id": "guice",
      "name": "Google Guice",
      "category": "Dependency Injection",
      "description": "Google Guice is a lightweight dependency injection framework for Java. It allows you to manage object creation and dependencies declaratively using annotations, reducing boilerplate and promoting loose coupling.",
      "story": "Guice was created by Google to simplify dependency management in Java applications. Instead of manually instantiating objects and passing dependencies, Guice allows developers to define how objects are wired together using modules and annotations like @Inject. It supports scopes, providers, and AOP features, making it suitable for both small and enterprise applications.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.google.inject</groupId>\n  <artifactId>guice</artifactId>\n  <version>5.1.0</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'com.google.inject:guice:5.1.0'"
      },
      "usage": {
        "overview": "Guice provides a declarative way to bind interfaces to implementations and inject dependencies. It supports constructor, method, and field injection, scopes (singleton, request, etc.), providers, and AOP interceptors.",
        "basic_examples": [
          {
            "title": "Basic dependency injection",
            "code": "import com.google.inject.*;\n\ninterface Service {\n    void execute();\n}\n\nclass ServiceImpl implements Service {\n    public void execute() { System.out.println(\"Service executed\"); }\n}\n\nclass Client {\n    private final Service service;\n    @Inject\n    Client(Service service) { this.service = service; }\n    void doWork() { service.execute(); }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Injector injector = Guice.createInjector(binder -> binder.bind(Service.class).to(ServiceImpl.class));\n        Client client = injector.getInstance(Client.class);\n        client.doWork();\n    }\n}",
            "explanation": "Binds the Service interface to ServiceImpl and injects it into Client automatically."
          },
          {
            "title": "Field injection",
            "code": "class Client {\n    @Inject private Service service;\n    void doWork() { service.execute(); }\n}",
            "explanation": "Demonstrates injecting dependencies directly into fields."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Providers",
            "code": "class Client {\n    private final Provider<Service> serviceProvider;\n    @Inject\n    Client(Provider<Service> serviceProvider) { this.serviceProvider = serviceProvider; }\n    void doWork() { serviceProvider.get().execute(); }\n}",
            "explanation": "Uses Provider to lazily fetch instances of a dependency when needed."
          },
          {
            "title": "Singleton scope",
            "code": "binder.bind(Service.class).to(ServiceImpl.class).in(Singleton.class);",
            "explanation": "Ensures a single instance of ServiceImpl is shared across the application."
          },
          {
            "title": "Custom module",
            "code": "class AppModule extends AbstractModule {\n    @Override\n    protected void configure() {\n        bind(Service.class).to(ServiceImpl.class);\n    }\n}\n\nInjector injector = Guice.createInjector(new AppModule());",
            "explanation": "Organizes bindings in a module for cleaner configuration."
          },
          {
            "title": "Method injection",
            "code": "class Client {\n    private Service service;\n    @Inject void setService(Service service) { this.service = service; }\n}",
            "explanation": "Injects dependencies using a setter method."
          }
        ],
        "best_practices": [
          "Prefer constructor injection over field or method injection for better testability.",
          "Use Modules to centralize and manage bindings cleanly.",
          "Leverage Singleton scope for stateless or shared services to save resources.",
          "Use Providers for lazy or conditional dependency creation.",
          "Combine Guice with AOP for cross-cutting concerns like logging and transactions."
        ],
        "error_handling": [
          {
            "error": "ConfigurationException",
            "solution": "Occurs when bindings are missing or ambiguous. Ensure all required bindings are properly defined."
          },
          {
            "error": "ProvisionException",
            "solution": "Occurs when Guice fails to create an instance. Check for constructor exceptions or circular dependencies."
          }
        ]
      },
      "references": {
        "official_docs": "https://github.com/google/guice",
        "github": "https://github.com/google/guice"
      }
    },
    {
      "id": "httpclient",
      "name": "Apache HttpClient",
      "category": "Networking/HTTP",
      "description": "Apache HttpClient is a robust and feature-rich HTTP client library for Java. It allows sending HTTP requests, handling responses, managing connections, cookies, authentication, and supporting advanced features like redirects and timeouts.",
      "story": "HttpClient was created to simplify HTTP communication in Java applications. It abstracts the complexities of HTTP connections, supports synchronous and asynchronous operations, and provides utilities for headers, cookies, and authentication. Widely used in web services, REST clients, and integrations, it ensures reliable and maintainable HTTP communication.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.httpcomponents.client5</groupId>\n  <artifactId>httpclient5</artifactId>\n  <version>5.2</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'org.apache.httpcomponents.client5:httpclient5:5.2'"
      },
      "usage": {
        "overview": "HttpClient allows creating HTTP requests (GET, POST, PUT, DELETE), handling responses, managing cookies, setting headers, handling timeouts, and supporting connection pooling. It supports both synchronous and asynchronous request execution.",
        "basic_examples": [
          {
            "title": "Simple GET request",
            "code": "import org.apache.hc.client5.http.fluent.Request;\n\nString response = Request.get(\"https://httpbin.org/get\").execute().returnContent().asString();\nSystem.out.println(response);",
            "explanation": "Performs a simple GET request and prints the response content."
          },
          {
            "title": "Simple POST request",
            "code": "import org.apache.hc.client5.http.fluent.Request;\nimport org.apache.hc.core5.http.io.entity.StringEntity;\n\nString json = \"{\\\"key\\\": \\\"value\\\"}\";\nString response = Request.post(\"https://httpbin.org/post\")\n    .bodyString(json, org.apache.hc.core5.http.ContentType.APPLICATION_JSON)\n    .execute().returnContent().asString();\nSystem.out.println(response);",
            "explanation": "Sends a POST request with JSON payload and prints the response."
          }
        ],
        "advanced_examples": [
          {
            "title": "Custom headers",
            "code": "import org.apache.hc.client5.http.fluent.Request;\n\nString response = Request.get(\"https://httpbin.org/headers\")\n    .addHeader(\"User-Agent\", \"MyHttpClient/1.0\")\n    .execute().returnContent().asString();\nSystem.out.println(response);",
            "explanation": "Adds custom headers to the request."
          },
          {
            "title": "Handling timeouts",
            "code": "import org.apache.hc.client5.http.config.RequestConfig;\nimport org.apache.hc.client5.http.impl.classic.CloseableHttpClient;\nimport org.apache.hc.client5.http.impl.classic.HttpClients;\nimport org.apache.hc.client5.http.classic.methods.HttpGet;\n\nRequestConfig config = RequestConfig.custom().setResponseTimeout(5_000).build();\ntry (CloseableHttpClient client = HttpClients.custom().setDefaultRequestConfig(config).build()) {\n    HttpGet request = new HttpGet(\"https://httpbin.org/delay/10\");\n    client.execute(request);\n} catch (Exception e) {\n    System.out.println(\"Request timed out\");\n}",
            "explanation": "Sets a timeout to prevent indefinite waiting."
          },
          {
            "title": "Using connection pool",
            "code": "import org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager;\nimport org.apache.hc.client5.http.impl.classic.CloseableHttpClient;\nimport org.apache.hc.client5.http.impl.classic.HttpClients;\n\nPoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();\ncm.setMaxTotal(50);\ncm.setDefaultMaxPerRoute(10);\nCloseableHttpClient client = HttpClients.custom().setConnectionManager(cm).build();",
            "explanation": "Manages multiple HTTP connections efficiently using a connection pool."
          },
          {
            "title": "Basic authentication",
            "code": "import org.apache.hc.client5.http.auth.UsernamePasswordCredentials;\nimport org.apache.hc.client5.http.impl.auth.BasicCredentialsProvider;\nimport org.apache.hc.client5.http.impl.classic.CloseableHttpClient;\nimport org.apache.hc.client5.http.impl.classic.HttpClients;\n\nBasicCredentialsProvider credsProvider = new BasicCredentialsProvider();\ncredsProvider.setCredentials(new UsernamePasswordCredentials(\"user\", \"password\".toCharArray()));\nCloseableHttpClient client = HttpClients.custom().setDefaultCredentialsProvider(credsProvider).build();",
            "explanation": "Sets up basic authentication for requests."
          }
        ],
        "best_practices": [
          "Use connection pooling for high-performance applications.",
          "Always set timeouts to avoid hanging requests.",
          "Use fluent API for simpler code and readability.",
          "Handle exceptions like IOExceptions to ensure reliability.",
          "Close resources properly using try-with-resources or clientsâ€™ close() methods."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when there is a network error or server is unreachable. Handle exceptions appropriately."
          },
          {
            "error": "HttpResponseException",
            "solution": "Occurs when the response status code indicates an error. Check status code and handle accordingly."
          },
          {
            "error": "ConnectionPoolTimeoutException",
            "solution": "Occurs when connections cannot be acquired from the pool. Adjust pool size or release connections promptly."
          }
        ]
      },
      "references": {
        "official_docs": "https://hc.apache.org/httpcomponents-client-5.2.x/",
        "github": "https://github.com/apache/httpcomponents-client"
      }
    },
    {
      "id": "okhttp",
      "name": "OkHttp",
      "category": "Networking/HTTP",
      "description": "OkHttp is a modern, efficient, and feature-rich HTTP client for Java and Android. It supports synchronous and asynchronous requests, connection pooling, HTTP/2, web sockets, caching, retries, and timeouts.",
      "story": "OkHttp was developed by Square to simplify HTTP communication in Java and Android applications. It provides a high-performance and reliable client with advanced features like transparent GZIP compression, connection reuse, and support for modern protocols like HTTP/2 and WebSocket. OkHttp is widely used in REST clients, microservices, and mobile applications.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.squareup.okhttp3</groupId>\n  <artifactId>okhttp</artifactId>\n  <version>4.11.0</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'com.squareup.okhttp3:okhttp:4.11.0'"
      },
      "usage": {
        "overview": "OkHttp allows creating HTTP requests (GET, POST, PUT, DELETE), handling responses, managing headers and cookies, performing asynchronous calls, and integrating with web sockets and interceptors.",
        "basic_examples": [
          {
            "title": "Simple GET request",
            "code": "import okhttp3.OkHttpClient;\nimport okhttp3.Request;\nimport okhttp3.Response;\n\nOkHttpClient client = new OkHttpClient();\nRequest request = new Request.Builder().url(\"https://httpbin.org/get\").build();\ntry (Response response = client.newCall(request).execute()) {\n    System.out.println(response.body().string());\n}",
            "explanation": "Performs a synchronous GET request and prints the response body."
          },
          {
            "title": "Simple POST request",
            "code": "import okhttp3.*;\n\nOkHttpClient client = new OkHttpClient();\nRequestBody body = RequestBody.create(\n    MediaType.parse(\"application/json\"),\n    \"{\\\"key\\\":\\\"value\\\"}\"\n);\nRequest request = new Request.Builder().url(\"https://httpbin.org/post\").post(body).build();\ntry (Response response = client.newCall(request).execute()) {\n    System.out.println(response.body().string());\n}",
            "explanation": "Sends a POST request with a JSON payload."
          }
        ],
        "advanced_examples": [
          {
            "title": "Asynchronous request",
            "code": "client.newCall(request).enqueue(new Callback() {\n    @Override public void onFailure(Call call, IOException e) { e.printStackTrace(); }\n    @Override public void onResponse(Call call, Response response) throws IOException {\n        System.out.println(response.body().string());\n    }\n});",
            "explanation": "Executes the request asynchronously without blocking the main thread."
          },
          {
            "title": "Adding headers",
            "code": "Request request = new Request.Builder()\n    .url(\"https://httpbin.org/headers\")\n    .addHeader(\"User-Agent\", \"OkHttpClient/1.0\")\n    .build();",
            "explanation": "Adds custom headers to an HTTP request."
          },
          {
            "title": "Connection pooling",
            "code": "OkHttpClient client = new OkHttpClient.Builder()\n    .connectionPool(new ConnectionPool(5, 5, TimeUnit.MINUTES))\n    .build();",
            "explanation": "Manages reusable connections to improve performance."
          },
          {
            "title": "Timeouts",
            "code": "OkHttpClient client = new OkHttpClient.Builder()\n    .connectTimeout(10, TimeUnit.SECONDS)\n    .readTimeout(30, TimeUnit.SECONDS)\n    .writeTimeout(15, TimeUnit.SECONDS)\n    .build();",
            "explanation": "Sets connection, read, and write timeouts to prevent hanging requests."
          },
          {
            "title": "WebSocket usage",
            "code": "import okhttp3.WebSocket;\nimport okhttp3.WebSocketListener;\nimport okhttp3.OkHttpClient;\n\nOkHttpClient client = new OkHttpClient();\nRequest request = new Request.Builder().url(\"wss://echo.websocket.org\").build();\nWebSocket ws = client.newWebSocket(request, new WebSocketListener() {\n    @Override public void onOpen(WebSocket webSocket, Response response) {\n        webSocket.send(\"Hello WebSocket\");\n    }\n    @Override public void onMessage(WebSocket webSocket, String text) {\n        System.out.println(\"Received: \" + text);\n    }\n});",
            "explanation": "Connects to a WebSocket endpoint and sends/receives messages."
          }
        ],
        "best_practices": [
          "Reuse OkHttpClient instances to take advantage of connection pooling.",
          "Use asynchronous requests to avoid blocking the main thread in applications.",
          "Set timeouts to prevent network delays from hanging the application.",
          "Use interceptors for logging, authentication, or modifying requests/responses.",
          "Close response bodies to prevent resource leaks."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs for network failures or server errors. Handle exceptions appropriately with retries if needed."
          },
          {
            "error": "ProtocolException",
            "solution": "Occurs when the server response violates HTTP protocol. Ensure requests and server responses are valid."
          },
          {
            "error": "IllegalStateException",
            "solution": "Occurs if the request body or response is used improperly. Always follow OkHttp usage rules."
          }
        ]
      },
      "references": {
        "official_docs": "https://square.github.io/okhttp/",
        "github": "https://github.com/square/okhttp"
      }
    },
    {
      "id": "jakarta-mail",
      "name": "Jakarta Mail (JavaMail)",
      "category": "Email/Communication",
      "description": "Jakarta Mail (formerly JavaMail) is a Java API for sending, receiving, and managing email messages using protocols such as SMTP, IMAP, and POP3. It provides a simple interface for building email applications and integrating email functionality into Java applications.",
      "story": "JavaMail was originally developed as part of the Java EE platform and later moved to the Eclipse Foundation under Jakarta EE. It abstracts the complexities of email protocols, allowing developers to focus on application logic. Jakarta Mail is widely used in enterprise applications, automated email notifications, and email clients.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.sun.mail</groupId>\n  <artifactId>jakarta.mail</artifactId>\n  <version>2.1.2</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'com.sun.mail:jakarta.mail:2.1.2'"
      },
      "usage": {
        "overview": "Jakarta Mail allows sending emails via SMTP, reading emails from IMAP or POP3, handling attachments, multipart messages, HTML content, and managing folders. It integrates easily with Java SE and Jakarta EE applications.",
        "basic_examples": [
          {
            "title": "Sending a simple email",
            "code": "import jakarta.mail.*;\nimport jakarta.mail.internet.*;\nimport java.util.Properties;\n\nProperties props = new Properties();\nprops.put(\"mail.smtp.host\", \"smtp.example.com\");\nprops.put(\"mail.smtp.port\", \"587\");\nprops.put(\"mail.smtp.auth\", \"true\");\n\nSession session = Session.getInstance(props, new Authenticator() {\n    protected PasswordAuthentication getPasswordAuthentication() {\n        return new PasswordAuthentication(\"username\", \"password\");\n    }\n});\n\nMessage message = new MimeMessage(session);\nmessage.setFrom(new InternetAddress(\"from@example.com\"));\nmessage.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"to@example.com\"));\nmessage.setSubject(\"Test Email\");\nmessage.setText(\"Hello, this is a test email.\");\n\nTransport.send(message);",
            "explanation": "Sends a simple text email using SMTP with authentication."
          },
          {
            "title": "Reading emails from IMAP",
            "code": "Properties props = new Properties();\nprops.put(\"mail.store.protocol\", \"imap\");\nSession session = Session.getDefaultInstance(props, null);\nStore store = session.getStore(\"imap\");\nstore.connect(\"imap.example.com\", \"username\", \"password\");\nFolder inbox = store.getFolder(\"INBOX\");\ninbox.open(Folder.READ_ONLY);\nMessage[] messages = inbox.getMessages();\nfor (Message msg : messages) {\n    System.out.println(msg.getSubject());\n}\ninbox.close(false);\nstore.close();",
            "explanation": "Connects to an IMAP server and prints the subjects of emails in the inbox."
          }
        ],
        "advanced_examples": [
          {
            "title": "Sending HTML email",
            "code": "MimeMessage message = new MimeMessage(session);\nmessage.setFrom(new InternetAddress(\"from@example.com\"));\nmessage.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"to@example.com\"));\nmessage.setSubject(\"HTML Email\");\nmessage.setContent(\"<h1>Hello</h1><p>This is an HTML email</p>\", \"text/html\");\nTransport.send(message);",
            "explanation": "Sends an email with HTML content."
          },
          {
            "title": "Sending email with attachment",
            "code": "MimeBodyPart textPart = new MimeBodyPart();\ntextPart.setText(\"Please find the attachment.\");\nMimeBodyPart attachmentPart = new MimeBodyPart();\nattachmentPart.attachFile(new File(\"file.pdf\"));\nMultipart multipart = new MimeMultipart();\nmultipart.addBodyPart(textPart);\nmultipart.addBodyPart(attachmentPart);\n\nMimeMessage message = new MimeMessage(session);\nmessage.setFrom(new InternetAddress(\"from@example.com\"));\nmessage.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"to@example.com\"));\nmessage.setSubject(\"Email with Attachment\");\nmessage.setContent(multipart);\nTransport.send(message);",
            "explanation": "Sends an email with both text content and a file attachment."
          },
          {
            "title": "Using folders and flags",
            "code": "Folder inbox = store.getFolder(\"INBOX\");\ninbox.open(Folder.READ_WRITE);\nfor (Message msg : inbox.getMessages()) {\n    if (!msg.isSet(Flags.Flag.SEEN)) {\n        System.out.println(\"Unread: \" + msg.getSubject());\n        msg.setFlag(Flags.Flag.SEEN, true);\n    }\n}\ninbox.close(true);",
            "explanation": "Reads unread emails and marks them as seen."
          }
        ],
        "best_practices": [
          "Use SSL/TLS for secure email transmission.",
          "Reuse Session objects instead of creating new ones repeatedly.",
          "Handle exceptions like MessagingException and IOException gracefully.",
          "Close connections, folders, and stores properly to avoid resource leaks.",
          "Validate email addresses before sending to prevent delivery failures."
        ],
        "error_handling": [
          {
            "error": "AuthenticationFailedException",
            "solution": "Occurs if username or password is incorrect. Check credentials and server settings."
          },
          {
            "error": "SendFailedException",
            "solution": "Occurs when the email cannot be delivered. Verify recipients and SMTP server configuration."
          },
          {
            "error": "MessagingException",
            "solution": "Generic error for email operations. Inspect cause for details."
          }
        ]
      },
      "references": {
        "official_docs": "https://eclipse-ee4j.github.io/mail/",
        "github": "https://github.com/eclipse-ee4j/mail"
      }
    },
    {
      "id": "jakarta-mail",
      "name": "Jakarta Mail (JavaMail)",
      "category": "Email/Communication",
      "description": "Jakarta Mail (formerly JavaMail) is a Java API for sending, receiving, and managing email messages using protocols such as SMTP, IMAP, and POP3. It provides a simple interface for building email applications and integrating email functionality into Java applications.",
      "story": "JavaMail was originally developed as part of the Java EE platform and later moved to the Eclipse Foundation under Jakarta EE. It abstracts the complexities of email protocols, allowing developers to focus on application logic. Jakarta Mail is widely used in enterprise applications, automated email notifications, and email clients.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.sun.mail</groupId>\n  <artifactId>jakarta.mail</artifactId>\n  <version>2.1.2</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'com.sun.mail:jakarta.mail:2.1.2'"
      },
      "usage": {
        "overview": "Jakarta Mail allows sending emails via SMTP, reading emails from IMAP or POP3, handling attachments, multipart messages, HTML content, and managing folders. It integrates easily with Java SE and Jakarta EE applications.",
        "basic_examples": [
          {
            "title": "Sending a simple email",
            "code": "import jakarta.mail.*;\nimport jakarta.mail.internet.*;\nimport java.util.Properties;\n\nProperties props = new Properties();\nprops.put(\"mail.smtp.host\", \"smtp.example.com\");\nprops.put(\"mail.smtp.port\", \"587\");\nprops.put(\"mail.smtp.auth\", \"true\");\n\nSession session = Session.getInstance(props, new Authenticator() {\n    protected PasswordAuthentication getPasswordAuthentication() {\n        return new PasswordAuthentication(\"username\", \"password\");\n    }\n});\n\nMessage message = new MimeMessage(session);\nmessage.setFrom(new InternetAddress(\"from@example.com\"));\nmessage.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"to@example.com\"));\nmessage.setSubject(\"Test Email\");\nmessage.setText(\"Hello, this is a test email.\");\n\nTransport.send(message);",
            "explanation": "Sends a simple text email using SMTP with authentication."
          },
          {
            "title": "Reading emails from IMAP",
            "code": "Properties props = new Properties();\nprops.put(\"mail.store.protocol\", \"imap\");\nSession session = Session.getDefaultInstance(props, null);\nStore store = session.getStore(\"imap\");\nstore.connect(\"imap.example.com\", \"username\", \"password\");\nFolder inbox = store.getFolder(\"INBOX\");\ninbox.open(Folder.READ_ONLY);\nMessage[] messages = inbox.getMessages();\nfor (Message msg : messages) {\n    System.out.println(msg.getSubject());\n}\ninbox.close(false);\nstore.close();",
            "explanation": "Connects to an IMAP server and prints the subjects of emails in the inbox."
          }
        ],
        "advanced_examples": [
          {
            "title": "Sending HTML email",
            "code": "MimeMessage message = new MimeMessage(session);\nmessage.setFrom(new InternetAddress(\"from@example.com\"));\nmessage.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"to@example.com\"));\nmessage.setSubject(\"HTML Email\");\nmessage.setContent(\"<h1>Hello</h1><p>This is an HTML email</p>\", \"text/html\");\nTransport.send(message);",
            "explanation": "Sends an email with HTML content."
          },
          {
            "title": "Sending email with attachment",
            "code": "MimeBodyPart textPart = new MimeBodyPart();\ntextPart.setText(\"Please find the attachment.\");\nMimeBodyPart attachmentPart = new MimeBodyPart();\nattachmentPart.attachFile(new File(\"file.pdf\"));\nMultipart multipart = new MimeMultipart();\nmultipart.addBodyPart(textPart);\nmultipart.addBodyPart(attachmentPart);\n\nMimeMessage message = new MimeMessage(session);\nmessage.setFrom(new InternetAddress(\"from@example.com\"));\nmessage.setRecipients(Message.RecipientType.TO, InternetAddress.parse(\"to@example.com\"));\nmessage.setSubject(\"Email with Attachment\");\nmessage.setContent(multipart);\nTransport.send(message);",
            "explanation": "Sends an email with both text content and a file attachment."
          },
          {
            "title": "Using folders and flags",
            "code": "Folder inbox = store.getFolder(\"INBOX\");\ninbox.open(Folder.READ_WRITE);\nfor (Message msg : inbox.getMessages()) {\n    if (!msg.isSet(Flags.Flag.SEEN)) {\n        System.out.println(\"Unread: \" + msg.getSubject());\n        msg.setFlag(Flags.Flag.SEEN, true);\n    }\n}\ninbox.close(true);",
            "explanation": "Reads unread emails and marks them as seen."
          }
        ],
        "best_practices": [
          "Use SSL/TLS for secure email transmission.",
          "Reuse Session objects instead of creating new ones repeatedly.",
          "Handle exceptions like MessagingException and IOException gracefully.",
          "Close connections, folders, and stores properly to avoid resource leaks.",
          "Validate email addresses before sending to prevent delivery failures."
        ],
        "error_handling": [
          {
            "error": "AuthenticationFailedException",
            "solution": "Occurs if username or password is incorrect. Check credentials and server settings."
          },
          {
            "error": "SendFailedException",
            "solution": "Occurs when the email cannot be delivered. Verify recipients and SMTP server configuration."
          },
          {
            "error": "MessagingException",
            "solution": "Generic error for email operations. Inspect cause for details."
          }
        ]
      },
      "references": {
        "official_docs": "https://eclipse-ee4j.github.io/mail/",
        "github": "https://github.com/eclipse-ee4j/mail"
      }
    },
    {
      "id": "flyway",
      "name": "Flyway",
      "category": "Database/Migration",
      "description": "Flyway is an open-source database migration tool for Java that allows developers to version, manage, and automate database schema changes. It supports SQL-based migrations as well as Java-based migrations for complex transformations.",
      "story": "Flyway was created to simplify database version control and continuous integration workflows. It enables developers to maintain consistent database schemas across environments, ensures smooth migrations, and integrates easily with Java applications and build tools. Flyway is widely used in enterprise applications, microservices, and automated deployment pipelines.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.flywaydb</groupId>\n  <artifactId>flyway-core</artifactId>\n  <version>10.15.0</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'org.flywaydb:flyway-core:10.15.0'"
      },
      "usage": {
        "overview": "Flyway allows defining migrations as SQL scripts or Java classes, tracks which migrations have been applied, and ensures the database is up-to-date. It supports multiple databases such as PostgreSQL, MySQL, Oracle, SQL Server, and SQLite.",
        "basic_examples": [
          {
            "title": "Basic Flyway configuration",
            "code": "import org.flywaydb.core.Flyway;\n\nFlyway flyway = Flyway.configure()\n    .dataSource(\"jdbc:postgresql://localhost:5432/mydb\", \"user\", \"password\")\n    .load();\nflyway.migrate();",
            "explanation": "Configures Flyway with a PostgreSQL database and applies all pending migrations."
          },
          {
            "title": "SQL-based migration",
            "code": "-- V1__create_users_table.sql\nCREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) NOT NULL\n);",
            "explanation": "Defines a SQL migration script named with Flyway's versioned naming convention (V1__)."
          }
        ],
        "advanced_examples": [
          {
            "title": "Java-based migration",
            "code": "import org.flywaydb.core.api.migration.BaseJavaMigration;\nimport org.flywaydb.core.api.migration.Context;\nimport java.sql.Statement;\n\npublic class V2__Add_email_to_users extends BaseJavaMigration {\n    @Override\n    public void migrate(Context context) throws Exception {\n        try (Statement stmt = context.getConnection().createStatement()) {\n            stmt.execute(\"ALTER TABLE users ADD COLUMN email VARCHAR(255)\");\n        }\n    }\n}",
            "explanation": "Defines a Java-based migration to add a column to the users table."
          },
          {
            "title": "Undo migration",
            "code": "-- U2__remove_email_from_users.sql\nALTER TABLE users DROP COLUMN email;",
            "explanation": "Defines an undo migration script to revert a previous migration if needed."
          },
          {
            "title": "Baseline an existing database",
            "code": "Flyway flyway = Flyway.configure()\n    .dataSource(\"jdbc:mysql://localhost:3306/mydb\", \"user\", \"password\")\n    .baselineVersion(\"1\")\n    .baselineOnMigrate(true)\n    .load();\nflyway.baseline();",
            "explanation": "Sets a baseline for an existing database to start managing migrations without reapplying old scripts."
          }
        ],
        "best_practices": [
          "Use versioned migrations (V1__, V2__, ...) for schema changes to maintain order.",
          "Keep SQL scripts small and atomic to reduce risks during migrations.",
          "Store migration scripts in source control alongside application code.",
          "Test migrations in a staging environment before production deployment.",
          "Use Java-based migrations only when complex logic or conditional operations are required."
        ],
        "error_handling": [
          {
            "error": "FlywayException",
            "solution": "Occurs if a migration fails or the database is in an inconsistent state. Inspect migration logs and fix the SQL/Java scripts."
          },
          {
            "error": "ValidationException",
            "solution": "Occurs when the applied migrations do not match the migration history. Use repair() cautiously to fix metadata."
          },
          {
            "error": "SQLException",
            "solution": "Occurs for database-level errors. Check connection settings, SQL syntax, and database compatibility."
          }
        ]
      },
      "references": {
        "official_docs": "https://flywaydb.org/documentation/",
        "github": "https://github.com/flyway/flyway"
      }
    },
    {
      "id": "rxjava",
      "name": "RxJava",
      "category": "Reactive Programming",
      "description": "RxJava is a Java library for composing asynchronous and event-based programs using observable sequences. It provides powerful operators for managing concurrency, data streams, and transformations in a functional style.",
      "story": "RxJava was inspired by the Reactive Extensions (Rx) from Microsoft and was created to bring reactive programming paradigms to Java. It allows developers to handle asynchronous events, multithreading, and reactive streams in a declarative way, improving code readability and reducing boilerplate in complex event-driven applications.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>io.reactivex.rxjava3</groupId>\n  <artifactId>rxjava</artifactId>\n  <version>3.1.7</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'io.reactivex.rxjava3:rxjava:3.1.7'"
      },
      "usage": {
        "overview": "RxJava provides Observable, Flowable, Single, Maybe, and Completable types to handle streams of data. It supports operators like map, filter, merge, flatMap, and error handling operators for reactive programming patterns.",
        "basic_examples": [
          {
            "title": "Creating an Observable",
            "code": "import io.reactivex.rxjava3.core.Observable;\n\nObservable<String> observable = Observable.just(\"Hello\", \"RxJava\", \"World\");\nobservable.subscribe(System.out::println);",
            "explanation": "Creates a simple Observable that emits three strings and prints them."
          },
          {
            "title": "Using map operator",
            "code": "Observable<Integer> numbers = Observable.just(1, 2, 3, 4);\nnumbers.map(x -> x * x).subscribe(System.out::println);",
            "explanation": "Transforms each emitted number by squaring it using the map operator."
          }
        ],
        "advanced_examples": [
          {
            "title": "Combining Observables",
            "code": "Observable<String> obs1 = Observable.just(\"A\", \"B\");\nObservable<String> obs2 = Observable.just(\"1\", \"2\");\nObservable.combineLatest(obs1, obs2, (s1, s2) -> s1 + s2).subscribe(System.out::println);",
            "explanation": "Combines the latest emissions from two Observables."
          },
          {
            "title": "Error handling",
            "code": "Observable<Integer> numbers = Observable.just(1, 0, 2);\nnumbers.map(x -> 10 / x).onErrorReturnItem(-1).subscribe(System.out::println);",
            "explanation": "Handles division by zero errors and provides a default value using onErrorReturnItem."
          },
          {
            "title": "Using Flowable for backpressure",
            "code": "import io.reactivex.rxjava3.core.Flowable;\n\nFlowable.range(1, 1000)\n    .map(x -> x * 2)\n    .subscribe(System.out::println);",
            "explanation": "Handles large streams of data efficiently with Flowable to manage backpressure."
          },
          {
            "title": "Threading with Schedulers",
            "code": "Observable.just(\"Hello\", \"RxJava\")\n    .subscribeOn(Schedulers.io())\n    .observeOn(Schedulers.single())\n    .subscribe(System.out::println);",
            "explanation": "Specifies different threads for subscription and observation using Schedulers."
          }
        ],
        "best_practices": [
          "Use appropriate reactive types (Observable, Flowable, Single, Maybe, Completable) for the scenario.",
          "Always manage subscriptions to avoid memory leaks, using Disposable or CompositeDisposable.",
          "Use Flowable for streams with large or fast-emitting data to handle backpressure.",
          "Prefer functional operators over manual threading and callbacks for cleaner code.",
          "Handle errors explicitly using onErrorReturn, onErrorResumeNext, or try-catch in operators."
        ],
        "error_handling": [
          {
            "error": "OnErrorNotImplementedException",
            "solution": "Occurs if an Observable emits an error but no error handler is provided. Always provide onError callbacks when subscribing."
          },
          {
            "error": "MissingBackpressureException",
            "solution": "Occurs when Flowable emits items faster than downstream can consume. Use strategies like buffer, drop, or latest to manage backpressure."
          },
          {
            "error": "NullPointerException",
            "solution": "RxJava does not allow null emissions. Ensure that no null values are emitted in the stream."
          }
        ]
      },
      "references": {
        "official_docs": "https://github.com/ReactiveX/RxJava",
        "github": "https://github.com/ReactiveX/RxJava"
      }
    },
    {
      "id": "project-reactor",
      "name": "Project Reactor",
      "category": "Reactive Programming",
      "description": "Project Reactor is a reactive library for building non-blocking, asynchronous, and event-driven applications on the JVM. It provides types like Mono and Flux to handle zero-to-one and zero-to-many reactive sequences respectively, following the Reactive Streams specification.",
      "story": "Project Reactor was developed by Pivotal (now part of VMware) to provide a fully reactive foundation for Java applications, particularly in Spring ecosystems. It is widely used in reactive web applications, microservices, and data streaming pipelines to improve scalability, responsiveness, and resource utilization.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>io.projectreactor</groupId>\n  <artifactId>reactor-core</artifactId>\n  <version>3.5.9</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'io.projectreactor:reactor-core:3.5.9'"
      },
      "usage": {
        "overview": "Project Reactor provides reactive types like Flux and Mono, operators for transformations, filtering, combining, error handling, and scheduling. It integrates seamlessly with Spring WebFlux and reactive databases for end-to-end non-blocking applications.",
        "basic_examples": [
          {
            "title": "Creating a Mono",
            "code": "import reactor.core.publisher.Mono;\n\nMono<String> mono = Mono.just(\"Hello Reactor\");\nmono.subscribe(System.out::println);",
            "explanation": "Creates a Mono that emits a single value and prints it."
          },
          {
            "title": "Creating a Flux",
            "code": "import reactor.core.publisher.Flux;\n\nFlux<Integer> flux = Flux.just(1, 2, 3, 4);\nflux.subscribe(System.out::println);",
            "explanation": "Creates a Flux that emits multiple values and prints each one."
          }
        ],
        "advanced_examples": [
          {
            "title": "Transforming data with map",
            "code": "Flux<Integer> numbers = Flux.just(1, 2, 3, 4);\nnumbers.map(x -> x * x).subscribe(System.out::println);",
            "explanation": "Applies a transformation to each emitted value using the map operator."
          },
          {
            "title": "Filtering data",
            "code": "Flux<Integer> numbers = Flux.range(1, 10);\nnumbers.filter(x -> x % 2 == 0).subscribe(System.out::println);",
            "explanation": "Filters even numbers from a sequence using the filter operator."
          },
          {
            "title": "Combining sequences",
            "code": "Flux<String> flux1 = Flux.just(\"A\", \"B\");\nFlux<String> flux2 = Flux.just(\"1\", \"2\");\nFlux.zip(flux1, flux2, (a,b) -> a + b).subscribe(System.out::println);",
            "explanation": "Combines two sequences element-wise using zip."
          },
          {
            "title": "Error handling",
            "code": "Flux<Integer> numbers = Flux.just(1, 0, 2);\nnumbers.map(x -> 10 / x).onErrorReturn(-1).subscribe(System.out::println);",
            "explanation": "Handles division by zero errors and provides a fallback value."
          },
          {
            "title": "Scheduling and threading",
            "code": "Flux.range(1, 5)\n    .publishOn(Schedulers.parallel())\n    .map(x -> x * 2)\n    .subscribe(System.out::println);",
            "explanation": "Executes the Flux operations on a parallel scheduler for non-blocking concurrency."
          }
        ],
        "best_practices": [
          "Use Mono for single-value sequences and Flux for multiple-value sequences.",
          "Avoid blocking calls inside reactive pipelines to maintain non-blocking behavior.",
          "Handle errors gracefully with onErrorReturn, onErrorResume, or retry operators.",
          "Use proper Schedulers for asynchronous execution and resource management.",
          "Integrate with Spring WebFlux or reactive database clients for end-to-end reactive applications."
        ],
        "error_handling": [
          {
            "error": "OnErrorNotImplementedException",
            "solution": "Occurs when a reactive stream emits an error but no error handler is defined. Always provide onError handlers."
          },
          {
            "error": "IllegalStateException",
            "solution": "Occurs when subscribing multiple times to a single-use Mono or Flux improperly. Ensure proper usage."
          },
          {
            "error": "NullPointerException",
            "solution": "Reactor does not allow null values to be emitted. Use Mono.empty() or Flux.empty() instead of null."
          }
        ]
      },
      "references": {
        "official_docs": "https://projectreactor.io/docs/core/release/reference/",
        "github": "https://github.com/reactor/reactor-core"
      }
    },
    {
      "id": "rabbitmq",
      "name": "RabbitMQ Java Client",
      "category": "Messaging/Queue",
      "description": "RabbitMQ Java Client is a Java library for interacting with RabbitMQ, a message broker that implements the Advanced Message Queuing Protocol (AMQP). It enables applications to send, receive, and process messages asynchronously and reliably.",
      "story": "RabbitMQ, originally developed by Pivotal, is a popular message broker used in distributed systems, microservices, and event-driven architectures. The Java client allows developers to integrate RabbitMQ messaging capabilities into Java applications, supporting features like queues, exchanges, routing, acknowledgments, and transactions for reliable message delivery.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.rabbitmq</groupId>\n  <artifactId>amqp-client</artifactId>\n  <version>5.18.0</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'com.rabbitmq:amqp-client:5.18.0'"
      },
      "usage": {
        "overview": "The library provides ConnectionFactory, Connection, Channel, and QueueingConsumer APIs to connect to RabbitMQ, declare queues, publish and consume messages, and manage exchanges and routing keys.",
        "basic_examples": [
          {
            "title": "Sending a message",
            "code": "import com.rabbitmq.client.Channel;\nimport com.rabbitmq.client.Connection;\nimport com.rabbitmq.client.ConnectionFactory;\n\nConnectionFactory factory = new ConnectionFactory();\nfactory.setHost(\"localhost\");\ntry (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) {\n    channel.queueDeclare(\"hello\", false, false, false, null);\n    String message = \"Hello RabbitMQ!\";\n    channel.basicPublish(\"\", \"hello\", null, message.getBytes());\n    System.out.println(\"Sent: \" + message);\n}",
            "explanation": "Connects to RabbitMQ, declares a queue, and sends a simple message."
          },
          {
            "title": "Receiving a message",
            "code": "import com.rabbitmq.client.*;\n\nConnectionFactory factory = new ConnectionFactory();\nfactory.setHost(\"localhost\");\nConnection connection = factory.newConnection();\nChannel channel = connection.createChannel();\nchannel.queueDeclare(\"hello\", false, false, false, null);\nDeliverCallback deliverCallback = (consumerTag, delivery) -> {\n    String message = new String(delivery.getBody(), \"UTF-8\");\n    System.out.println(\"Received: \" + message);\n};\nchannel.basicConsume(\"hello\", true, deliverCallback, consumerTag -> {});",
            "explanation": "Connects to RabbitMQ, listens on a queue, and prints received messages."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using exchanges and routing keys",
            "code": "channel.exchangeDeclare(\"logs\", \"fanout\");\nString message = \"Log message\";\nchannel.basicPublish(\"logs\", \"\", null, message.getBytes());",
            "explanation": "Publishes a message to a fanout exchange, broadcasting to all bound queues."
          },
          {
            "title": "Acknowledgments and manual message handling",
            "code": "boolean autoAck = false;\nchannel.basicConsume(\"task_queue\", autoAck, (consumerTag, delivery) -> {\n    String message = new String(delivery.getBody(), \"UTF-8\");\n    System.out.println(\"Received: \" + message);\n    channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);\n}, consumerTag -> {});",
            "explanation": "Handles messages manually and acknowledges after processing to ensure reliability."
          },
          {
            "title": "Persistent messages",
            "code": "AMQP.BasicProperties props = new AMQP.BasicProperties.Builder().deliveryMode(2).build();\nchannel.basicPublish(\"\", \"task_queue\", props, message.getBytes());",
            "explanation": "Marks messages as persistent to survive RabbitMQ restarts."
          }
        ],
        "best_practices": [
          "Use persistent messages for critical data that should survive broker restarts.",
          "Handle message acknowledgments properly to avoid message loss or duplication.",
          "Use appropriate exchange types (direct, fanout, topic, headers) based on routing requirements.",
          "Monitor queues and consumers to prevent bottlenecks and memory issues.",
          "Use connection pooling or shared connections for efficiency in high-throughput systems."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when network or connection issues happen. Ensure RabbitMQ server is running and reachable."
          },
          {
            "error": "TimeoutException",
            "solution": "Occurs when connections or operations exceed timeout. Adjust timeout settings or check network stability."
          },
          {
            "error": "ShutdownSignalException",
            "solution": "Occurs when the connection or channel is closed unexpectedly. Handle reconnections gracefully."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.rabbitmq.com/api-guide.html",
        "github": "https://github.com/rabbitmq/rabbitmq-java-client"
      }
    },
    {
      "id": "activemq",
      "name": "ActiveMQ",
      "category": "Messaging/Queue",
      "description": "Apache ActiveMQ is a popular open-source message broker that implements JMS (Java Message Service). The ActiveMQ Java Client library allows Java applications to send, receive, and process messages asynchronously and reliably across distributed systems.",
      "story": "ActiveMQ was created by the Apache Software Foundation to provide a robust, high-performance, and enterprise-grade messaging solution. It supports a wide variety of messaging patterns, protocols, and integrations, making it suitable for microservices, event-driven systems, and enterprise applications.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.activemq</groupId>\n  <artifactId>activemq-client</artifactId>\n  <version>5.18.5</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'org.apache.activemq:activemq-client:5.18.5'"
      },
      "usage": {
        "overview": "ActiveMQ Java Client provides ConnectionFactory, Connection, Session, MessageProducer, MessageConsumer, Queue, and Topic APIs to facilitate message sending, receiving, and management. It supports both point-to-point (queue) and publish-subscribe (topic) messaging models.",
        "basic_examples": [
          {
            "title": "Sending a message to a queue",
            "code": "import javax.jms.*;\nimport org.apache.activemq.ActiveMQConnectionFactory;\n\nConnectionFactory factory = new ActiveMQConnectionFactory(\"tcp://localhost:61616\");\nConnection connection = factory.createConnection();\nconnection.start();\nSession session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\nQueue queue = session.createQueue(\"TEST.QUEUE\");\nMessageProducer producer = session.createProducer(queue);\nTextMessage message = session.createTextMessage(\"Hello ActiveMQ!\");\nproducer.send(message);\nSystem.out.println(\"Sent: \" + message.getText());\nsession.close();\nconnection.close();",
            "explanation": "Connects to ActiveMQ, creates a queue, and sends a simple text message."
          },
          {
            "title": "Receiving a message from a queue",
            "code": "import javax.jms.*;\nimport org.apache.activemq.ActiveMQConnectionFactory;\n\nConnectionFactory factory = new ActiveMQConnectionFactory(\"tcp://localhost:61616\");\nConnection connection = factory.createConnection();\nconnection.start();\nSession session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\nQueue queue = session.createQueue(\"TEST.QUEUE\");\nMessageConsumer consumer = session.createConsumer(queue);\nMessage message = consumer.receive(1000);\nif (message instanceof TextMessage) {\n    TextMessage textMessage = (TextMessage) message;\n    System.out.println(\"Received: \" + textMessage.getText());\n}\nsession.close();\nconnection.close();",
            "explanation": "Connects to ActiveMQ, listens on a queue, and prints received messages."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using topics (publish-subscribe)",
            "code": "Topic topic = session.createTopic(\"TEST.TOPIC\");\nMessageProducer producer = session.createProducer(topic);\nTextMessage message = session.createTextMessage(\"Broadcast message\");\nproducer.send(message);",
            "explanation": "Sends a message to all subscribers of a topic (publish-subscribe model)."
          },
          {
            "title": "Persistent messages",
            "code": "producer.setDeliveryMode(DeliveryMode.PERSISTENT);\nproducer.send(message);",
            "explanation": "Ensures messages are stored persistently and survive broker restarts."
          },
          {
            "title": "Asynchronous message listener",
            "code": "consumer.setMessageListener(msg -> {\n    if (msg instanceof TextMessage) {\n        try {\n            System.out.println(\"Received asynchronously: \" + ((TextMessage) msg).getText());\n        } catch (JMSException e) {\n            e.printStackTrace();\n        }\n    }\n});",
            "explanation": "Sets a listener to receive messages asynchronously without blocking."
          }
        ],
        "best_practices": [
          "Use persistent delivery mode for critical messages to prevent data loss.",
          "Choose queues for point-to-point messaging and topics for publish-subscribe patterns.",
          "Handle exceptions and reconnections gracefully to maintain reliability.",
          "Monitor message queues and consumers to avoid bottlenecks or memory issues.",
          "Consider using connection pooling for high-throughput applications."
        ],
        "error_handling": [
          {
            "error": "JMSException",
            "solution": "Occurs for messaging-related errors. Check connection settings, broker availability, and session configuration."
          },
          {
            "error": "MessageFormatException",
            "solution": "Occurs when a message cannot be serialized/deserialized properly. Ensure compatible message types."
          },
          {
            "error": "InvalidDestinationException",
            "solution": "Occurs when the specified queue or topic does not exist. Verify destination names and broker configuration."
          }
        ]
      },
      "references": {
        "official_docs": "https://activemq.apache.org/components/classic/documentation/",
        "github": "https://github.com/apache/activemq"
      }
    },
    {
      "id": "redisson",
      "name": "Redisson",
      "category": "Caching/Distributed Data",
      "description": "Redisson is a Java client for Redis that provides a high-level, distributed Java data structures framework. It allows Java applications to interact with Redis using objects, collections, locks, atomic variables, and other advanced features in a thread-safe and cluster-aware manner.",
      "story": "Redisson was created to simplify the integration of Redis into Java applications, offering a rich set of distributed Java objects and utilities. It supports reactive, asynchronous, and synchronous APIs and is widely used for caching, distributed locking, pub/sub messaging, and managing high-concurrency applications.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.redisson</groupId>\n  <artifactId>redisson</artifactId>\n  <version>3.21.7</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\nimplementation 'org.redisson:redisson:3.21.7'"
      },
      "usage": {
        "overview": "Redisson provides distributed implementations of Java objects like Map, Set, List, Queue, Lock, AtomicLong, and Semaphore. It supports cluster mode, replication, reactive programming, and transaction-like features over Redis.",
        "basic_examples": [
          {
            "title": "Connecting to Redis",
            "code": "import org.redisson.Redisson;\nimport org.redisson.api.RedissonClient;\nimport org.redisson.config.Config;\n\nConfig config = new Config();\nconfig.useSingleServer().setAddress(\"redis://127.0.0.1:6379\");\nRedissonClient redisson = Redisson.create(config);",
            "explanation": "Sets up a Redisson client to connect to a local Redis instance."
          },
          {
            "title": "Using a distributed map",
            "code": "import org.redisson.api.RMap;\nRMap<String, String> map = redisson.getMap(\"myMap\");\nmap.put(\"key\", \"value\");\nSystem.out.println(map.get(\"key\"));",
            "explanation": "Demonstrates storing and retrieving values from a distributed map backed by Redis."
          }
        ],
        "advanced_examples": [
          {
            "title": "Distributed lock",
            "code": "import org.redisson.api.RLock;\nRLock lock = redisson.getLock(\"myLock\");\nlock.lock();\ntry {\n    // critical section\n} finally {\n    lock.unlock();\n}",
            "explanation": "Uses Redisson to implement a distributed lock ensuring thread-safe access across multiple JVMs."
          },
          {
            "title": "Distributed atomic long",
            "code": "import org.redisson.api.RAtomicLong;\nRAtomicLong atomicLong = redisson.getAtomicLong(\"counter\");\natomicLong.incrementAndGet();\nSystem.out.println(atomicLong.get());",
            "explanation": "Provides a distributed atomic counter across different processes."
          },
          {
            "title": "Pub/Sub messaging",
            "code": "import org.redisson.api.RTopic;\nRTopic topic = redisson.getTopic(\"myTopic\");\ntopic.addListener(String.class, (channel, msg) -> System.out.println(\"Received: \" + msg));\ntopic.publish(\"Hello Redisson!\");",
            "explanation": "Demonstrates publish/subscribe messaging using Redis channels."
          },
          {
            "title": "Reactive API example",
            "code": "import org.redisson.api.RMapReactive;\nRMapReactive<String, String> reactiveMap = redisson.getMap(\"reactiveMap\");\nreactiveMap.put(\"key\", \"value\").subscribe();",
            "explanation": "Shows asynchronous, non-blocking operations using Redisson's reactive API."
          }
        ],
        "best_practices": [
          "Use distributed locks and atomic objects for multi-instance applications to avoid race conditions.",
          "Prefer asynchronous or reactive APIs for high-concurrency scenarios to improve performance.",
          "Keep Redis data structures optimized to reduce memory usage and latency.",
          "Use appropriate TTL (time-to-live) settings for cache entries.",
          "Monitor Redis cluster and Redisson metrics for resource utilization and scaling."
        ],
        "error_handling": [
          {
            "error": "RedisConnectionException",
            "solution": "Occurs when Redisson cannot connect to the Redis server. Check host, port, and network connectivity."
          },
          {
            "error": "RedisTimeoutException",
            "solution": "Occurs when a Redis operation exceeds the timeout. Adjust timeout settings or optimize Redis commands."
          },
          {
            "error": "IllegalStateException",
            "solution": "Occurs if the client is shut down or configuration is invalid. Ensure proper client lifecycle management."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.redisson.org/",
        "github": "https://github.com/redisson/redisson"
      }
    },
    {
      "id": "arquillian",
      "name": "Arquillian",
      "category": "Testing/Integration",
      "description": "Arquillian is a powerful testing platform for Java that simplifies integration and functional testing of Java EE and Jakarta EE applications. It allows developers to execute tests inside real runtime containers rather than mocks, ensuring realistic behavior and deployment conditions.",
      "story": "Arquillian was created to overcome limitations of traditional unit testing frameworks for enterprise applications. It provides a way to deploy your code in a container, run tests against it, and verify real-world interactions, making integration testing easier, repeatable, and closer to production scenarios.",
      "installation": {
        "maven": "Add dependencies in pom.xml:\n<dependency>\n  <groupId>org.jboss.arquillian.junit</groupId>\n  <artifactId>arquillian-junit-container</artifactId>\n  <version>1.7.0.Final</version>\n  <scope>test</scope>\n</dependency>\n<dependency>\n  <groupId>org.jboss.arquillian.container</groupId>\n  <artifactId>arquillian-weld-embedded</artifactId>\n  <version>3.0.0.Final</version>\n  <scope>test</scope>\n</dependency>",
        "gradle": "Add dependencies in build.gradle:\ntestImplementation 'org.jboss.arquillian.junit:arquillian-junit-container:1.7.0.Final'\ntestImplementation 'org.jboss.arquillian.container:arquillian-weld-embedded:3.0.0.Final'"
      },
      "usage": {
        "overview": "Arquillian allows developers to write tests that run inside real or embedded containers. It manages the deployment lifecycle, container startup, and test execution, and integrates with popular testing frameworks like JUnit and TestNG.",
        "basic_examples": [
          {
            "title": "Simple Arquillian test with JUnit",
            "code": "import org.jboss.arquillian.junit.Arquillian;\nimport org.jboss.arquillian.container.test.api.Deployment;\nimport org.jboss.shrinkwrap.api.ShrinkWrap;\nimport org.jboss.shrinkwrap.api.spec.JavaArchive;\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\n\n@RunWith(Arquillian.class)\npublic class MyServiceTest {\n\n    @Deployment\n    public static JavaArchive createDeployment() {\n        return ShrinkWrap.create(JavaArchive.class)\n                         .addClass(MyService.class)\n                         .addAsManifestResource(\"beans.xml\");\n    }\n\n    @Test\n    public void testServiceMethod() {\n        MyService service = new MyService();\n        assertEquals(\"Hello\", service.sayHello());\n    }\n}",
            "explanation": "Defines a deployment package using ShrinkWrap and runs a simple test in the Arquillian-managed container."
          }
        ],
        "advanced_examples": [
          {
            "title": "Injecting CDI beans",
            "code": "import javax.inject.Inject;\n\n@Inject\nMyService service;\n\n@Test\npublic void testInjectedService() {\n    assertEquals(\"Hello\", service.sayHello());\n}",
            "explanation": "Demonstrates dependency injection in tests to access container-managed beans."
          },
          {
            "title": "Using different container adapters",
            "code": "// In arquillian.xml, configure container:\n// <container qualifier=\"wildfly\" default=\"true\">\n//     <configuration>\n//         <property name=\"managementAddress\">localhost</property>\n//         <property name=\"managementPort\">9990</property>\n//     </configuration>\n// </container>",
            "explanation": "Arquillian supports multiple containers such as WildFly, GlassFish, and TomEE, configured via arquillian.xml."
          },
          {
            "title": "Integration with TestNG",
            "code": "@RunWith(Arquillian.class)\npublic class MyTestNGTest extends AbstractTestNGSpringContextTests {\n    // TestNG methods with @Test annotations\n}",
            "explanation": "Arquillian can also integrate with TestNG instead of JUnit."
          }
        ],
        "best_practices": [
          "Use ShrinkWrap to define minimal deployment packages containing only required classes and resources.",
          "Leverage embedded containers for fast, repeatable tests during development.",
          "Use Arquillian Drone or Selenium integration for functional web testing.",
          "Separate unit tests and integration tests clearly to maintain test speed.",
          "Configure container-specific settings in arquillian.xml to match production environments."
        ],
        "error_handling": [
          {
            "error": "DeploymentException",
            "solution": "Occurs when the deployment archive is invalid or container fails to start. Verify ShrinkWrap configuration and container availability."
          },
          {
            "error": "InjectionException",
            "solution": "Occurs when CDI beans cannot be injected. Ensure beans.xml is present and CDI beans are properly defined."
          },
          {
            "error": "ContainerStartupException",
            "solution": "Occurs if the container cannot start. Check container installation, network settings, and version compatibility."
          }
        ]
      },
      "references": {
        "official_docs": "https://arquillian.org/guides/",
        "github": "https://github.com/arquillian/arquillian-core"
      }
    },
    {
      "id": "wiremock",
      "name": "WireMock",
      "category": "Testing/Mocking",
      "description": "WireMock is a flexible and powerful Java library for mocking HTTP services. It allows developers to stub, simulate, and test interactions with external APIs, enabling reliable and isolated testing of client code without depending on real external services.",
      "story": "WireMock was created to provide a robust tool for testing HTTP-based integrations. It can be used for unit tests, integration tests, or contract tests, allowing developers to simulate API behavior, return custom responses, and verify HTTP requests. Its popularity grew as microservices and API-driven architectures became widespread.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.github.tomakehurst</groupId>\n  <artifactId>wiremock-jre8</artifactId>\n  <version>3.2.0</version>\n  <scope>test</scope>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\ntestImplementation 'com.github.tomakehurst:wiremock-jre8:3.2.0'"
      },
      "usage": {
        "overview": "WireMock allows developers to start a mock HTTP server, configure stubs, simulate delays or failures, and verify requests. It supports both programmatic and declarative (JSON) configuration and can run in unit tests or standalone mode.",
        "basic_examples": [
          {
            "title": "Starting a WireMock server",
            "code": "import com.github.tomakehurst.wiremock.WireMockServer;\nimport static com.github.tomakehurst.wiremock.client.WireMock.*;\n\nWireMockServer wireMockServer = new WireMockServer(8080);\nwireMockServer.start();\n\nconfigureFor(\"localhost\", 8080);\nstubFor(get(urlEqualTo(\"/hello\"))\n        .willReturn(aResponse()\n            .withHeader(\"Content-Type\", \"text/plain\")\n            .withBody(\"Hello WireMock!\")));\n\n// Shutdown\n// wireMockServer.stop();",
            "explanation": "Starts a WireMock server, defines a stub for GET /hello, and returns a custom response."
          },
          {
            "title": "Verifying requests",
            "code": "verify(getRequestedFor(urlEqualTo(\"/hello\")));",
            "explanation": "Checks whether a specific HTTP request was made to the mock server."
          }
        ],
        "advanced_examples": [
          {
            "title": "Simulating delays and errors",
            "code": "stubFor(get(urlEqualTo(\"/slow\"))\n    .willReturn(aResponse()\n        .withFixedDelay(2000) // 2 seconds delay\n        .withStatus(500)\n        .withBody(\"Server error\")));",
            "explanation": "Simulates slow responses and server errors for testing client resilience."
          },
          {
            "title": "Using JSON stubs",
            "code": "// Save a stub mapping as src/test/resources/__files/hello.json\n{\n  \"request\": { \"method\": \"GET\", \"url\": \"/hello\" },\n  \"response\": { \"status\": 200, \"body\": \"Hello from JSON!\" }\n}",
            "explanation": "Defines stubs declaratively using JSON files instead of programmatic API."
          },
          {
            "title": "Recording and replaying requests",
            "code": "wireMockServer.startRecording(\"http://real-api-server.com\");\n// perform tests\nwireMockServer.stopRecording();",
            "explanation": "Records real HTTP interactions to create stubs automatically for later replay."
          },
          {
            "title": "Using WireMock with JUnit",
            "code": "import org.junit.Rule;\nimport com.github.tomakehurst.wiremock.junit.WireMockRule;\n\n@Rule\npublic WireMockRule wireMockRule = new WireMockRule(8080);",
            "explanation": "Integrates WireMock into JUnit tests for automatic setup and teardown of the mock server."
          }
        ],
        "best_practices": [
          "Use WireMock for integration and contract testing to avoid dependency on real external services.",
          "Keep stubs small and focused to simplify test maintenance.",
          "Combine programmatic stubs with JSON-based stubs for flexibility.",
          "Simulate realistic network conditions using delays and error responses.",
          "Clean up or reset stubs between tests to ensure isolation."
        ],
        "error_handling": [
          {
            "error": "PortInUseException",
            "solution": "Occurs if the configured port is already in use. Change the WireMock server port or stop the conflicting service."
          },
          {
            "error": "VerificationFailedException",
            "solution": "Occurs when a request verification fails. Ensure the request was made and matches the expected URL, method, and headers."
          },
          {
            "error": "MappingNotFoundException",
            "solution": "Occurs when no stub matches a request. Define appropriate stubs for all expected test requests."
          }
        ]
      },
      "references": {
        "official_docs": "http://wiremock.org/docs/",
        "github": "https://github.com/wiremock/wiremock"
      }
    },
    {
      "id": "awaitility",
      "name": "Awaitility",
      "category": "Testing/Async",
      "description": "Awaitility is a Java DSL (Domain Specific Language) for testing asynchronous code. It allows developers to wait for a certain condition to be met within a specified time period, making testing of async operations, background tasks, or event-driven systems more reliable and readable.",
      "story": "Testing asynchronous operations in Java can be challenging due to timing and concurrency issues. Awaitility was created to simplify this by providing a clean, readable API to wait for conditions without using Thread.sleep() or complex polling logic. It is widely used in unit tests, integration tests, and reactive systems testing.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.awaitility</groupId>\n  <artifactId>awaitility</artifactId>\n  <version>4.2.0</version>\n  <scope>test</scope>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\ntestImplementation 'org.awaitility:awaitility:4.2.0'"
      },
      "usage": {
        "overview": "Awaitility allows you to define expectations using conditions, durations, and polling intervals. It integrates with JUnit, TestNG, and other test frameworks, making async testing straightforward.",
        "basic_examples": [
          {
            "title": "Waiting for a flag to be true",
            "code": "import static org.awaitility.Awaitility.await;\nimport java.util.concurrent.TimeUnit;\n\nboolean[] flag = {false};\nnew Thread(() -> {\n    Thread.sleep(1000);\n    flag[0] = true;\n}).start();\n\nawait().atMost(5, TimeUnit.SECONDS).until(() -> flag[0]);",
            "explanation": "Waits up to 5 seconds until the `flag` variable becomes true, allowing asynchronous threads to complete."
          },
          {
            "title": "Waiting for a value to change",
            "code": "import static org.awaitility.Awaitility.await;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nAtomicInteger counter = new AtomicInteger(0);\nnew Thread(() -> counter.incrementAndGet()).start();\nawait().untilAtomic(counter, val -> val > 0);",
            "explanation": "Waits for an AtomicInteger to become greater than 0."
          }
        ],
        "advanced_examples": [
          {
            "title": "Custom polling interval",
            "code": "await().atMost(10, TimeUnit.SECONDS).pollInterval(500, TimeUnit.MILLISECONDS)\n       .until(() -> myService.isReady());",
            "explanation": "Polls every 500 milliseconds for a condition to become true, with a maximum timeout of 10 seconds."
          },
          {
            "title": "Ignoring exceptions",
            "code": "await().atMost(5, TimeUnit.SECONDS).ignoreExceptions()\n       .until(() -> externalService.getData() != null);",
            "explanation": "Ignores transient exceptions while waiting for a condition, useful for unstable or delayed async services."
          },
          {
            "title": "Combining with matchers",
            "code": "import static org.hamcrest.Matchers.*;\nawait().atMost(3, TimeUnit.SECONDS).until(() -> list.size(), equalTo(5));",
            "explanation": "Uses Hamcrest matchers to define more expressive conditions."
          }
        ],
        "best_practices": [
          "Avoid using Thread.sleep() in tests; prefer Awaitility for readability and reliability.",
          "Define reasonable timeouts to prevent tests from hanging indefinitely.",
          "Use atomic variables or thread-safe constructs for shared state in async tests.",
          "Integrate with JUnit or TestNG to run async tests seamlessly.",
          "Use polling intervals to balance responsiveness and CPU usage during waits."
        ],
        "error_handling": [
          {
            "error": "ConditionTimeoutException",
            "solution": "Occurs when the expected condition is not met within the specified timeout. Verify the async logic or increase the timeout duration if necessary."
          },
          {
            "error": "IllegalStateException",
            "solution": "Occurs if Awaitility is misconfigured, e.g., negative timeouts or invalid poll intervals. Ensure proper API usage."
          }
        ]
      },
      "references": {
        "official_docs": "https://awaitility.github.io/awaitility/",
        "github": "https://github.com/awaitility/awaitility"
      }
    },
    {
      "id": "apache-maven",
      "name": "Apache Maven",
      "category": "Build/Dependency Management",
      "description": "Apache Maven is a powerful build automation and project management tool for Java and other JVM-based languages. It provides a uniform build system, dependency management, and a project object model (POM) to define project structure, plugins, and external libraries.",
      "story": "Maven was created by the Apache Software Foundation to simplify Java project builds, dependency resolution, and lifecycle management. It standardizes the build process, encourages best practices, and integrates with continuous integration tools, making it a cornerstone in modern Java development.",
      "installation": {
        "website": "https://maven.apache.org/install.html",
        "maven_setup": "Download Maven, extract to a directory, and set environment variables (M2_HOME, PATH) to use 'mvn' command."
      },
      "usage": {
        "overview": "Maven uses the Project Object Model (POM) to manage project configuration, dependencies, build plugins, and tasks. It supports standard lifecycles: clean, compile, test, package, verify, install, and deploy.",
        "basic_examples": [
          {
            "title": "Creating a new Maven project",
            "code": "mvn archetype:generate -DgroupId=com.example -DartifactId=my-app -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false",
            "explanation": "Generates a basic Java project structure with POM and source folders."
          },
          {
            "title": "Compiling a Maven project",
            "code": "mvn compile",
            "explanation": "Compiles source code and resolves dependencies defined in pom.xml."
          },
          {
            "title": "Running tests",
            "code": "mvn test",
            "explanation": "Executes unit tests using configured testing framework (e.g., JUnit)."
          }
        ],
        "advanced_examples": [
          {
            "title": "Packaging a project",
            "code": "mvn package",
            "explanation": "Compiles, runs tests, and packages the project into a JAR or WAR file as defined in the POM."
          },
          {
            "title": "Installing to local repository",
            "code": "mvn install",
            "explanation": "Installs the built artifact into the local Maven repository (~/.m2/repository) for use by other projects."
          },
          {
            "title": "Adding dependencies",
            "code": "<dependencies>\n  <dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-lang3</artifactId>\n    <version>3.13.0</version>\n  </dependency>\n</dependencies>",
            "explanation": "Declares a dependency in pom.xml so Maven downloads and manages the library automatically."
          },
          {
            "title": "Running custom plugins",
            "code": "mvn clean verify -Pproduction",
            "explanation": "Executes custom plugins and profiles for complex builds or environment-specific tasks."
          }
        ],
        "best_practices": [
          "Keep POM files organized and modular using parent/child projects.",
          "Use dependency management to handle versions consistently across modules.",
          "Leverage Maven profiles to differentiate builds for dev, test, and production.",
          "Use the Maven Central repository or private artifact repositories for dependencies.",
          "Regularly update Maven plugins and dependencies to maintain compatibility."
        ],
        "error_handling": [
          {
            "error": "DependencyResolutionException",
            "solution": "Occurs when Maven cannot resolve a dependency. Check the groupId, artifactId, version, and repository availability."
          },
          {
            "error": "PluginExecutionException",
            "solution": "Occurs when a Maven plugin fails during execution. Verify plugin configuration and version compatibility."
          },
          {
            "error": "BuildFailureException",
            "solution": "Occurs if compilation, tests, or packaging fails. Review logs, fix code or configuration issues."
          }
        ]
      },
      "references": {
        "official_docs": "https://maven.apache.org/guides/index.html",
        "github": "https://github.com/apache/maven"
      }
    },
    {
      "id": "gradle",
      "name": "Gradle",
      "category": "Build/Dependency Management",
      "description": "Gradle is a modern build automation tool for Java, Kotlin, and other JVM-based languages. It provides a flexible, high-performance build system with support for dependency management, multi-project builds, and incremental compilation, making it ideal for complex enterprise projects.",
      "story": "Gradle was created to improve upon traditional build tools like Apache Ant and Maven by offering a declarative DSL, performance optimizations, and extensive plugin support. It has become widely adopted in the Java ecosystem, Android development, and large-scale projects due to its flexibility, speed, and compatibility with existing build conventions.",
      "installation": {
        "website": "https://gradle.org/install/",
        "gradle_setup": "Download Gradle, extract it, and set the environment variable PATH to include the bin directory. Verify with 'gradle -v'."
      },
      "usage": {
        "overview": "Gradle uses a Groovy or Kotlin-based DSL (build.gradle or build.gradle.kts) to define tasks, dependencies, and project configurations. It supports standard lifecycles such as clean, build, test, and deploy, with incremental builds for speed.",
        "basic_examples": [
          {
            "title": "Creating a Gradle project",
            "code": "gradle init --type java-application",
            "explanation": "Generates a basic Java project structure with Gradle build scripts and source directories."
          },
          {
            "title": "Compiling a project",
            "code": "gradle build",
            "explanation": "Compiles the source code, runs tests, and produces a JAR file in the build/libs directory."
          },
          {
            "title": "Adding dependencies",
            "code": "dependencies {\n    implementation 'org.apache.commons:commons-lang3:3.13.0'\n    testImplementation 'junit:junit:4.13.2'\n}",
            "explanation": "Declares project dependencies that Gradle automatically downloads and manages."
          }
        ],
        "advanced_examples": [
          {
            "title": "Custom tasks",
            "code": "task hello {\n    doLast {\n        println 'Hello Gradle!'\n    }\n}",
            "explanation": "Defines a custom task named 'hello' that prints a message when executed."
          },
          {
            "title": "Multi-project build",
            "code": "// settings.gradle\ninclude 'core', 'app'\n\n// app/build.gradle\ndependencies {\n    implementation project(':core')\n}",
            "explanation": "Demonstrates a multi-module Gradle project where the app module depends on the core module."
          },
          {
            "title": "Using plugins",
            "code": "plugins {\n    id 'java'\n    id 'application'\n}\n\napplication {\n    mainClass = 'com.example.Main'\n}",
            "explanation": "Applies plugins to add functionality like Java compilation and application packaging."
          },
          {
            "title": "Running tests",
            "code": "gradle test",
            "explanation": "Executes unit tests defined in src/test/java and generates test reports."
          }
        ],
        "best_practices": [
          "Use Gradle wrapper (gradlew) to ensure consistent builds across machines.",
          "Organize multi-module projects to isolate concerns and manage dependencies effectively.",
          "Leverage incremental builds and caching to speed up build times.",
          "Use plugins for standard tasks like Java compilation, testing, and packaging.",
          "Maintain a clear separation between implementation and test dependencies."
        ],
        "error_handling": [
          {
            "error": "DependencyResolutionException",
            "solution": "Occurs when Gradle cannot resolve a dependency. Check repository configuration, dependency coordinates, and network access."
          },
          {
            "error": "TaskExecutionException",
            "solution": "Occurs when a task fails during execution. Review task logs, fix build script issues or compilation errors."
          },
          {
            "error": "BuildFailedException",
            "solution": "Occurs if compilation, testing, or packaging fails. Examine logs to identify and fix underlying problems."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.gradle.org/",
        "github": "https://github.com/gradle/gradle"
      }
    },
    {
      "id": "apache-shiro",
      "name": "Apache Shiro",
      "category": "Security",
      "description": "Apache Shiro is a powerful and easy-to-use Java security framework that performs authentication, authorization, cryptography, and session management. It simplifies securing applications by providing a flexible and intuitive API.",
      "story": "Apache Shiro was created to offer a simple yet comprehensive approach to application security in Java. It allows developers to secure web and enterprise applications without deep knowledge of complex security mechanisms. Shiro integrates seamlessly with any Java application and supports features such as password hashing, access control, and session management.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.shiro</groupId>\n  <artifactId>shiro-core</artifactId>\n  <version>1.11.0</version>\n</dependency>",
        "gradle": "Add dependency in build.gradle:\ntestImplementation 'org.apache.shiro:shiro-core:1.11.0'"
      },
      "usage": {
        "overview": "Shiro provides authentication, authorization, session management, and cryptography. It can secure applications through programmatic API, annotations, or configuration files, supporting both web and non-web environments.",
        "basic_examples": [
          {
            "title": "Authenticating a user",
            "code": "import org.apache.shiro.SecurityUtils;\nimport org.apache.shiro.authc.UsernamePasswordToken;\nimport org.apache.shiro.subject.Subject;\n\nUsernamePasswordToken token = new UsernamePasswordToken(\"user\", \"password\");\nSubject currentUser = SecurityUtils.getSubject();\ncurrentUser.login(token);",
            "explanation": "Authenticates a user using a username and password token."
          },
          {
            "title": "Checking roles and permissions",
            "code": "if(currentUser.hasRole(\"admin\")) {\n    System.out.println(\"User has admin role\");\n}\n\nif(currentUser.isPermitted(\"document:read\")) {\n    System.out.println(\"User can read documents\");\n}",
            "explanation": "Checks if the current user has a specific role or permission."
          }
        ],
        "advanced_examples": [
          {
            "title": "Configuring Shiro with INI file",
            "code": "[users]\nuser = password, admin\n\n[roles]\nadmin = document:read,document:write",
            "explanation": "Defines users and roles with permissions in an INI configuration file."
          },
          {
            "title": "Password hashing",
            "code": "import org.apache.shiro.crypto.hash.Sha256Hash;\nString hashedPassword = new Sha256Hash(\"password\").toHex();",
            "explanation": "Hashes a password using SHA-256 for secure storage."
          },
          {
            "title": "Session management",
            "code": "Subject currentUser = SecurityUtils.getSubject();\nSession session = currentUser.getSession();\nsession.setAttribute(\"key\", \"value\");",
            "explanation": "Stores and retrieves data in a Shiro-managed session."
          },
          {
            "title": "Using annotations for authorization",
            "code": "@RequiresRoles(\"admin\")\npublic void adminMethod() {\n    // only accessible by admin users\n}",
            "explanation": "Secures methods using annotations for role-based access control."
          }
        ],
        "best_practices": [
          "Always hash and salt passwords before storing them.",
          "Use Shiroâ€™s permission system instead of hardcoding roles.",
          "Secure web applications using Shiroâ€™s web filters.",
          "Combine annotations and programmatic checks for fine-grained security.",
          "Regularly update Shiro to patch security vulnerabilities."
        ],
        "error_handling": [
          {
            "error": "UnknownAccountException",
            "solution": "Occurs when a username does not exist. Verify the username or user store."
          },
          {
            "error": "IncorrectCredentialsException",
            "solution": "Occurs when the password does not match the stored credentials."
          },
          {
            "error": "AuthorizationException",
            "solution": "Occurs when a user attempts to access a resource they are not permitted to."
          }
        ]
      },
      "references": {
        "official_docs": "https://shiro.apache.org/",
        "github": "https://github.com/apache/shiro"
      }
    },
    {
      "id": "java-jwt",
      "name": "Java JWT (JJWT)",
      "category": "Security/Authentication",
      "description": "Java JWT libraries provide tools for creating, parsing, and validating JSON Web Tokens (JWT) in Java applications. They are widely used for implementing stateless authentication, secure token-based authorization, and claims-based identity management.",
      "story": "JWTs have become the standard for stateless authentication in modern web applications and microservices. Libraries like JJWT (Java JWT) simplify working with JWTs by providing a fluent API for token creation, signing, and verification. They are compatible with HMAC, RSA, and EC algorithms and integrate easily with Spring Security or custom authentication systems.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>io.jsonwebtoken</groupId>\n  <artifactId>jjwt-api</artifactId>\n  <version>0.11.5</version>\n</dependency>\n<dependency>\n  <groupId>io.jsonwebtoken</groupId>\n  <artifactId>jjwt-impl</artifactId>\n  <version>0.11.5</version>\n  <scope>runtime</scope>\n</dependency>\n<dependency>\n  <groupId>io.jsonwebtoken</groupId>\n  <artifactId>jjwt-jackson</artifactId>\n  <version>0.11.5</version>\n  <scope>runtime</scope>\n</dependency>",
        "gradle": "implementation 'io.jsonwebtoken:jjwt-api:0.11.5'\nruntimeOnly 'io.jsonwebtoken:jjwt-impl:0.11.5'\nruntimeOnly 'io.jsonwebtoken:jjwt-jackson:0.11.5'"
      },
      "usage": {
        "overview": "JWT libraries allow creation of signed tokens, verification of token signatures, and extraction of claims. They support symmetric (HMAC) and asymmetric (RSA/EC) signing algorithms and can be used in authentication, authorization, and API security scenarios.",
        "basic_examples": [
          {
            "title": "Creating a JWT token",
            "code": "import io.jsonwebtoken.Jwts;\nimport io.jsonwebtoken.SignatureAlgorithm;\nimport java.util.Date;\n\nString jwt = Jwts.builder()\n    .setSubject(\"user123\")\n    .setIssuedAt(new Date())\n    .setExpiration(new Date(System.currentTimeMillis() + 3600000)) // 1 hour\n    .signWith(Keys.secretKeyFor(SignatureAlgorithm.HS256))\n    .compact();",
            "explanation": "Creates a JWT token with subject 'user123', issued and expiration time, and signs it using HMAC SHA-256."
          },
          {
            "title": "Parsing and validating a JWT token",
            "code": "import io.jsonwebtoken.Jwts;\nimport io.jsonwebtoken.security.Keys;\n\nvar claims = Jwts.parserBuilder()\n    .setSigningKey(secretKey)\n    .build()\n    .parseClaimsJws(jwt)\n    .getBody();\n\nSystem.out.println(claims.getSubject());",
            "explanation": "Parses and verifies the JWT signature, then extracts the claims (payload) securely."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using custom claims",
            "code": "String jwt = Jwts.builder()\n    .setSubject(\"user123\")\n    .claim(\"role\", \"admin\")\n    .claim(\"email\", \"user@example.com\")\n    .signWith(secretKey)\n    .compact();",
            "explanation": "Adds custom claims like 'role' and 'email' to the JWT payload."
          },
          {
            "title": "Validating token expiration",
            "code": "try {\n    var claims = Jwts.parserBuilder().setSigningKey(secretKey).build().parseClaimsJws(jwt).getBody();\n} catch (io.jsonwebtoken.ExpiredJwtException e) {\n    System.out.println(\"Token has expired\");\n}",
            "explanation": "Catches an exception if the token is expired."
          },
          {
            "title": "Asymmetric signing with RSA",
            "code": "KeyPair keyPair = Keys.keyPairFor(SignatureAlgorithm.RS256);\nString jwt = Jwts.builder()\n    .setSubject(\"user123\")\n    .signWith(keyPair.getPrivate())\n    .compact();",
            "explanation": "Creates a JWT signed using RSA private key and verifies using the public key."
          }
        ],
        "best_practices": [
          "Use strong signing algorithms (HS256, RS256, or ES256) for token integrity.",
          "Set short expiration times and implement refresh tokens.",
          "Do not store sensitive information in JWT payload.",
          "Validate token signature and claims before granting access.",
          "Use HTTPS for transmitting JWTs to prevent interception."
        ],
        "error_handling": [
          {
            "error": "io.jsonwebtoken.ExpiredJwtException",
            "solution": "Occurs when the token is expired. Handle by returning an authentication error or refreshing the token."
          },
          {
            "error": "io.jsonwebtoken.SignatureException",
            "solution": "Occurs when the token signature is invalid. Verify the signing key and algorithm."
          },
          {
            "error": "io.jsonwebtoken.MalformedJwtException",
            "solution": "Occurs if the token format is invalid or tampered with."
          }
        ]
      },
      "references": {
        "official_docs": "https://github.com/jwtk/jjwt",
        "github": "https://github.com/jwtk/jjwt"
      }
    },
    {
      "id": "guava",
      "name": "Guava",
      "category": "Utilities/Collections",
      "description": "Guava is a set of core Java libraries developed by Google that provides utilities for collections, caching, concurrency, primitives support, string manipulation, I/O, and more. It simplifies common tasks and enhances productivity in Java applications.",
      "story": "Guava was created by Google to provide reusable, high-quality Java libraries that address common programming challenges. It has become a popular choice for improving Java code readability, performance, and maintainability, offering a wide range of utility classes that complement the standard Java API.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.google.guava</groupId>\n  <artifactId>guava</artifactId>\n  <version>32.1.2-jre</version>\n</dependency>",
        "gradle": "implementation 'com.google.guava:guava:32.1.2-jre'"
      },
      "usage": {
        "overview": "Guava provides utility classes for collections, caching, concurrency, strings, primitives, I/O, hashing, and functional programming. It simplifies common tasks and provides immutable data structures, fluent APIs, and enhanced performance.",
        "basic_examples": [
          {
            "title": "Using ImmutableList",
            "code": "import com.google.common.collect.ImmutableList;\n\nImmutableList<String> list = ImmutableList.of(\"apple\", \"banana\", \"cherry\");\nSystem.out.println(list);",
            "explanation": "Creates an immutable list that cannot be modified after creation."
          },
          {
            "title": "Using Multimap",
            "code": "import com.google.common.collect.ArrayListMultimap;\nimport com.google.common.collect.Multimap;\n\nMultimap<String, String> multimap = ArrayListMultimap.create();\nmultimap.put(\"fruit\", \"apple\");\nmultimap.put(\"fruit\", \"banana\");\nSystem.out.println(multimap.get(\"fruit\"));",
            "explanation": "Allows mapping a single key to multiple values efficiently."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Cache",
            "code": "import com.google.common.cache.Cache;\nimport com.google.common.cache.CacheBuilder;\n\nCache<String, Integer> cache = CacheBuilder.newBuilder()\n    .maximumSize(100)\n    .build();\n\ncache.put(\"key\", 42);\nSystem.out.println(cache.getIfPresent(\"key\"));",
            "explanation": "Implements an in-memory cache with maximum size and fast retrieval."
          },
          {
            "title": "Using FluentIterable",
            "code": "import com.google.common.collect.FluentIterable;\nimport java.util.Arrays;\n\nFluentIterable<String> filtered = FluentIterable.from(Arrays.asList(\"apple\", \"banana\", \"cherry\"))\n    .filter(s -> s.startsWith(\"b\"));\nSystem.out.println(filtered.toList());",
            "explanation": "Provides fluent operations on collections, like filtering and transformations."
          },
          {
            "title": "Using Strings utility",
            "code": "import com.google.common.base.Strings;\n\nString padded = Strings.padStart(\"7\", 3, '0');\nSystem.out.println(padded);",
            "explanation": "Adds padding to a string for formatting purposes."
          },
          {
            "title": "Using Optional",
            "code": "import com.google.common.base.Optional;\n\nOptional<String> optional = Optional.of(\"hello\");\nif(optional.isPresent()) {\n    System.out.println(optional.get());\n}",
            "explanation": "Handles nulls safely and expresses optional values clearly."
          }
        ],
        "best_practices": [
          "Prefer immutable collections for thread-safety and predictability.",
          "Use Guava caching for expensive computations or frequently accessed data.",
          "Leverage FluentIterable and functional methods for readable collection manipulation.",
          "Use Guava utilities for strings, hashing, and primitive types to simplify code.",
          "Keep dependencies up-to-date to benefit from bug fixes and performance improvements."
        ],
        "error_handling": [
          {
            "error": "NullPointerException",
            "solution": "Guava utilities often prefer explicit null checks. Use Optional or Preconditions to handle null values safely."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Occurs when Preconditions or validation methods detect invalid arguments. Check method contracts carefully."
          }
        ]
      },
      "references": {
        "official_docs": "https://guava.dev/",
        "github": "https://github.com/google/guava"
      }
    },
    {
      "id": "fastutil",
      "name": "FastUtil",
      "category": "Collections/Utilities",
      "description": "FastUtil is a Java library that provides fast and memory-efficient collections for primitive types, including maps, sets, lists, and more. It offers specialized implementations that avoid the overhead of boxing/unboxing primitive types, improving performance in high-throughput applications.",
      "story": "FastUtil was developed to address the performance limitations of standard Java collections when working with primitive types. By providing specialized collections, FastUtil reduces memory footprint and increases speed, making it popular in scenarios such as numerical computing, large datasets, and performance-critical systems.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>it.unimi.dsi</groupId>\n  <artifactId>fastutil</artifactId>\n  <version>8.6.1</version>\n</dependency>",
        "gradle": "implementation 'it.unimi.dsi:fastutil:8.6.1'"
      },
      "usage": {
        "overview": "FastUtil provides collections optimized for primitive types (int, long, double, etc.), including maps, sets, lists, and priority queues. It supports fast iteration, bulk operations, and interoperability with standard Java collections.",
        "basic_examples": [
          {
            "title": "Using IntArrayList",
            "code": "import it.unimi.dsi.fastutil.ints.IntArrayList;\n\nIntArrayList list = new IntArrayList();\nlist.add(10);\nlist.add(20);\nSystem.out.println(list);",
            "explanation": "Creates a list of primitive integers without boxing overhead."
          },
          {
            "title": "Using Int2ObjectMap",
            "code": "import it.unimi.dsi.fastutil.ints.Int2ObjectOpenHashMap;\n\nInt2ObjectOpenHashMap<String> map = new Int2ObjectOpenHashMap<>();\nmap.put(1, \"one\");\nmap.put(2, \"two\");\nSystem.out.println(map.get(1));",
            "explanation": "Creates a map with primitive integer keys and object values for efficient access."
          }
        ],
        "advanced_examples": [
          {
            "title": "Iterating over IntArrayList",
            "code": "IntArrayList list = new IntArrayList(new int[]{1,2,3,4});\nfor(int value : list) {\n    System.out.println(value);\n}",
            "explanation": "Demonstrates fast iteration over primitive lists using enhanced for-loop."
          },
          {
            "title": "Using Long2LongMap",
            "code": "import it.unimi.dsi.fastutil.longs.Long2LongOpenHashMap;\n\nLong2LongOpenHashMap map = new Long2LongOpenHashMap();\nmap.put(100L, 1000L);\nmap.put(200L, 2000L);\nSystem.out.println(map.get(100L));",
            "explanation": "Stores mappings of primitive long keys and values efficiently."
          },
          {
            "title": "Sorting primitive arrays",
            "code": "import it.unimi.dsi.fastutil.ints.IntArrays;\n\nint[] arr = {5,2,9,1};\nIntArrays.quickSort(arr);\nSystem.out.println(Arrays.toString(arr));",
            "explanation": "Uses FastUtilâ€™s optimized sorting algorithms for primitive arrays."
          },
          {
            "title": "Converting to standard Java collections",
            "code": "import it.unimi.dsi.fastutil.ints.IntArrayList;\n\nIntArrayList list = new IntArrayList(new int[]{1,2,3});\nList<Integer> javaList = list; // auto-boxed\nSystem.out.println(javaList);",
            "explanation": "Demonstrates interoperability with standard Java collections."
          }
        ],
        "best_practices": [
          "Use FastUtil collections for large datasets with primitive types to save memory and improve performance.",
          "Prefer primitive-specialized maps and sets to avoid boxing overhead.",
          "Use built-in iteration and bulk operations for high-performance tasks.",
          "Combine FastUtil with standard Java collections where interoperability is needed.",
          "Keep the library updated to leverage performance improvements and bug fixes."
        ],
        "error_handling": [
          {
            "error": "NullPointerException",
            "solution": "FastUtil collections for primitives do not accept nulls. Ensure primitive arrays or default values are used."
          },
          {
            "error": "IndexOutOfBoundsException",
            "solution": "Occurs when accessing invalid indexes in lists or arrays. Check bounds carefully."
          }
        ]
      },
      "references": {
        "official_docs": "http://fastutil.di.unimi.it/",
        "github": "https://github.com/vigna/fastutil"
      }
    },
    {
      "id": "logback",
      "name": "Logback",
      "category": "Logging",
      "description": "Logback is a popular Java logging framework intended as a successor to Log4j. It provides powerful configuration options, fast performance, and a rich set of appenders and layouts for logging messages in various formats and destinations.",
      "story": "Logback was created by Ceki GÃ¼lcÃ¼, the founder of Log4j, to overcome the limitations of Log4j and provide a faster, more reliable, and natively configurable logging framework for Java applications. Logback is widely used in enterprise applications, Spring Boot projects, and microservices due to its simplicity and robust features.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>ch.qos.logback</groupId>\n  <artifactId>logback-classic</artifactId>\n  <version>1.4.11</version>\n</dependency>",
        "gradle": "implementation 'ch.qos.logback:logback-classic:1.4.11'"
      },
      "usage": {
        "overview": "Logback allows logging messages at different levels (TRACE, DEBUG, INFO, WARN, ERROR). It supports console, file, rolling file, and asynchronous appenders, with flexible XML or Groovy-based configuration.",
        "basic_examples": [
          {
            "title": "Simple logging",
            "code": "import org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\npublic class Main {\n    private static final Logger logger = LoggerFactory.getLogger(Main.class);\n\n    public static void main(String[] args) {\n        logger.info(\"Application started\");\n        logger.debug(\"Debugging details\");\n        logger.error(\"An error occurred\");\n    }\n}",
            "explanation": "Uses Logback via the SLF4J API to log messages at different levels."
          }
        ],
        "advanced_examples": [
          {
            "title": "Configuring logback.xml",
            "code": "<configuration>\n    <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\">\n        <encoder>\n            <pattern>%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n</pattern>\n        </encoder>\n    </appender>\n\n    <root level=\"info\">\n        <appender-ref ref=\"STDOUT\" />\n    </root>\n</configuration>",
            "explanation": "Defines a console appender and sets the root logging level to INFO with a custom message pattern."
          },
          {
            "title": "Rolling file appender",
            "code": "<appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n    <file>logs/app.log</file>\n    <rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\">\n        <fileNamePattern>logs/app.%d{yyyy-MM-dd}.log</fileNamePattern>\n        <maxHistory>30</maxHistory>\n    </rollingPolicy>\n    <encoder>\n        <pattern>%d [%thread] %-5level %logger{36} - %msg%n</pattern>\n    </encoder>\n</appender>",
            "explanation": "Logs messages to a file and rolls over daily, keeping logs for the last 30 days."
          },
          {
            "title": "Using MDC for contextual logging",
            "code": "import org.slf4j.MDC;\n\nMDC.put(\"userId\", \"12345\");\nlogger.info(\"User logged in\");\nMDC.clear();",
            "explanation": "Adds contextual information (e.g., user ID) to logs using Mapped Diagnostic Context."
          },
          {
            "title": "Async logging",
            "code": "<appender name=\"ASYNC\" class=\"ch.qos.logback.classic.AsyncAppender\">\n    <appender-ref ref=\"FILE\" />\n</appender>",
            "explanation": "Wraps an existing appender with an asynchronous appender to improve performance for high-volume logging."
          }
        ],
        "best_practices": [
          "Use SLF4J API for logging to allow swapping underlying logging frameworks.",
          "Avoid logging sensitive information in production logs.",
          "Use appropriate log levels (DEBUG for development, INFO/WARN/ERROR for production).",
          "Configure rolling appenders to prevent log files from growing indefinitely.",
          "Leverage MDC or structured logging for better traceability."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundException",
            "solution": "Ensure log file paths are correct and the application has write permissions."
          },
          {
            "error": "PatternLayout encoder errors",
            "solution": "Check the logback pattern configuration and validate the syntax."
          }
        ]
      },
      "references": {
        "official_docs": "http://logback.qos.ch/documentation.html",
        "github": "https://github.com/qos-ch/logback"
      }
    },
    {
      "id": "micrometer",
      "name": "Micrometer",
      "category": "Monitoring / Metrics",
      "description": "Micrometer is a metrics instrumentation library for Java applications that provides a vendor-neutral interface for capturing application metrics and exposing them to monitoring systems. It supports counters, gauges, timers, distribution summaries, and more.",
      "story": "Micrometer was developed to unify metrics collection in Java applications, particularly for modern microservices architectures. It integrates seamlessly with Spring Boot and provides adapters for popular monitoring systems like Prometheus, Graphite, Datadog, and New Relic. This enables developers to monitor performance, track business metrics, and diagnose issues in production environments.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>io.micrometer</groupId>\n  <artifactId>micrometer-core</artifactId>\n  <version>1.12.1</version>\n</dependency>",
        "gradle": "implementation 'io.micrometer:micrometer-core:1.12.1'"
      },
      "usage": {
        "overview": "Micrometer provides a consistent API to record metrics like counters, gauges, timers, and distribution summaries. Metrics can be tagged for filtering and organized for export to external monitoring systems.",
        "basic_examples": [
          {
            "title": "Creating a counter",
            "code": "import io.micrometer.core.instrument.MeterRegistry;\nimport io.micrometer.core.instrument.Counter;\n\nCounter counter = registry.counter(\"requests_total\");\ncounter.increment();",
            "explanation": "Creates a counter metric and increments it to track the total number of requests."
          },
          {
            "title": "Creating a gauge",
            "code": "import io.micrometer.core.instrument.Gauge;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nAtomicInteger queueSize = new AtomicInteger(0);\nGauge.builder(\"queue.size\", queueSize, AtomicInteger::get)\n     .register(registry);",
            "explanation": "Creates a gauge metric to monitor the current size of a queue."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using a timer",
            "code": "import io.micrometer.core.instrument.Timer;\n\nTimer timer = registry.timer(\"requests_latency\");\ntimer.record(() -> {\n    // code to measure\n});",
            "explanation": "Measures the execution time of a code block and records it as a timer metric."
          },
          {
            "title": "Distribution summary",
            "code": "import io.micrometer.core.instrument.DistributionSummary;\n\nDistributionSummary summary = DistributionSummary.builder(\"payload.size\").register(registry);\nsummary.record(1024);",
            "explanation": "Records numeric values to track distributions, e.g., payload sizes."
          },
          {
            "title": "Tagging metrics",
            "code": "Counter counter = Counter.builder(\"requests_total\")\n    .tags(\"endpoint\", \"/api/users\", \"status\", \"success\")\n    .register(registry);\ncounter.increment();",
            "explanation": "Adds tags to metrics for filtering and aggregation in monitoring systems."
          },
          {
            "title": "Publishing to Prometheus",
            "code": "import io.micrometer.prometheus.PrometheusMeterRegistry;\n\nPrometheusMeterRegistry prometheusRegistry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);",
            "explanation": "Configures Micrometer to expose metrics in Prometheus format for scraping by monitoring tools."
          }
        ],
        "best_practices": [
          "Instrument all important business and technical metrics using counters, gauges, and timers.",
          "Use tags to differentiate metrics by dimensions like endpoint, region, or user.",
          "Export metrics to a centralized monitoring system for alerting and visualization.",
          "Avoid high-cardinality tags that can overwhelm the monitoring backend.",
          "Leverage Micrometer integration with Spring Boot Actuator for automatic metrics collection."
        ],
        "error_handling": [
          {
            "error": "MeterAlreadyExistsException",
            "solution": "Occurs if a metric with the same name and tags is registered multiple times. Reuse existing metrics or use unique tags."
          },
          {
            "error": "No registry configured",
            "solution": "Ensure a MeterRegistry instance is available and properly configured before registering metrics."
          }
        ]
      },
      "references": {
        "official_docs": "https://micrometer.io/docs",
        "github": "https://github.com/micrometer-metrics/micrometer"
      }
    },
    {
      "id": "protobuf",
      "name": "Protocol Buffers (Protobuf)",
      "category": "Serialization / Messaging",
      "description": "Protocol Buffers (Protobuf) is a language-neutral, platform-neutral, and extensible mechanism for serializing structured data. It is used to efficiently encode data for communication between services, storage, or configuration in Java applications.",
      "story": "Protobuf was developed by Google to provide a faster and smaller alternative to XML and JSON for serializing structured data. It supports backward and forward compatibility, strong typing, and works across multiple languages. Protobuf is widely used in RPC systems, microservices, data storage, and messaging applications.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>com.google.protobuf</groupId>\n  <artifactId>protobuf-java</artifactId>\n  <version>3.24.3</version>\n</dependency>",
        "gradle": "implementation 'com.google.protobuf:protobuf-java:3.24.3'"
      },
      "usage": {
        "overview": "Protobuf allows you to define structured data in `.proto` files, generate Java classes, and serialize/deserialize data efficiently. It supports messages, enums, nested structures, and repeated fields.",
        "basic_examples": [
          {
            "title": "Defining a message in a .proto file",
            "code": "syntax = \"proto3\";\n\nmessage Person {\n  string name = 1;\n  int32 id = 2;\n  string email = 3;\n}",
            "explanation": "Defines a simple `Person` message with `name`, `id`, and `email` fields."
          },
          {
            "title": "Generating Java classes",
            "code": "# Using protoc compiler\nprotoc --java_out=src/main/java person.proto",
            "explanation": "Generates Java classes from the .proto definition for use in your application."
          }
        ],
        "advanced_examples": [
          {
            "title": "Serializing a message",
            "code": "Person person = Person.newBuilder()\n    .setName(\"Alice\")\n    .setId(1)\n    .setEmail(\"alice@example.com\")\n    .build();\n\nbyte[] data = person.toByteArray();",
            "explanation": "Builds a Protobuf message and serializes it to a byte array for storage or transmission."
          },
          {
            "title": "Deserializing a message",
            "code": "Person parsedPerson = Person.parseFrom(data);\nSystem.out.println(parsedPerson.getName());",
            "explanation": "Parses a byte array back into a Protobuf message instance."
          },
          {
            "title": "Using nested messages and enums",
            "code": "message AddressBook {\n  repeated Person people = 1;\n}\n\nAddressBook book = AddressBook.newBuilder()\n    .addPeople(person)\n    .build();",
            "explanation": "Shows how to define repeated (list) fields and nested messages in Protobuf."
          },
          {
            "title": "Working with optional and default values",
            "code": "Person person = Person.newBuilder()\n    .setName(\"Bob\")\n    .build();\nSystem.out.println(person.getEmail()); // empty string as default",
            "explanation": "Optional fields take default values if not explicitly set."
          }
        ],
        "best_practices": [
          "Use `.proto` version 3 syntax for simplicity and modern features.",
          "Leverage repeated fields instead of lists for efficient storage.",
          "Keep backward and forward compatibility by assigning unique field numbers.",
          "Avoid removing fields; deprecate them instead to maintain compatibility.",
          "Use Protobuf for inter-service communication, storage, or network efficiency."
        ],
        "error_handling": [
          {
            "error": "InvalidProtocolBufferException",
            "solution": "Occurs when parsing corrupted or incompatible byte arrays. Ensure the data matches the message schema."
          },
          {
            "error": "Missing required fields",
            "solution": "Ensure all required fields are set before serialization (for proto2 syntax) or rely on default values (proto3)."
          }
        ]
      },
      "references": {
        "official_docs": "https://developers.google.com/protocol-buffers/docs/javatutorial",
        "github": "https://github.com/protocolbuffers/protobuf"
      }
    },
    {
      "id": "avro",
      "name": "Apache Avro",
      "category": "Serialization / Data",
      "description": "Apache Avro is a data serialization system that provides compact, fast, and binary data serialization for Java and other languages. It is widely used in big data ecosystems for storing and transmitting structured data efficiently.",
      "story": "Avro was created as part of the Hadoop project to provide a language-agnostic, schema-based serialization system. It allows schemas to evolve over time, supports rich data structures, and integrates seamlessly with Hadoop, Kafka, and other big data tools. Its compact binary format and dynamic typing make it efficient for data storage and streaming.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.avro</groupId>\n  <artifactId>avro</artifactId>\n  <version>1.12.3</version>\n</dependency>",
        "gradle": "implementation 'org.apache.avro:avro:1.12.3'"
      },
      "usage": {
        "overview": "Avro uses JSON-defined schemas to generate Java classes. It supports serialization, deserialization, and schema evolution. Avro can serialize data in a compact binary format or a readable JSON format.",
        "basic_examples": [
          {
            "title": "Defining an Avro schema (user.avsc)",
            "code": "{\n  \"type\": \"record\",\n  \"name\": \"User\",\n  \"namespace\": \"com.example\",\n  \"fields\": [\n    {\"name\": \"name\", \"type\": \"string\"},\n    {\"name\": \"age\", \"type\": \"int\"}\n  ]\n}",
            "explanation": "Defines a simple Avro record `User` with `name` and `age` fields."
          },
          {
            "title": "Generating Java classes",
            "code": "# Using avro-tools\njava -jar avro-tools-1.12.3.jar compile schema user.avsc src/main/java",
            "explanation": "Generates Java classes from the Avro schema for use in serialization/deserialization."
          }
        ],
        "advanced_examples": [
          {
            "title": "Serializing a record",
            "code": "User user = User.newBuilder().setName(\"Alice\").setAge(30).build();\nByteArrayOutputStream out = new ByteArrayOutputStream();\nDatumWriter<User> writer = new SpecificDatumWriter<>(User.class);\nBinaryEncoder encoder = EncoderFactory.get().binaryEncoder(out, null);\nwriter.write(user, encoder);\nencoder.flush();\nbyte[] serializedData = out.toByteArray();",
            "explanation": "Serializes a `User` object to a compact binary format."
          },
          {
            "title": "Deserializing a record",
            "code": "DatumReader<User> reader = new SpecificDatumReader<>(User.class);\nBinaryDecoder decoder = DecoderFactory.get().binaryDecoder(serializedData, null);\nUser deserializedUser = reader.read(null, decoder);\nSystem.out.println(deserializedUser.getName());",
            "explanation": "Deserializes binary data back into a `User` object."
          },
          {
            "title": "Using GenericRecord without code generation",
            "code": "Schema schema = new Schema.Parser().parse(new File(\"user.avsc\"));\nGenericRecord record = new GenericData.Record(schema);\nrecord.put(\"name\", \"Bob\");\nrecord.put(\"age\", 25);",
            "explanation": "Demonstrates dynamic usage of Avro records without generating Java classes."
          },
          {
            "title": "Schema evolution",
            "code": "// Add a new optional field in schema without breaking old data\n{ \"name\": \"email\", \"type\": [\"null\", \"string\"], \"default\": null }",
            "explanation": "Supports adding optional fields while maintaining backward and forward compatibility."
          }
        ],
        "best_practices": [
          "Use specific Java classes for better type safety when possible.",
          "Leverage default values in schemas for schema evolution.",
          "Use Avro binary format for compact storage and JSON format for readability during debugging.",
          "Integrate with Kafka or Hadoop for streaming and batch data processing.",
          "Validate schemas before serialization to prevent runtime errors."
        ],
        "error_handling": [
          {
            "error": "AvroTypeException",
            "solution": "Occurs when data does not match the schema type. Ensure the data conforms to the defined schema."
          },
          {
            "error": "IOException during serialization/deserialization",
            "solution": "Check streams, encoders, decoders, and ensure proper closing of resources."
          }
        ]
      },
      "references": {
        "official_docs": "https://avro.apache.org/docs/current/",
        "github": "https://github.com/apache/avro"
      }
    },
    {
      "id": "jetty",
      "name": "Jetty",
      "category": "Web / HTTP Server",
      "description": "Jetty is a lightweight, high-performance Java HTTP server and servlet container. It provides an embedded web server, making it easy to integrate into Java applications for serving web content, REST APIs, or acting as a backend server.",
      "story": "Jetty was created to offer a flexible and embeddable Java web server for developers. Unlike traditional servlet containers, Jetty can be embedded directly into applications, giving developers control over server lifecycle, configuration, and deployment. It is widely used in microservices, frameworks, and standalone Java applications requiring HTTP capabilities.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>jetty-server</artifactId>\n  <version>11.0.20</version>\n</dependency>\n<dependency>\n  <groupId>org.eclipse.jetty</groupId>\n  <artifactId>jetty-servlet</artifactId>\n  <version>11.0.20</version>\n</dependency>",
        "gradle": "implementation 'org.eclipse.jetty:jetty-server:11.0.20'\nimplementation 'org.eclipse.jetty:jetty-servlet:11.0.20'"
      },
      "usage": {
        "overview": "Jetty allows you to create embedded HTTP servers, deploy servlets, handle REST APIs, and manage asynchronous requests. It is suitable for both standalone applications and integration with frameworks like Spring or Jersey.",
        "basic_examples": [
          {
            "title": "Starting a simple embedded Jetty server",
            "code": "import org.eclipse.jetty.server.Server;\n\nServer server = new Server(8080);\nserver.start();\nserver.join();",
            "explanation": "Creates and starts a Jetty server listening on port 8080."
          },
          {
            "title": "Adding a servlet",
            "code": "import org.eclipse.jetty.servlet.ServletContextHandler;\nimport org.eclipse.jetty.servlet.ServletHolder;\nimport jakarta.servlet.http.HttpServlet;\nimport jakarta.servlet.http.HttpServletRequest;\nimport jakarta.servlet.http.HttpServletResponse;\n\nServletContextHandler context = new ServletContextHandler(ServletContextHandler.SESSIONS);\ncontext.setContextPath(\"/\");\nserver.setHandler(context);\n\ncontext.addServlet(new ServletHolder(new HttpServlet() {\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) {\n        resp.getWriter().println(\"Hello from Jetty!\");\n    }\n}), \"/hello\");",
            "explanation": "Registers a simple servlet that responds with 'Hello from Jetty!' to GET requests on `/hello`."
          }
        ],
        "advanced_examples": [
          {
            "title": "Handling asynchronous requests",
            "code": "context.addServlet(new ServletHolder(new HttpServlet() {\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) {\n        AsyncContext async = req.startAsync();\n        async.start(() -> {\n            try {\n                Thread.sleep(1000);\n                resp.getWriter().println(\"Async response\");\n                async.complete();\n            } catch(Exception e) { e.printStackTrace(); }\n        });\n    }\n}), \"/async\");",
            "explanation": "Demonstrates handling asynchronous HTTP requests to improve scalability."
          },
          {
            "title": "Deploying REST API with Jetty + Jersey",
            "code": "import org.glassfish.jersey.server.ResourceConfig;\nimport org.glassfish.jersey.servlet.ServletContainer;\n\nResourceConfig config = new ResourceConfig().packages(\"com.example.resources\");\nServletHolder jerseyServlet = new ServletHolder(new ServletContainer(config));\ncontext.addServlet(jerseyServlet, \"/api/*\");",
            "explanation": "Integrates Jetty with Jersey to serve RESTful APIs."
          },
          {
            "title": "Setting HTTPS",
            "code": "import org.eclipse.jetty.util.ssl.SslContextFactory;\n\nSslContextFactory.Server sslContextFactory = new SslContextFactory.Server();\nsslContextFactory.setKeyStorePath(\"keystore.jks\");\nsslContextFactory.setKeyStorePassword(\"password\");\nServerConnector sslConnector = new ServerConnector(server, sslContextFactory);\nsslConnector.setPort(8443);\nserver.addConnector(sslConnector);",
            "explanation": "Configures Jetty to serve HTTPS requests using a keystore."
          }
        ],
        "best_practices": [
          "Use embedded Jetty for microservices and standalone applications for better control.",
          "Handle exceptions within servlets to avoid server crashes.",
          "Use thread pools and async requests to handle high concurrency.",
          "Keep server configuration externalized for flexibility in different environments.",
          "Combine with frameworks like Spring Boot for easier configuration and dependency injection."
        ],
        "error_handling": [
          {
            "error": "BindException: Address already in use",
            "solution": "Ensure the configured port is free or change to another port before starting the server."
          },
          {
            "error": "ServletException",
            "solution": "Occurs when servlet initialization or processing fails. Check servlet code and mappings."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.eclipse.org/jetty/documentation/",
        "github": "https://github.com/eclipse/jetty.project"
      }
    },
    {
      "id": "httpcomponents",
      "name": "Apache HttpComponents",
      "category": "HTTP / Networking",
      "description": "Apache HttpComponents is a set of Java libraries for client-side and server-side HTTP communication. The most commonly used module is HttpClient, which provides a robust and flexible API for sending HTTP requests and handling responses.",
      "story": "HttpComponents was developed by the Apache Software Foundation to provide a reliable and extensible HTTP client and server implementation for Java. It is widely used for interacting with REST APIs, web scraping, and performing network requests with fine-grained control over connections, cookies, and authentication.",
      "installation": {
        "maven": "Add dependency in pom.xml:\n<dependency>\n  <groupId>org.apache.httpcomponents.client5</groupId>\n  <artifactId>httpclient5</artifactId>\n  <version>5.3.1</version>\n</dependency>",
        "gradle": "implementation 'org.apache.httpcomponents.client5:httpclient5:5.3.1'"
      },
      "usage": {
        "overview": "HttpComponents HttpClient allows you to send HTTP requests (GET, POST, PUT, DELETE, etc.), handle headers, cookies, authentication, and manage connection pooling. It supports synchronous and asynchronous operations and integrates easily with Java applications.",
        "basic_examples": [
          {
            "title": "Simple GET request",
            "code": "import org.apache.hc.client5.http.fluent.Request;\n\nString response = Request.get(\"https://httpbin.org/get\").execute().returnContent().asString();\nSystem.out.println(response);",
            "explanation": "Performs a simple HTTP GET request and prints the response content."
          },
          {
            "title": "POST request with JSON payload",
            "code": "import org.apache.hc.client5.http.fluent.Request;\nimport org.apache.hc.core5.http.ContentType;\n\nString json = \"{\\\"key\\\":\\\"value\\\"}\";\nString response = Request.post(\"https://httpbin.org/post\")\n    .bodyString(json, ContentType.APPLICATION_JSON)\n    .execute().returnContent().asString();\nSystem.out.println(response);",
            "explanation": "Sends a POST request with a JSON payload and prints the response."
          }
        ],
        "advanced_examples": [
          {
            "title": "Custom headers and authentication",
            "code": "import org.apache.hc.client5.http.impl.classic.CloseableHttpClient;\nimport org.apache.hc.client5.http.impl.classic.HttpClients;\nimport org.apache.hc.client5.http.classic.methods.HttpGet;\nimport org.apache.hc.core5.http.io.entity.EntityUtils;\n\nCloseableHttpClient client = HttpClients.custom().build();\nHttpGet request = new HttpGet(\"https://httpbin.org/headers\");\nrequest.addHeader(\"Authorization\", \"Bearer TOKEN\");\nString response = client.execute(request, httpResponse -> EntityUtils.toString(httpResponse.getEntity()));\nSystem.out.println(response);",
            "explanation": "Demonstrates setting custom HTTP headers and using authentication tokens."
          },
          {
            "title": "Connection pooling",
            "code": "import org.apache.hc.client5.http.impl.io.PoolingHttpClientConnectionManager;\nimport org.apache.hc.client5.http.impl.classic.CloseableHttpClient;\nimport org.apache.hc.client5.http.impl.classic.HttpClients;\n\nPoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();\ncm.setMaxTotal(100);\ncm.setDefaultMaxPerRoute(20);\nCloseableHttpClient client = HttpClients.custom().setConnectionManager(cm).build();",
            "explanation": "Uses a connection pool to efficiently manage multiple concurrent HTTP requests."
          },
          {
            "title": "Handling timeouts",
            "code": "import org.apache.hc.client5.http.config.RequestConfig;\nRequestConfig config = RequestConfig.custom()\n    .setConnectTimeout(5000)\n    .setResponseTimeout(5000)\n    .build();\nHttpGet request = new HttpGet(\"https://httpbin.org/delay/10\");\nrequest.setConfig(config);",
            "explanation": "Configures connection and response timeouts to prevent hanging requests."
          },
          {
            "title": "Asynchronous request execution",
            "code": "import org.apache.hc.client5.http.impl.async.CloseableHttpAsyncClient;\nimport org.apache.hc.client5.http.impl.async.HttpAsyncClients;\nimport org.apache.hc.client5.http.async.methods.SimpleHttpRequest;\nimport java.util.concurrent.Future;\n\nCloseableHttpAsyncClient asyncClient = HttpAsyncClients.createDefault();\nasyncClient.start();\nFuture response = asyncClient.execute(SimpleHttpRequest.create(\"GET\", \"https://httpbin.org/get\"), null);\nSystem.out.println(response.get());",
            "explanation": "Executes HTTP requests asynchronously to improve performance in high-concurrency scenarios."
          }
        ],
        "best_practices": [
          "Reuse HttpClient instances to take advantage of connection pooling.",
          "Always close responses and clients to avoid resource leaks.",
          "Set appropriate timeouts to prevent blocking in network failures.",
          "Handle exceptions like IOException, HttpException to manage request failures.",
          "Use asynchronous clients for scalable, non-blocking HTTP requests."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs due to network issues or unreachable endpoints. Check connectivity and URLs."
          },
          {
            "error": "HttpResponseException",
            "solution": "Thrown when the server responds with an unexpected HTTP status code. Handle response codes appropriately."
          },
          {
            "error": "ConnectionPoolTimeoutException",
            "solution": "Occurs when connection pool is exhausted. Increase pool size or reuse clients efficiently."
          }
        ]
      },
      "references": {
        "official_docs": "https://hc.apache.org/httpcomponents-client-5.3.x/index.html",
        "github": "https://github.com/apache/httpcomponents-client"
      }
    },
    {
      "id": "spring-cloud",
      "name": "Spring Cloud",
      "category": "Microservices / Cloud",
      "description": "Spring Cloud provides a suite of tools for building distributed systems and microservices in Java. It integrates with Spring Boot to offer service discovery, configuration management, load balancing, circuit breakers, messaging, and cloud-native patterns.",
      "story": "Spring Cloud was developed to simplify the development of microservices and distributed systems in the Spring ecosystem. It abstracts common challenges such as service registration, configuration synchronization, messaging, and resiliency. Widely adopted in enterprise applications, Spring Cloud allows developers to quickly build scalable, fault-tolerant microservices on cloud platforms.",
      "installation": {
        "maven": "Add dependencies in pom.xml:\n<dependency>\n  <groupId>org.springframework.cloud</groupId>\n  <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n  <version>3.1.6</version>\n</dependency>\n<dependency>\n  <groupId>org.springframework.cloud</groupId>\n  <artifactId>spring-cloud-starter-config</artifactId>\n  <version>3.1.6</version>\n</dependency>",
        "gradle": "implementation 'org.springframework.cloud:spring-cloud-starter-netflix-eureka-client:3.1.6'\nimplementation 'org.springframework.cloud:spring-cloud-starter-config:3.1.6'"
      },
      "usage": {
        "overview": "Spring Cloud provides tools for service discovery (Eureka), configuration management (Spring Cloud Config), distributed messaging (Spring Cloud Stream), API gateway (Spring Cloud Gateway), load balancing (Ribbon), and resiliency (Hystrix / Resilience4j).",
        "basic_examples": [
          {
            "title": "Eureka Client Registration",
            "code": "@SpringBootApplication\n@EnableEurekaClient\npublic class MyServiceApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(MyServiceApplication.class, args);\n    }\n}",
            "explanation": "Registers a Spring Boot application as a Eureka client for service discovery."
          },
          {
            "title": "Fetching configuration from Spring Cloud Config",
            "code": "@RefreshScope\n@RestController\npublic class ConfigController {\n    @Value(\"${example.property}\")\n    private String property;\n\n    @GetMapping(\"/property\")\n    public String getProperty() {\n        return property;\n    }\n}",
            "explanation": "Reads properties from a centralized Spring Cloud Config server and exposes them via a REST endpoint."
          }
        ],
        "advanced_examples": [
          {
            "title": "Load-balanced RestTemplate",
            "code": "@Bean\n@LoadBalanced\npublic RestTemplate restTemplate() {\n    return new RestTemplate();\n}\n\nString response = restTemplate.getForObject(\"http://my-service/endpoint\", String.class);",
            "explanation": "Uses service names instead of hard-coded URLs, with automatic client-side load balancing via Ribbon."
          },
          {
            "title": "Circuit breaker with Resilience4j",
            "code": "@RestController\npublic class MyController {\n    @Autowired\n    private SomeService service;\n\n    @GetMapping(\"/call\")\n    @CircuitBreaker(name = \"backendService\", fallbackMethod = \"fallback\")\n    public String callService() {\n        return service.call();\n    }\n\n    public String fallback(Throwable t) {\n        return \"Fallback response\";\n    }\n}",
            "explanation": "Implements a circuit breaker pattern to gracefully handle service failures."
          },
          {
            "title": "Spring Cloud Gateway route",
            "code": "@Bean\npublic RouteLocator customRouteLocator(RouteLocatorBuilder builder) {\n    return builder.routes()\n        .route(\"path_route\", r -> r.path(\"/get\")\n            .uri(\"http://httpbin.org\"))\n        .build();\n}",
            "explanation": "Configures an API gateway route to forward requests to another service."
          },
          {
            "title": "Spring Cloud Stream with Kafka",
            "code": "@EnableBinding(Sink.class)\npublic class MyStreamListener {\n    @StreamListener(Sink.INPUT)\n    public void handle(String message) {\n        System.out.println(\"Received: \" + message);\n    }\n}",
            "explanation": "Consumes messages from a messaging broker using Spring Cloud Stream abstraction."
          }
        ],
        "best_practices": [
          "Use Spring Cloud Config for centralized configuration and environment management.",
          "Leverage service discovery (Eureka, Consul) for dynamic routing.",
          "Implement circuit breakers and retries for resiliency.",
          "Use Spring Cloud Gateway for routing and API management.",
          "Monitor and log distributed systems with Sleuth, Zipkin, or Micrometer."
        ],
        "error_handling": [
          {
            "error": "ServiceUnavailableException",
            "solution": "Occurs when a service cannot be discovered. Ensure Eureka server is running and services are registered."
          },
          {
            "error": "Configuration refresh not applied",
            "solution": "Use /actuator/refresh endpoint or @RefreshScope to reload updated properties from Config Server."
          },
          {
            "error": "CircuitBreakerOpenException",
            "solution": "Thrown when circuit breaker is open. Check service availability and fallback methods."
          }
        ]
      },
      "references": {
        "official_docs": "https://spring.io/projects/spring-cloud",
        "github": "https://github.com/spring-cloud"
      }
    },
    {
      "id": "service-discovery-clients",
      "name": "Consul / Eureka Clients",
      "category": "Microservices / Service Discovery",
      "description": "Consul and Eureka are popular service discovery tools for microservices. Java clients integrate applications with these services, enabling automatic registration, service lookup, and health monitoring for distributed systems.",
      "story": "As microservices architectures grew, managing service instances dynamically became essential. Eureka (from Netflix) and Consul (from HashiCorp) provide registries where services register themselves and discover other services at runtime. Java client libraries simplify integrating Spring Boot and other Java applications with these service registries, improving scalability, load balancing, and fault tolerance.",
      "installation": {
        "maven": "Eureka Client:\n<dependency>\n  <groupId>org.springframework.cloud</groupId>\n  <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n  <version>3.1.6</version>\n</dependency>\n\nConsul Client:\n<dependency>\n  <groupId>org.springframework.cloud</groupId>\n  <artifactId>spring-cloud-starter-consul-discovery</artifactId>\n  <version>3.1.6</version>\n</dependency>",
        "gradle": "implementation 'org.springframework.cloud:spring-cloud-starter-netflix-eureka-client:3.1.6'\nimplementation 'org.springframework.cloud:spring-cloud-starter-consul-discovery:3.1.6'"
      },
      "usage": {
        "overview": "Clients for Eureka or Consul enable automatic registration of services, health check management, and runtime discovery of other services. This allows Java microservices to communicate without hardcoded URLs, supporting dynamic scaling and resiliency.",
        "basic_examples": [
          {
            "title": "Eureka Client Registration",
            "code": "@SpringBootApplication\n@EnableEurekaClient\npublic class MyApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(MyApplication.class, args);\n    }\n}",
            "explanation": "Registers a Spring Boot application with a Eureka server for service discovery."
          },
          {
            "title": "Consul Client Registration",
            "code": "@SpringBootApplication\n@EnableDiscoveryClient\npublic class MyConsulApp {\n    public static void main(String[] args) {\n        SpringApplication.run(MyConsulApp.class, args);\n    }\n}",
            "explanation": "Registers a Spring Boot application with Consul for service discovery and health checks."
          }
        ],
        "advanced_examples": [
          {
            "title": "Service lookup with RestTemplate",
            "code": "@Bean\n@LoadBalanced\nRestTemplate restTemplate() {\n    return new RestTemplate();\n}\n\nString response = restTemplate.getForObject(\"http://MY-SERVICE/endpoint\", String.class);",
            "explanation": "Uses service names instead of hardcoded URLs with client-side load balancing for Eureka or Consul."
          },
          {
            "title": "Health checks and metadata",
            "code": "management.endpoint.health.show-details=always\nspring.cloud.consul.discovery.health-check-path=/actuator/health",
            "explanation": "Configures health check endpoints and service metadata for Consul or Eureka."
          },
          {
            "title": "Dynamic service registration",
            "code": "spring.application.name=my-service\nspring.cloud.consul.discovery.instance-id=${spring.application.name}-${random.value}",
            "explanation": "Automatically generates unique instance IDs for dynamic registration in Consul."
          }
        ],
        "best_practices": [
          "Use client-side load balancing with RestTemplate or WebClient for scalable calls.",
          "Configure health check endpoints to detect unhealthy instances quickly.",
          "Set proper instance metadata and service names for easier monitoring.",
          "Enable circuit breakers and retries for service-to-service communication.",
          "Monitor service registries for changes and remove stale instances periodically."
        ],
        "error_handling": [
          {
            "error": "ServiceNotFoundException",
            "solution": "Occurs when the requested service is not registered or unavailable. Ensure the service is running and registered with Eureka/Consul."
          },
          {
            "error": "Connection refused",
            "solution": "Check that the Eureka or Consul server is running and reachable from the client."
          },
          {
            "error": "Timeout during discovery",
            "solution": "Increase timeout or check network connectivity between services and the registry."
          }
        ]
      },
      "references": {
        "official_docs": "https://spring.io/projects/spring-cloud-netflix\nhttps://www.consul.io/docs",
        "github": "https://github.com/spring-cloud/spring-cloud-netflix\nhttps://github.com/hashicorp/consul"
      }
    },
    {
      "id": "apache-poi",
      "name": "Apache POI",
      "category": "Data / Office",
      "description": "Apache POI is a Java library for reading and writing Microsoft Office file formats, including Excel, Word, and PowerPoint. It enables Java applications to manipulate spreadsheets, documents, and presentations programmatically.",
      "story": "Apache POI was developed to allow Java developers to interact with Microsoft Office files without relying on COM or Microsoft APIs. It provides comprehensive support for both older binary formats (e.g., XLS, DOC) and newer OOXML formats (e.g., XLSX, DOCX). Widely used in enterprise applications, POI allows automation of reports, document generation, and data extraction.",
      "installation": {
        "maven": "Add dependencies in pom.xml:\n<dependency>\n  <groupId>org.apache.poi</groupId>\n  <artifactId>poi</artifactId>\n  <version>5.2.3</version>\n</dependency>\n<dependency>\n  <groupId>org.apache.poi</groupId>\n  <artifactId>poi-ooxml</artifactId>\n  <version>5.2.3</version>\n</dependency>",
        "gradle": "implementation 'org.apache.poi:poi:5.2.3'\nimplementation 'org.apache.poi:poi-ooxml:5.2.3'"
      },
      "usage": {
        "overview": "Apache POI provides APIs to read, write, and manipulate Microsoft Office files. For Excel, it supports HSSF (XLS) and XSSF (XLSX). For Word, it supports HWPF (DOC) and XWPF (DOCX). POI can create new documents, read existing files, update cell values, style sheets, and generate charts.",
        "basic_examples": [
          {
            "title": "Reading an Excel file",
            "code": "import org.apache.poi.ss.usermodel.*;\nimport java.io.*;\n\nFileInputStream fis = new FileInputStream(\"example.xlsx\");\nWorkbook workbook = WorkbookFactory.create(fis);\nSheet sheet = workbook.getSheetAt(0);\nfor (Row row : sheet) {\n    for (Cell cell : row) {\n        System.out.print(cell + \"\\t\");\n    }\n    System.out.println();\n}\nworkbook.close();\nfis.close();",
            "explanation": "Reads all rows and cells from the first sheet of an Excel file and prints the content."
          },
          {
            "title": "Writing to an Excel file",
            "code": "Workbook workbook = new XSSFWorkbook();\nSheet sheet = workbook.createSheet(\"Data\");\nRow row = sheet.createRow(0);\nrow.createCell(0).setCellValue(\"Name\");\nrow.createCell(1).setCellValue(\"Age\");\nFileOutputStream fos = new FileOutputStream(\"output.xlsx\");\nworkbook.write(fos);\nfos.close();\nworkbook.close();",
            "explanation": "Creates a new Excel file with a header row containing 'Name' and 'Age'."
          }
        ],
        "advanced_examples": [
          {
            "title": "Styling cells",
            "code": "CellStyle style = workbook.createCellStyle();\nFont font = workbook.createFont();\nfont.setBold(true);\nstyle.setFont(font);\nrow.getCell(0).setCellStyle(style);",
            "explanation": "Applies bold font styling to a cell in Excel."
          },
          {
            "title": "Creating a Word document",
            "code": "import org.apache.poi.xwpf.usermodel.*;\nXWPFDocument document = new XWPFDocument();\nXWPFParagraph paragraph = document.createParagraph();\nXWPFRun run = paragraph.createRun();\nrun.setText(\"Hello, Apache POI!\");\nFileOutputStream fos = new FileOutputStream(\"document.docx\");\ndocument.write(fos);\nfos.close();\ndocument.close();",
            "explanation": "Creates a new Word document with a paragraph of text."
          },
          {
            "title": "Reading a Word document",
            "code": "FileInputStream fis = new FileInputStream(\"document.docx\");\nXWPFDocument document = new XWPFDocument(fis);\nfor (XWPFParagraph para : document.getParagraphs()) {\n    System.out.println(para.getText());\n}\ndocument.close();\nfis.close();",
            "explanation": "Reads and prints all paragraphs from an existing Word document."
          },
          {
            "title": "Generating a PowerPoint presentation",
            "code": "import org.apache.poi.xslf.usermodel.*;\nXMLSlideShow ppt = new XMLSlideShow();\nXSLFSlide slide = ppt.createSlide();\nXSLFTextBox box = slide.createTextBox();\nbox.setText(\"Welcome to Apache POI PowerPoint\");\nFileOutputStream fos = new FileOutputStream(\"presentation.pptx\");\nppt.write(fos);\nfos.close();\nppt.close();",
            "explanation": "Creates a new PowerPoint presentation with a single slide and text box."
          }
        ],
        "best_practices": [
          "Always close Workbooks, Documents, and Streams to prevent resource leaks.",
          "Use XSSF for XLSX and HSSF for XLS to maintain compatibility.",
          "Leverage cell styles and formatting sparingly to improve performance.",
          "Validate file existence and handle IOException when reading or writing files.",
          "Use streaming APIs (SXSSF) for writing large Excel files efficiently."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when the file cannot be read or written. Ensure the file exists and you have proper permissions."
          },
          {
            "error": "EncryptedDocumentException",
            "solution": "Thrown when trying to open a password-protected Excel file without credentials. Provide a password or skip protected files."
          },
          {
            "error": "IllegalStateException: Cannot get a numeric value from a string cell",
            "solution": "Ensure you read cell types correctly; check `cell.getCellType()` before accessing content."
          }
        ]
      },
      "references": {
        "official_docs": "https://poi.apache.org/",
        "github": "https://github.com/apache/poi"
      }
    },
    {
      "id": "pdf-libraries",
      "name": "iText / PDFBox",
      "category": "Data / PDF",
      "description": "iText and Apache PDFBox are Java libraries for creating, manipulating, and reading PDF documents. They allow developers to generate dynamic PDFs, extract content, fill forms, merge or split documents, and manage metadata programmatically.",
      "story": "With the increasing use of PDF for reports, invoices, and legal documents, Java developers needed robust libraries to handle PDFs. iText, initially released in 2000, and PDFBox, an Apache project, provide comprehensive APIs to work with PDF files without relying on external applications. They are widely used in enterprise systems for automated PDF generation and processing.",
      "installation": {
        "maven": "iText:\n<dependency>\n  <groupId>com.itextpdf</groupId>\n  <artifactId>itext7-core</artifactId>\n  <version>7.2.5</version>\n</dependency>\n\nPDFBox:\n<dependency>\n  <groupId>org.apache.pdfbox</groupId>\n  <artifactId>pdfbox</artifactId>\n  <version>3.0.0</version>\n</dependency>",
        "gradle": "implementation 'com.itextpdf:itext7-core:7.2.5'\nimplementation 'org.apache.pdfbox:pdfbox:3.0.0'"
      },
      "usage": {
        "overview": "iText and PDFBox provide APIs to create new PDFs, read existing documents, manipulate pages, extract text and metadata, encrypt/decrypt files, and fill PDF forms. iText has a commercial-friendly license for advanced features, while PDFBox is fully open-source under Apache License.",
        "basic_examples": [
          {
            "title": "Creating a simple PDF with iText",
            "code": "import com.itextpdf.kernel.pdf.PdfWriter;\nimport com.itextpdf.kernel.pdf.PdfDocument;\nimport com.itextpdf.layout.Document;\nimport com.itextpdf.layout.element.Paragraph;\n\nPdfWriter writer = new PdfWriter(\"example.pdf\");\nPdfDocument pdf = new PdfDocument(writer);\nDocument document = new Document(pdf);\ndocument.add(new Paragraph(\"Hello, iText PDF!\"));\ndocument.close();",
            "explanation": "Creates a new PDF file with a single paragraph using iText."
          },
          {
            "title": "Reading text from PDF with PDFBox",
            "code": "import org.apache.pdfbox.pdmodel.PDDocument;\nimport org.apache.pdfbox.text.PDFTextStripper;\nimport java.io.File;\n\nPDDocument document = PDDocument.load(new File(\"example.pdf\"));\nString text = new PDFTextStripper().getText(document);\nSystem.out.println(text);\ndocument.close();",
            "explanation": "Reads and prints all text from an existing PDF using PDFBox."
          }
        ],
        "advanced_examples": [
          {
            "title": "Merging PDFs with PDFBox",
            "code": "import org.apache.pdfbox.multipdf.PDFMergerUtility;\nPDFMergerUtility merger = new PDFMergerUtility();\nmerger.addSource(\"file1.pdf\");\nmerger.addSource(\"file2.pdf\");\nmerger.setDestinationFileName(\"merged.pdf\");\nmerger.mergeDocuments(null);",
            "explanation": "Combines multiple PDF files into a single document."
          },
          {
            "title": "Adding images with iText",
            "code": "import com.itextpdf.layout.element.Image;\nimport com.itextpdf.io.image.ImageDataFactory;\nImage img = new Image(ImageDataFactory.create(\"logo.png\"));\ndocument.add(img);",
            "explanation": "Adds an image to a PDF document using iText."
          },
          {
            "title": "Filling PDF forms with PDFBox",
            "code": "import org.apache.pdfbox.pdmodel.interactive.form.PDAcroForm;\nPDAcroForm form = document.getDocumentCatalog().getAcroForm();\nform.getField(\"name\").setValue(\"John Doe\");\ndocument.save(\"filled_form.pdf\");",
            "explanation": "Fills fields of an existing PDF form programmatically."
          },
          {
            "title": "Encrypting PDF with iText",
            "code": "pdf.protect(new StandardEncryption(EncryptionConstants.ENCRYPTION_AES_128, \"userpass\", \"ownerpass\"));",
            "explanation": "Adds password protection and encryption to a PDF document using iText."
          }
        ],
        "best_practices": [
          "Always close PDDocument or Document objects to release resources.",
          "Use streaming APIs for large PDFs to avoid memory issues.",
          "Validate PDF inputs when extracting text or filling forms.",
          "Consider licensing for iText if using advanced features in commercial applications.",
          "Use PDFBox for fully open-source projects and simpler PDF manipulation tasks."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when the PDF file cannot be read or written. Ensure the file exists and has proper permissions."
          },
          {
            "error": "COSVisitorException (iText)",
            "solution": "Thrown during PDF writing errors. Verify document structure and content."
          },
          {
            "error": "IllegalArgumentException: page number out of range",
            "solution": "Ensure you access existing pages correctly in a PDF when manipulating or extracting content."
          }
        ]
      },
      "references": {
        "official_docs": "https://itextpdf.com/en/resources/documentation\nhttps://pdfbox.apache.org/",
        "github": "https://github.com/itext/itext7\nhttps://github.com/apache/pdfbox"
      }
    },
    {
      "id": "jsoup",
      "name": "Jsoup",
      "category": "Web / HTML Parsing",
      "description": "Jsoup is a Java library for working with real-world HTML. It provides a convenient API for fetching URLs, parsing HTML, extracting and manipulating data, and cleaning user-submitted content to prevent XSS attacks.",
      "story": "Developed to simplify HTML parsing in Java, Jsoup allows developers to work with messy or malformed HTML similar to how jQuery does in JavaScript. It is widely used for web scraping, data extraction, content sanitization, and automated web interactions in Java applications.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.jsoup</groupId>\n  <artifactId>jsoup</artifactId>\n  <version>1.16.1</version>\n</dependency>",
        "gradle": "implementation 'org.jsoup:jsoup:1.16.1'"
      },
      "usage": {
        "overview": "Jsoup allows connecting to URLs, parsing HTML into a DOM-like structure, querying elements using CSS selectors, and manipulating content. It can also sanitize untrusted HTML and extract data for processing or storage.",
        "basic_examples": [
          {
            "title": "Fetching and parsing HTML from a URL",
            "code": "import org.jsoup.Jsoup;\nimport org.jsoup.nodes.Document;\n\nDocument doc = Jsoup.connect(\"https://example.com\").get();\nSystem.out.println(doc.title());",
            "explanation": "Connects to a web page, parses the HTML, and prints the page title."
          },
          {
            "title": "Parsing HTML from a string",
            "code": "String html = \"<html><body><p>Hello, Jsoup!</p></body></html>\";\nDocument doc = Jsoup.parse(html);\nSystem.out.println(doc.select(\"p\").text());",
            "explanation": "Parses an HTML string and extracts the text content of the `<p>` element."
          }
        ],
        "advanced_examples": [
          {
            "title": "Selecting elements with CSS selectors",
            "code": "Elements links = doc.select(\"a[href]\");\nfor (Element link : links) {\n    System.out.println(link.attr(\"href\") + \" -> \" + link.text());\n}",
            "explanation": "Selects all anchor elements with an href attribute and prints their URLs and text."
          },
          {
            "title": "Extracting and modifying elements",
            "code": "Element paragraph = doc.selectFirst(\"p\");\nparagraph.text(\"Updated text!\");",
            "explanation": "Finds the first paragraph and updates its text content."
          },
          {
            "title": "Sanitizing HTML",
            "code": "String safeHtml = Jsoup.clean(unsafeHtml, Safelist.basic());",
            "explanation": "Cleans untrusted HTML to allow only safe tags and attributes, preventing XSS attacks."
          },
          {
            "title": "Form submission",
            "code": "Document loginForm = Jsoup.connect(\"https://example.com/login\")\n    .data(\"username\", \"user\")\n    .data(\"password\", \"pass\")\n    .post();",
            "explanation": "Submits a form programmatically via POST using Jsoup."
          }
        ],
        "best_practices": [
          "Always close connections when fetching data from URLs.",
          "Use CSS selectors for efficient element extraction.",
          "Sanitize any user-submitted HTML before storing or displaying it.",
          "Handle network exceptions when connecting to remote pages.",
          "Use caching or throttling to avoid overloading target websites during scraping."
        ],
        "error_handling": [
          {
            "error": "IOException",
            "solution": "Occurs when the connection fails or URL cannot be reached. Handle network failures appropriately."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Thrown when the input HTML or selector is invalid. Validate input before parsing."
          },
          {
            "error": "NullPointerException",
            "solution": "Occurs if an element is not found. Always check for null when using `selectFirst()` or similar methods."
          }
        ]
      },
      "references": {
        "official_docs": "https://jsoup.org/",
        "github": "https://github.com/jhy/jsoup"
      }
    },
    {
      "id": "quartz",
      "name": "Quartz",
      "category": "Scheduler / Job Management",
      "description": "Quartz is a powerful and widely used Java library for scheduling and executing jobs. It allows developers to define tasks, schedule them with cron-like expressions or fixed intervals, and manage job execution in enterprise applications.",
      "story": "Quartz was created to provide a robust, feature-rich scheduling library for Java applications. It supports simple schedules, cron schedules, persistent job stores, clustering, and job listeners. Quartz is used in applications ranging from batch processing to workflow automation, where timed or repeated task execution is required.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.quartz-scheduler</groupId>\n  <artifactId>quartz</artifactId>\n  <version>2.3.2</version>\n</dependency>",
        "gradle": "implementation 'org.quartz-scheduler:quartz:2.3.2'"
      },
      "usage": {
        "overview": "Quartz provides an API to define jobs by implementing the `Job` interface, schedule them using `Trigger`s, and execute them through a `Scheduler`. Jobs can be scheduled at specific times, repeated at intervals, or defined using cron expressions. Quartz also supports persistent storage and clustering for distributed applications.",
        "basic_examples": [
          {
            "title": "Defining and executing a simple job",
            "code": "import org.quartz.*;\nimport org.quartz.impl.StdSchedulerFactory;\n\npublic class HelloJob implements Job {\n    public void execute(JobExecutionContext context) {\n        System.out.println(\"Hello, Quartz!\");\n    }\n}\n\nScheduler scheduler = StdSchedulerFactory.getDefaultScheduler();\nscheduler.start();\nJobDetail job = JobBuilder.newJob(HelloJob.class)\n    .withIdentity(\"myJob\", \"group1\")\n    .build();\nTrigger trigger = TriggerBuilder.newTrigger()\n    .withIdentity(\"myTrigger\", \"group1\")\n    .startNow()\n    .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(10).repeatForever())\n    .build();\nscheduler.scheduleJob(job, trigger);",
            "explanation": "Defines a simple job that prints a message and schedules it to run every 10 seconds indefinitely."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using a CronTrigger",
            "code": "Trigger cronTrigger = TriggerBuilder.newTrigger()\n    .withIdentity(\"cronTrigger\", \"group1\")\n    .withSchedule(CronScheduleBuilder.cronSchedule(\"0 0/5 * * * ?\")) // every 5 minutes\n    .build();\nscheduler.scheduleJob(job, cronTrigger);",
            "explanation": "Schedules a job using a cron expression to execute every 5 minutes."
          },
          {
            "title": "JobDataMap for passing parameters",
            "code": "JobDetail job = JobBuilder.newJob(HelloJob.class)\n    .usingJobData(\"name\", \"Quartz User\")\n    .build();\n// In job execute method: String name = context.getJobDetail().getJobDataMap().getString(\"name\");",
            "explanation": "Passes data to a job at execution time using a JobDataMap."
          },
          {
            "title": "Persistent job store",
            "code": "// Configure quartz.properties to use JDBCJobStore for persistence\n// This ensures jobs survive application restarts",
            "explanation": "Quartz can persist jobs and triggers in a relational database for reliability in production."
          },
          {
            "title": "Listeners for monitoring jobs",
            "code": "scheduler.getListenerManager().addJobListener(new JobListener() {\n    public String getName() { return \"MyListener\"; }\n    public void jobToBeExecuted(JobExecutionContext context) {}\n    public void jobExecutionVetoed(JobExecutionContext context) {}\n    public void jobWasExecuted(JobExecutionContext context, JobExecutionException jobException) {\n        System.out.println(\"Job executed: \" + context.getJobDetail().getKey());\n    }\n});",
            "explanation": "Adds a job listener to monitor job execution events."
          }
        ],
        "best_practices": [
          "Use meaningful job and trigger names and groups for better management.",
          "Consider persistent job stores for critical tasks that must survive restarts.",
          "Handle exceptions within jobs to prevent scheduler disruption.",
          "Use cron triggers carefully to avoid overlapping executions.",
          "Monitor scheduler performance and consider clustering for high availability."
        ],
        "error_handling": [
          {
            "error": "SchedulerException",
            "solution": "Occurs if the scheduler fails to start, schedule a job, or shut down. Check configuration and job definitions."
          },
          {
            "error": "JobExecutionException",
            "solution": "Thrown within a job when execution fails. Can be used to trigger retries or rescheduling."
          },
          {
            "error": "ObjectAlreadyExistsException",
            "solution": "Thrown when trying to schedule a job or trigger with an existing identity. Use unique names or groups."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.quartz-scheduler.org/documentation/",
        "github": "https://github.com/quartz-scheduler/quartz"
      }
    },
    {
      "id": "caching-libraries",
      "name": "Ehcache / Caffeine",
      "category": "Performance / Caching",
      "description": "Ehcache and Caffeine are Java caching libraries that improve application performance by storing frequently accessed data in memory, reducing expensive database or API calls. They support in-memory and optionally persistent caching with flexible eviction and expiration policies.",
      "story": "Caching is a key technique to optimize performance and scalability. Ehcache, created in 2003, is a mature and widely-used caching library that supports in-memory, disk, and distributed caching. Caffeine, developed later, provides a high-performance, in-memory cache with efficient algorithms like W-TinyLFU for eviction. Both libraries are used in enterprise Java applications to accelerate data access, reduce latency, and manage load efficiently.",
      "installation": {
        "maven": "Ehcache:\n<dependency>\n  <groupId>org.ehcache</groupId>\n  <artifactId>ehcache</artifactId>\n  <version>3.11.9</version>\n</dependency>\n\nCaffeine:\n<dependency>\n  <groupId>com.github.ben-manes.caffeine</groupId>\n  <artifactId>caffeine</artifactId>\n  <version>3.1.8</version>\n</dependency>",
        "gradle": "implementation 'org.ehcache:ehcache:3.11.9'\nimplementation 'com.github.ben-manes.caffeine:caffeine:3.1.8'"
      },
      "usage": {
        "overview": "These libraries allow you to store key-value pairs in a cache with expiration, size limits, eviction policies, and optional persistence. Caffeine is highly optimized for low-latency, high-throughput caching, while Ehcache supports more enterprise features including clustering and JMX monitoring.",
        "basic_examples": [
          {
            "title": "Simple in-memory cache with Caffeine",
            "code": "import com.github.benmanes.caffeine.cache.Cache;\nimport com.github.benmanes.caffeine.cache.Caffeine;\n\nCache<String, String> cache = Caffeine.newBuilder()\n    .maximumSize(100)\n    .expireAfterWrite(10, java.util.concurrent.TimeUnit.MINUTES)\n    .build();\n\ncache.put(\"key1\", \"value1\");\nString value = cache.getIfPresent(\"key1\");\nSystem.out.println(value);",
            "explanation": "Creates a simple Caffeine cache with max size and expiration, then stores and retrieves a value."
          },
          {
            "title": "Basic Ehcache configuration",
            "code": "import org.ehcache.Cache;\nimport org.ehcache.CacheManager;\nimport org.ehcache.config.builders.*;\n\nCacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder().build(true);\nCache<String, String> cache = cacheManager.createCache(\"myCache\",\n    CacheConfigurationBuilder.newCacheConfigurationBuilder(String.class, String.class,\n        ResourcePoolsBuilder.heap(100)));\n\ncache.put(\"key1\", \"value1\");\nSystem.out.println(cache.get(\"key1\"));\ncacheManager.close();",
            "explanation": "Creates an Ehcache in-memory cache, adds an entry, retrieves it, and closes the cache manager."
          }
        ],
        "advanced_examples": [
          {
            "title": "Loading cache with automatic computation (Caffeine)",
            "code": "Cache<String, String> cache = Caffeine.newBuilder()\n    .maximumSize(100)\n    .build(key -> \"Value for \" + key);\n\nSystem.out.println(cache.get(\"key1\"));",
            "explanation": "Caffeine can automatically compute values if absent using a mapping function."
          },
          {
            "title": "Persistent cache with Ehcache",
            "code": "// Configure Ehcache XML for disk persistence\n// Allows cache to survive application restarts",
            "explanation": "Ehcache supports persistent caches on disk, useful for storing large datasets."
          },
          {
            "title": "Eviction policies",
            "code": "// Caffeine supports LRU, LFU, and W-TinyLFU eviction policies.\n// Ehcache supports LRU, LFU, FIFO and custom policies.",
            "explanation": "Defines how entries are evicted when cache is full or expired."
          },
          {
            "title": "Statistics and monitoring",
            "code": "System.out.println(cache.stats()); // Caffeine\n// Ehcache provides JMX beans for monitoring hits, misses, evictions",
            "explanation": "Both libraries provide APIs or JMX to monitor cache performance and statistics."
          }
        ],
        "best_practices": [
          "Use caches for frequently accessed, immutable or semi-static data.",
          "Define reasonable size limits and expiration policies to avoid memory issues.",
          "Monitor cache hit/miss ratios to tune performance.",
          "For distributed systems, consider clustered cache options (Ehcache Terracotta, Redis integration).",
          "Avoid caching sensitive data in plaintext unless encrypted."
        ],
        "error_handling": [
          {
            "error": "NullPointerException",
            "solution": "Occurs when null keys or values are inserted. Ensure keys and values are non-null."
          },
          {
            "error": "CacheMiss",
            "solution": "In Caffeine, `getIfPresent()` returns null if absent. Use `get(key, mappingFunction)` for automatic loading."
          },
          {
            "error": "OutOfMemoryError",
            "solution": "Occurs if cache grows without bounds. Define size limits and expiration policies."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.ehcache.org/\nhttps://github.com/ben-manes/caffeine",
        "github": "https://github.com/ehcache/ehcache3\nhttps://github.com/ben-manes/caffeine"
      }
    },
    {
      "id": "mapdb",
      "name": "MapDB",
      "category": "Data / Embedded Database / Caching",
      "description": "MapDB is an embedded Java database and caching library that provides fast, concurrent, and off-heap key-value storage. It supports maps, sets, queues, and other collections with optional persistence to disk or memory-mapped files.",
      "story": "MapDB was created to offer a lightweight, fast, and thread-safe Java storage solution for applications needing persistent collections or in-memory caching. It combines features of a database and a cache, allowing developers to manage large datasets efficiently without relying on external database servers.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.mapdb</groupId>\n  <artifactId>mapdb</artifactId>\n  <version>3.0.9</version>\n</dependency>",
        "gradle": "implementation 'org.mapdb:mapdb:3.0.9'"
      },
      "usage": {
        "overview": "MapDB provides concurrent collections (maps, sets, queues) with optional persistence. It supports transactions, snapshots, off-heap memory, and disk-backed storage. Developers can use it as an embedded database for small to medium-sized applications or as a high-performance cache for large datasets.",
        "basic_examples": [
          {
            "title": "Creating a persistent map",
            "code": "import org.mapdb.DB;\nimport org.mapdb.DBMaker;\nimport java.util.concurrent.ConcurrentMap;\n\nDB db = DBMaker.fileDB(\"data.db\").make();\nConcurrentMap<String, String> map = db.hashMap(\"myMap\").createOrOpen();\nmap.put(\"key1\", \"value1\");\nSystem.out.println(map.get(\"key1\"));\ndb.close();",
            "explanation": "Creates a disk-backed persistent map, adds an entry, retrieves it, and closes the database."
          },
          {
            "title": "In-memory map",
            "code": "ConcurrentMap<String, Integer> map = DBMaker.memoryDB().make().hashMap(\"numbers\").createOrOpen();\nmap.put(\"one\", 1);\nSystem.out.println(map.get(\"one\"));",
            "explanation": "Creates a fast in-memory concurrent map for temporary storage."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using transactions",
            "code": "DB db = DBMaker.fileDB(\"data.db\").transactionEnable().make();\nConcurrentMap<String, String> map = db.hashMap(\"myMap\").createOrOpen();\nmap.put(\"key2\", \"value2\");\ndb.commit(); // persist changes\ndb.close();",
            "explanation": "Enables transactional updates, allowing commit or rollback of changes."
          },
          {
            "title": "Off-heap storage",
            "code": "DB db = DBMaker.memoryDirectDB().make();\nConcurrentMap<String, String> map = db.hashMap(\"offHeapMap\").createOrOpen();",
            "explanation": "Stores data off-heap to reduce garbage collection overhead for large datasets."
          },
          {
            "title": "Queue usage",
            "code": "import org.mapdb.HTreeMap;\nHTreeMap<String, String> map = db.hashMap(\"queueMap\").createOrOpen();",
            "explanation": "MapDB also supports queues and other collection types for concurrent applications."
          }
        ],
        "best_practices": [
          "Always close the DB instance to release file handles.",
          "Use transactions for critical updates to prevent data corruption.",
          "Use off-heap memory for large in-memory datasets to reduce GC overhead.",
          "Regularly back up disk-based databases for safety.",
          "Leverage snapshots for consistent read views in concurrent environments."
        ],
        "error_handling": [
          {
            "error": "IllegalArgumentException",
            "solution": "Thrown when invalid configuration is provided, such as duplicate map names. Ensure unique names for maps and collections."
          },
          {
            "error": "DBException",
            "solution": "Occurs when disk operations fail. Check file permissions, disk space, and paths."
          },
          {
            "error": "NullPointerException",
            "solution": "Ensure keys and values are not null unless explicitly allowed by collection type."
          }
        ]
      },
      "references": {
        "official_docs": "http://www.mapdb.org/",
        "github": "https://github.com/jankotek/mapdb"
      }
    },
    {
      "id": "apache-ignite",
      "name": "Apache Ignite",
      "category": "Performance / In-Memory Data Grid",
      "description": "Apache Ignite is a distributed in-memory data grid and caching platform for Java. It provides high-performance key-value storage, SQL querying, ACID transactions, compute grid, and integration with other data sources.",
      "story": "Apache Ignite was created to enable real-time processing and high-speed access to large datasets across a cluster of machines. It combines in-memory caching, distributed databases, and compute capabilities, making it suitable for low-latency applications, microservices, and big data analytics.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.apache.ignite</groupId>\n  <artifactId>ignite-core</artifactId>\n  <version>2.15.0</version>\n</dependency>",
        "gradle": "implementation 'org.apache.ignite:ignite-core:2.15.0'"
      },
      "usage": {
        "overview": "Ignite provides APIs for creating distributed caches, performing SQL queries on in-memory data, running distributed computations, and handling transactions. It can act as a standalone cluster or integrate with existing databases, Hadoop, or Spark environments.",
        "basic_examples": [
          {
            "title": "Starting an Ignite node and creating a cache",
            "code": "import org.apache.ignite.Ignition;\nimport org.apache.ignite.configuration.CacheConfiguration;\nimport org.apache.ignite.Ignite;\nimport org.apache.ignite.IgniteCache;\n\nIgnite ignite = Ignition.start();\nCacheConfiguration<Integer, String> cfg = new CacheConfiguration<>();\ncfg.setName(\"myCache\");\nIgniteCache<Integer, String> cache = ignite.getOrCreateCache(cfg);\ncache.put(1, \"Hello Ignite\");\nSystem.out.println(cache.get(1));\nignite.close();",
            "explanation": "Starts an Ignite node, creates a named cache, stores a key-value pair, retrieves it, and shuts down the node."
          }
        ],
        "advanced_examples": [
          {
            "title": "SQL query on cache",
            "code": "cache.put(2, \"World\");\nString sql = \"SELECT _val FROM String WHERE _key = ?\";\nString val = cache.query(new SqlQuery<String, String>(String.class, sql).setArgs(2)).getAll().iterator().next().getValue();\nSystem.out.println(val);",
            "explanation": "Executes a SQL query on the Ignite cache to retrieve data."
          },
          {
            "title": "Distributed computation",
            "code": "ignite.compute().broadcast(() -> System.out.println(\"Hello from node!\"));",
            "explanation": "Broadcasts a task to all nodes in the cluster using Igniteâ€™s compute grid."
          },
          {
            "title": "Transactions",
            "code": "try (Transaction tx = ignite.transactions().txStart()) {\n    cache.put(3, \"Transactional Value\");\n    tx.commit();\n}",
            "explanation": "Performs a transactional update on the cache."
          },
          {
            "title": "Integration with persistent store",
            "code": "// Configure CacheConfiguration with CacheStoreFactory to integrate with RDBMS for read-through/write-through",
            "explanation": "Allows Ignite caches to persist data to a database or external storage for durability."
          }
        ],
        "best_practices": [
          "Use partitioned or replicated caches based on access patterns.",
          "Enable persistence for critical datasets to survive node restarts.",
          "Leverage SQL indexing for fast queries on cache data.",
          "Use transactions for atomic updates in multi-node environments.",
          "Monitor cluster performance and rebalance partitions if needed."
        ],
        "error_handling": [
          {
            "error": "IgniteException",
            "solution": "Occurs if Ignite fails to start or execute operations. Check configuration, cluster connectivity, and logs."
          },
          {
            "error": "CacheException",
            "solution": "Thrown when cache operations fail. Ensure cache exists and keys/values are valid."
          },
          {
            "error": "ClusterTopologyException",
            "solution": "Occurs if the cluster topology changes during a distributed operation. Retry or handle failover logic."
          }
        ]
      },
      "references": {
        "official_docs": "https://ignite.apache.org/docs/latest/",
        "github": "https://github.com/apache/ignite"
      }
    },
    {
      "id": "hazelcast",
      "name": "Hazelcast",
      "category": "Performance / In-Memory Data Grid",
      "description": "Hazelcast is a distributed in-memory data grid and caching platform for Java. It provides high-performance storage for key-value data, distributed maps, queues, topics, and support for distributed computing, clustering, and transactions.",
      "story": "Hazelcast was developed to enable real-time, scalable, and fault-tolerant data processing across clusters. It supports in-memory computing, distributed caching, and event-driven architectures, making it ideal for microservices, high-throughput applications, and low-latency systems.",
      "installation": {
        "maven": "<dependency>\n  <groupId>com.hazelcast</groupId>\n  <artifactId>hazelcast</artifactId>\n  <version>5.3.2</version>\n</dependency>",
        "gradle": "implementation 'com.hazelcast:hazelcast:5.3.2'"
      },
      "usage": {
        "overview": "Hazelcast provides distributed collections such as maps, sets, queues, lists, and topics. It supports automatic clustering, distributed computation, transactions, and persistence to ensure data reliability. Developers can integrate Hazelcast as a cache, compute grid, or in-memory database.",
        "basic_examples": [
          {
            "title": "Starting a Hazelcast instance and using a map",
            "code": "import com.hazelcast.core.Hazelcast;\nimport com.hazelcast.core.HazelcastInstance;\nimport com.hazelcast.map.IMap;\n\nHazelcastInstance hz = Hazelcast.newHazelcastInstance();\nIMap<Integer, String> map = hz.getMap(\"myMap\");\nmap.put(1, \"Hello Hazelcast\");\nSystem.out.println(map.get(1));\nhz.shutdown();",
            "explanation": "Starts a Hazelcast node, creates a distributed map, stores and retrieves a value, and shuts down the instance."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using distributed queue",
            "code": "import com.hazelcast.collection.IQueue;\nIQueue<String> queue = hz.getQueue(\"myQueue\");\nqueue.add(\"Task1\");\nSystem.out.println(queue.poll());",
            "explanation": "Demonstrates using a distributed queue for inter-node task processing."
          },
          {
            "title": "Executing distributed computation",
            "code": "hz.getExecutorService(\"exec\").submit(() -> System.out.println(\"Running task across cluster\"));",
            "explanation": "Executes a task across cluster nodes using Hazelcast's distributed executor service."
          },
          {
            "title": "Transactions",
            "code": "import com.hazelcast.transaction.TransactionContext;\nTransactionContext context = hz.newTransactionContext();\ncontext.beginTransaction();\ntry {\n    IMap<Integer, String> mapTx = context.getMap(\"myMap\");\n    mapTx.put(2, \"Transactional Value\");\n    context.commitTransaction();\n} catch(Exception e) {\n    context.rollbackTransaction();\n}",
            "explanation": "Performs atomic operations on distributed data using transactions."
          },
          {
            "title": "Event listeners",
            "code": "map.addEntryListener(entryEvent -> System.out.println(\"Entry updated: \" + entryEvent), true);",
            "explanation": "Adds a listener to monitor map entry events across the cluster."
          }
        ],
        "best_practices": [
          "Use appropriate collection types (map, queue, set) based on use case.",
          "Enable backups for high availability and fault tolerance.",
          "Use transactions for critical operations to ensure consistency.",
          "Monitor cluster performance and adjust partitions and backups accordingly.",
          "Leverage Hazelcast management center for monitoring and tuning cluster."
        ],
        "error_handling": [
          {
            "error": "HazelcastInstanceNotActiveException",
            "solution": "Occurs if instance is shut down or not active. Ensure the Hazelcast instance is running."
          },
          {
            "error": "TransactionException",
            "solution": "Thrown if transaction fails. Handle commit/rollback appropriately."
          },
          {
            "error": "IllegalStateException",
            "solution": "Occurs if configuration is invalid or cluster is unstable. Validate cluster setup and configuration."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.hazelcast.com/",
        "github": "https://github.com/hazelcast/hazelcast"
      }
    },
    {
      "id": "javacv-opencv",
      "name": "JavaCV / OpenCV Java",
      "category": "Computer Vision / ML",
      "description": "JavaCV provides Java bindings for OpenCV and other computer vision libraries, allowing developers to process images and videos, detect objects, and apply advanced computer vision algorithms in Java applications.",
      "story": "OpenCV is a widely used open-source computer vision library originally written in C/C++. JavaCV provides wrappers to use OpenCV functionality from Java. It allows real-time image processing, video capture, object detection, and integration with deep learning frameworks. JavaCV is used in robotics, surveillance, augmented reality, and multimedia applications.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.bytedeco</groupId>\n  <artifactId>javacv-platform</artifactId>\n  <version>1.5.8</version>\n</dependency>",
        "gradle": "implementation 'org.bytedeco:javacv-platform:1.5.8'"
      },
      "usage": {
        "overview": "JavaCV allows capturing video from cameras, reading/writing image files, performing image transformations, object detection using Haar cascades, and interfacing with machine learning models. It leverages OpenCV's high-performance image processing capabilities from Java.",
        "basic_examples": [
          {
            "title": "Reading and displaying an image",
            "code": "import org.bytedeco.opencv.opencv_core.Mat;\nimport org.bytedeco.opencv.global.opencv_imgcodecs;\nimport org.bytedeco.opencv.global.opencv_highgui;\n\nMat image = opencv_imgcodecs.imread(\"image.jpg\");\nopencv_highgui.imshow(\"Display\", image);\nopencv_highgui.waitKey(0);",
            "explanation": "Reads an image file into a Mat object and displays it in a window."
          },
          {
            "title": "Capturing video from webcam",
            "code": "import org.bytedeco.opencv.opencv_videoio.VideoCapture;\nimport org.bytedeco.opencv.opencv_core.Mat;\n\nVideoCapture cap = new VideoCapture(0);\nMat frame = new Mat();\nwhile(cap.read(frame)) {\n    // Process frame\n}\ncap.release();",
            "explanation": "Captures live video from the default webcam and allows processing of each frame."
          }
        ],
        "advanced_examples": [
          {
            "title": "Grayscale conversion and edge detection",
            "code": "import static org.bytedeco.opencv.global.opencv_imgproc.*;\nMat gray = new Mat();\ncvtColor(image, gray, COLOR_BGR2GRAY);\nMat edges = new Mat();\nCanny(gray, edges, 100, 200);",
            "explanation": "Converts an image to grayscale and applies the Canny edge detection algorithm."
          },
          {
            "title": "Face detection with Haar cascades",
            "code": "import org.bytedeco.opencv.opencv_objdetect.CascadeClassifier;\nCascadeClassifier faceDetector = new CascadeClassifier(\"haarcascade_frontalface_default.xml\");\nRectVector faces = new RectVector();\nfaceDetector.detectMultiScale(gray, faces);",
            "explanation": "Detects faces in an image using a pre-trained Haar cascade classifier."
          },
          {
            "title": "Video recording",
            "code": "import org.bytedeco.opencv.opencv_videoio.VideoWriter;\nVideoWriter writer = new VideoWriter(\"output.avi\", VideoWriter.fourcc('M','J','P','G'), 30, new Size(640,480));\nwriter.write(frame);",
            "explanation": "Writes frames to a video file in real-time."
          },
          {
            "title": "Integration with deep learning models",
            "code": "// Load DNN model using OpenCV DNN module for object detection or classification",
            "explanation": "JavaCV can interface with OpenCVâ€™s DNN module to run pre-trained neural networks for computer vision tasks."
          }
        ],
        "best_practices": [
          "Release Mat objects and video capture resources to avoid memory leaks.",
          "Use smaller image resolutions for real-time processing to maintain performance.",
          "Leverage native OpenCV methods for heavy image processing tasks.",
          "Combine with JavaFX or Swing for GUI integration.",
          "Keep pre-trained classifiers and models organized for reusability."
        ],
        "error_handling": [
          {
            "error": "org.bytedeco.javacv.FrameGrabber.Exception",
            "solution": "Occurs if camera or video input cannot be accessed. Check device availability."
          },
          {
            "error": "NullPointerException",
            "solution": "Occurs if image or frame is empty. Ensure file paths are correct and capture works."
          },
          {
            "error": "opencv_core.CvException",
            "solution": "Thrown by OpenCV native methods. Check input Mat types, sizes, and parameters."
          }
        ]
      },
      "references": {
        "official_docs": "https://bytedeco.org/javacv/",
        "github": "https://github.com/bytedeco/javacv"
      }
    },
    {
      "id": "deeplearning4j",
      "name": "Deeplearning4j (DL4J)",
      "category": "ML/AI / Deep Learning",
      "description": "Deeplearning4j (DL4J) is an open-source, distributed deep learning library for Java and JVM-based languages. It allows building, training, and deploying neural networks for tasks like image recognition, NLP, time series analysis, and more.",
      "story": "DL4J was developed to bring deep learning capabilities to Java developers, integrating seamlessly with the Java ecosystem and big data tools like Hadoop and Spark. It supports GPU acceleration via CUDA, distributed training, and provides tools for preprocessing, model evaluation, and deployment.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.deeplearning4j</groupId>\n  <artifactId>deeplearning4j-core</artifactId>\n  <version>1.0.0-M2.1</version>\n</dependency>\n<dependency>\n  <groupId>org.nd4j</groupId>\n  <artifactId>nd4j-native-platform</artifactId>\n  <version>1.0.0-M2.1</version>\n</dependency>",
        "gradle": "implementation 'org.deeplearning4j:deeplearning4j-core:1.0.0-M2.1'\nimplementation 'org.nd4j:nd4j-native-platform:1.0.0-M2.1'"
      },
      "usage": {
        "overview": "DL4J provides APIs for building feedforward, convolutional, recurrent, and custom neural networks. It integrates with ND4J (n-dimensional arrays) for numerical computing and supports model serialization, evaluation, and visualization.",
        "basic_examples": [
          {
            "title": "Simple feedforward network",
            "code": "import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\nimport org.deeplearning4j.nn.conf.NeuralNetConfiguration;\nimport org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\nimport org.nd4j.linalg.activations.Activation;\nimport org.nd4j.linalg.lossfunctions.LossFunctions;\n\nMultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n    .list()\n    .layer(0, new org.deeplearning4j.nn.conf.layers.DenseLayer.Builder()\n        .nIn(4).nOut(3)\n        .activation(Activation.RELU)\n        .build())\n    .layer(1, new org.deeplearning4j.nn.conf.layers.OutputLayer.Builder(LossFunctions.LossFunction.MSE)\n        .activation(Activation.IDENTITY).nIn(3).nOut(1).build())\n    .build();\n\nMultiLayerNetwork model = new MultiLayerNetwork(conf);\nmodel.init();",
            "explanation": "Defines and initializes a simple feedforward neural network with one hidden layer."
          }
        ],
        "advanced_examples": [
          {
            "title": "Training with data",
            "code": "// Use DataSetIterator for batching\n// model.fit(dataIterator);",
            "explanation": "Trains the model on batched datasets using DL4Jâ€™s DataSetIterator."
          },
          {
            "title": "Convolutional Neural Network (CNN)",
            "code": "// Build CNN for image recognition using ConvolutionLayer and SubsamplingLayer",
            "explanation": "DL4J supports convolutional layers for processing images and extracting spatial features."
          },
          {
            "title": "Recurrent Neural Network (RNN)",
            "code": "// Build LSTM/GRU layers for sequence data and time series",
            "explanation": "DL4J can model sequences and time series using recurrent layers."
          },
          {
            "title": "GPU acceleration",
            "code": "// Use ND4J backend with CUDA to speed up training on GPUs",
            "explanation": "DL4J can leverage GPUs via ND4J for faster computations and large models."
          }
        ],
        "best_practices": [
          "Normalize input data for faster convergence.",
          "Use early stopping or model checkpoints to prevent overfitting.",
          "Batch data appropriately for efficient training.",
          "Monitor training metrics and adjust learning rates accordingly.",
          "Leverage GPU acceleration for deep or large models."
        ],
        "error_handling": [
          {
            "error": "ND4JIllegalStateException",
            "solution": "Occurs if ND4J backend is not properly configured. Ensure the correct native platform dependency is included."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Thrown if layer sizes, input shapes, or activation functions are incompatible. Verify network configuration."
          },
          {
            "error": "OutOfMemoryError",
            "solution": "Reduce batch size or use GPU memory efficiently. Consider memory-mapped datasets for large data."
          }
        ]
      },
      "references": {
        "official_docs": "https://deeplearning4j.org/docs/latest/",
        "github": "https://github.com/deeplearning4j/deeplearning4j"
      }
    },
    {
      "id": "nd4j",
      "name": "ND4J",
      "category": "ML/AI / Numerical Computing",
      "description": "ND4J (N-Dimensional Arrays for Java) is a scientific computing library for the JVM, providing high-performance n-dimensional arrays, linear algebra operations, and GPU acceleration. It serves as the foundation for Deeplearning4j and other Java-based ML frameworks.",
      "story": "ND4J was created to bring NumPy-like capabilities to Java. It allows Java developers to perform vectorized operations, matrix computations, and linear algebra efficiently, both on CPU and GPU. ND4J is commonly used for deep learning, data analysis, and scientific computing within the Java ecosystem.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.nd4j</groupId>\n  <artifactId>nd4j-native-platform</artifactId>\n  <version>1.0.0-M2.1</version>\n</dependency>",
        "gradle": "implementation 'org.nd4j:nd4j-native-platform:1.0.0-M2.1'"
      },
      "usage": {
        "overview": "ND4J provides Nd4j class for creating and manipulating n-dimensional arrays (INDArray), supports element-wise operations, linear algebra, broadcasting, reductions, and integration with deep learning frameworks like Deeplearning4j.",
        "basic_examples": [
          {
            "title": "Creating an array",
            "code": "import org.nd4j.linalg.factory.Nd4j;\nimport org.nd4j.linalg.api.ndarray.INDArray;\n\nINDArray array = Nd4j.create(new double[]{1, 2, 3, 4});\nSystem.out.println(array);",
            "explanation": "Creates a 1D n-dimensional array and prints its contents."
          },
          {
            "title": "Basic arithmetic",
            "code": "INDArray a = Nd4j.create(new double[]{1,2,3});\nINDArray b = Nd4j.create(new double[]{4,5,6});\nINDArray c = a.add(b);\nSystem.out.println(c);",
            "explanation": "Performs element-wise addition of two NDArrays."
          }
        ],
        "advanced_examples": [
          {
            "title": "Matrix multiplication",
            "code": "INDArray mat1 = Nd4j.create(new double[][]{{1,2},{3,4}});\nINDArray mat2 = Nd4j.create(new double[][]{{5,6},{7,8}});\nINDArray result = mat1.mmul(mat2);\nSystem.out.println(result);",
            "explanation": "Performs matrix multiplication using ND4J's `mmul` function."
          },
          {
            "title": "Broadcasting operations",
            "code": "INDArray mat = Nd4j.create(new double[][]{{1,2,3},{4,5,6}});\nINDArray addVec = Nd4j.create(new double[]{10,20,30});\nINDArray result = mat.addRowVector(addVec);\nSystem.out.println(result);",
            "explanation": "Demonstrates broadcasting a 1D vector across rows of a 2D matrix."
          },
          {
            "title": "Statistical operations",
            "code": "INDArray arr = Nd4j.create(new double[]{1,2,3,4,5});\nSystem.out.println(arr.meanNumber());\nSystem.out.println(arr.stdNumber());",
            "explanation": "Computes mean and standard deviation of an array."
          },
          {
            "title": "GPU acceleration",
            "code": "// Use ND4J with CUDA backend for GPU computations\n// Ensure nd4j-cuda-platform dependency is included",
            "explanation": "ND4J can leverage GPU for faster computations on large matrices or deep learning tasks."
          }
        ],
        "best_practices": [
          "Use vectorized operations instead of loops for performance.",
          "Leverage broadcasting for operations on arrays of different shapes.",
          "Prefer Nd4j native platform or CUDA backend for large datasets or GPU acceleration.",
          "Release unused NDArrays if memory usage is high.",
          "Combine ND4J with Deeplearning4j for deep learning workflows."
        ],
        "error_handling": [
          {
            "error": "IllegalStateException",
            "solution": "Occurs if ND4J backend is not properly initialized. Check native library dependencies."
          },
          {
            "error": "DimensionMismatchException",
            "solution": "Thrown when shapes of arrays do not match for operations. Verify array dimensions."
          },
          {
            "error": "OutOfMemoryError",
            "solution": "Reduce array sizes or enable off-heap memory for large datasets."
          }
        ]
      },
      "references": {
        "official_docs": "https://deeplearning4j.konduit.ai/nd4j",
        "github": "https://github.com/eclipse/deeplearning4j/tree/master/nd4j"
      }
    },
    {
      "id": "weka",
      "name": "Weka",
      "category": "ML/AI / Machine Learning",
      "description": "Weka is a collection of machine learning algorithms for data mining tasks in Java. It provides tools for classification, regression, clustering, association rule mining, and data preprocessing, with both a GUI and programmatic API.",
      "story": "Weka was developed at the University of Waikato to provide an accessible platform for teaching, research, and experimentation in machine learning. It offers a wide range of algorithms and evaluation methods, making it popular in academia and for rapid prototyping of ML models in Java.",
      "installation": {
        "maven": "<dependency>\n  <groupId>nz.ac.waikato.cms.weka</groupId>\n  <artifactId>weka-stable</artifactId>\n  <version>3.8.6</version>\n</dependency>",
        "gradle": "implementation 'nz.ac.waikato.cms.weka:weka-stable:3.8.6'"
      },
      "usage": {
        "overview": "Weka provides an API for loading datasets, applying machine learning algorithms, evaluating models, and exporting results. It supports ARFF, CSV, and database inputs, and integrates preprocessing filters, feature selection, and model evaluation methods.",
        "basic_examples": [
          {
            "title": "Loading a dataset and printing summary",
            "code": "import weka.core.Instances;\nimport weka.core.converters.ConverterUtils.DataSource;\n\nDataSource source = new DataSource(\"data/iris.arff\");\nInstances data = source.getDataSet();\nif(data.classIndex() == -1) data.setClassIndex(data.numAttributes() - 1);\nSystem.out.println(data);",
            "explanation": "Loads an ARFF dataset and prints a summary of instances and attributes."
          },
          {
            "title": "Training a simple classifier",
            "code": "import weka.classifiers.trees.J48;\nimport weka.classifiers.Evaluation;\n\nJ48 tree = new J48();\ntree.buildClassifier(data);\nEvaluation eval = new Evaluation(data);\neval.crossValidateModel(tree, data, 10, new java.util.Random(1));\nSystem.out.println(eval.toSummaryString());",
            "explanation": "Trains a J48 decision tree on the dataset and evaluates it using 10-fold cross-validation."
          }
        ],
        "advanced_examples": [
          {
            "title": "Data preprocessing with filters",
            "code": "import weka.filters.Filter;\nimport weka.filters.unsupervised.attribute.Normalize;\n\nNormalize normalize = new Normalize();\nnormalize.setInputFormat(data);\nInstances normalizedData = Filter.useFilter(data, normalize);",
            "explanation": "Applies normalization preprocessing to the dataset before training."
          },
          {
            "title": "Clustering",
            "code": "import weka.clusterers.SimpleKMeans;\nSimpleKMeans kMeans = new SimpleKMeans();\nkMeans.setNumClusters(3);\nkMeans.buildClusterer(data);",
            "explanation": "Performs k-means clustering on the dataset."
          },
          {
            "title": "Evaluating classifiers with ROC",
            "code": "eval.evaluateModel(tree, data);\nSystem.out.println(eval.areaUnderROC(1));",
            "explanation": "Evaluates classifier performance and prints ROC area for the positive class."
          },
          {
            "title": "Feature selection",
            "code": "import weka.attributeSelection.InfoGainAttributeEval;\nimport weka.attributeSelection.Ranker;\nweka.attributeSelection.AttributeSelection selector = new weka.attributeSelection.AttributeSelection();\nselector.setEvaluator(new InfoGainAttributeEval());\nselector.setSearch(new Ranker());\nselector.SelectAttributes(data);",
            "explanation": "Performs feature selection using information gain and ranks attributes."
          }
        ],
        "best_practices": [
          "Normalize or standardize data when needed.",
          "Use cross-validation to assess model performance reliably.",
          "Filter irrelevant or redundant features to improve accuracy.",
          "Try multiple algorithms and compare results.",
          "Leverage Wekaâ€™s evaluation metrics to understand classifier performance."
        ],
        "error_handling": [
          {
            "error": "Exception: No class attribute assigned",
            "solution": "Ensure the dataset has the class attribute set before training classifiers."
          },
          {
            "error": "ArrayIndexOutOfBoundsException",
            "solution": "Check dataset formatting and ensure ARFF/CSV files are correctly structured."
          },
          {
            "error": "Exception: Cannot handle string attributes",
            "solution": "Convert string attributes to nominal or numeric using preprocessing filters."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.cs.waikato.ac.nz/ml/weka/",
        "github": "https://github.com/Waikato/weka-3.8"
      }
    },
    {
      "id": "moa",
      "name": "MOA (Massive Online Analysis)",
      "category": "ML/AI / Streaming Machine Learning",
      "description": "MOA is an open-source Java framework for data stream mining. It provides tools for classification, regression, clustering, and concept drift detection on high-speed streaming data.",
      "story": "MOA was developed to support research and development in online learning and streaming analytics. It is widely used in academic research and industry to handle real-time data streams where models must be updated incrementally, unlike traditional batch learning.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.github.moa-dev</groupId>\n  <artifactId>moa</artifactId>\n  <version>2018.05</version>\n</dependency>",
        "gradle": "implementation 'org.github.moa-dev:moa:2018.05'"
      },
      "usage": {
        "overview": "MOA allows processing continuous data streams using incremental learning algorithms. It supports various stream generators, classifiers, ensemble methods, and evaluation metrics. MOA can be integrated with Weka and other Java ML libraries.",
        "basic_examples": [
          {
            "title": "Creating a stream and reading instances",
            "code": "import moa.streams.generators.RandomTreeGenerator;\nimport com.yahoo.labs.samoa.instances.Instance;\n\nRandomTreeGenerator stream = new RandomTreeGenerator();\nstream.prepareForUse();\nInstance instance = stream.nextInstance().getData();",
            "explanation": "Generates a random data stream and retrieves the next instance for processing."
          },
          {
            "title": "Training an incremental classifier",
            "code": "import moa.classifiers.trees.HoeffdingTree;\nHoeffdingTree learner = new HoeffdingTree();\nlearner.setModelContext(stream.getHeader());\nlearner.prepareForUse();\nlearner.trainOnInstance(instance);",
            "explanation": "Creates a Hoeffding Tree classifier and trains it incrementally on each instance from the stream."
          }
        ],
        "advanced_examples": [
          {
            "title": "Evaluating a stream classifier",
            "code": "import moa.evaluation.WindowClassificationPerformanceEvaluator;\nWindowClassificationPerformanceEvaluator evaluator = new WindowClassificationPerformanceEvaluator();\nevaluator.setWindowSize(1000);\nevaluator.addResult(learner, instance);",
            "explanation": "Evaluates classifier performance using a sliding window over the stream."
          },
          {
            "title": "Using ensemble methods",
            "code": "import moa.classifiers.meta.OzaBag;\nOzaBag ensemble = new OzaBag();\nensemble.setBaseLearner(new HoeffdingTree());",
            "explanation": "Creates an online bagging ensemble for better accuracy on streaming data."
          },
          {
            "title": "Concept drift detection",
            "code": "import moa.classifiers.core.driftdetection.DDM;\nDDM driftDetector = new DDM();",
            "explanation": "Detects concept drift in streaming data using Drift Detection Method (DDM)."
          },
          {
            "title": "Integrating with Weka",
            "code": "// MOA streams and classifiers can be converted to Weka instances for batch processing or evaluation",
            "explanation": "Facilitates hybrid workflows combining streaming and batch machine learning."
          }
        ],
        "best_practices": [
          "Use incremental learning algorithms designed for streaming data.",
          "Monitor concept drift to adapt models to changing distributions.",
          "Use ensemble methods for more robust predictions on streams.",
          "Evaluate models with prequential or sliding window evaluation.",
          "Keep memory usage low to handle high-speed data streams efficiently."
        ],
        "error_handling": [
          {
            "error": "NullPointerException",
            "solution": "Ensure the stream and model context are properly initialized before training."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Thrown if instance attributes or types do not match classifier expectations."
          },
          {
            "error": "OutOfMemoryError",
            "solution": "Use windowed evaluation or limit ensemble sizes to reduce memory footprint."
          }
        ]
      },
      "references": {
        "official_docs": "https://moa.cms.waikato.ac.nz/",
        "github": "https://github.com/Waikato/moa"
      }
    },
    {
      "id": "apache-flink",
      "name": "Apache Flink",
      "category": "Big Data / Streaming / ML",
      "description": "Apache Flink is a powerful open-source framework for distributed stream and batch data processing. Flink ML provides machine learning libraries for building scalable models on streaming and batch data.",
      "story": "Apache Flink was developed to handle large-scale data processing in real-time. It supports event-time processing, stateful computations, and exactly-once semantics. Flink ML extends Flink with scalable machine learning algorithms that can process both batch and streaming data efficiently.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.apache.flink</groupId>\n  <artifactId>flink-streaming-java_2.12</artifactId>\n  <version>1.17.2</version>\n</dependency>\n<dependency>\n  <groupId>org.apache.flink</groupId>\n  <artifactId>flink-ml-lib_2.12</artifactId>\n  <version>2.2.0</version>\n</dependency>",
        "gradle": "implementation 'org.apache.flink:flink-streaming-java_2.12:1.17.2'\nimplementation 'org.apache.flink:flink-ml-lib_2.12:2.2.0'"
      },
      "usage": {
        "overview": "Flink allows processing high-throughput, low-latency data streams and performing batch analytics. Flink ML provides scalable implementations of algorithms like linear regression, k-means, logistic regression, and clustering on streaming or batch datasets.",
        "basic_examples": [
          {
            "title": "Streaming word count",
            "code": "import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\nimport org.apache.flink.streaming.api.datastream.DataStream;\n\nStreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\nDataStream<String> text = env.socketTextStream(\"localhost\", 9999);\ntext.flatMap(new Tokenizer())\n    .keyBy(value -> value.f0)\n    .sum(1)\n    .print();\nenv.execute(\"Streaming WordCount\");",
            "explanation": "Processes text data from a socket stream and counts the occurrences of each word in real-time."
          },
          {
            "title": "Batch dataset processing",
            "code": "import org.apache.flink.api.java.ExecutionEnvironment;\nExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\nDataSet<String> data = env.readTextFile(\"data.csv\");\ndata.print();",
            "explanation": "Reads and prints a batch dataset from a CSV file."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Flink ML for linear regression",
            "code": "import org.apache.flink.ml.regression.LinearRegression;\nLinearRegression lr = new LinearRegression().setStepsize(0.01).setIterations(100);\nlr.fit(trainingData);\nINDArray predictions = lr.predict(testData);",
            "explanation": "Trains a linear regression model using Flink ML and generates predictions on test data."
          },
          {
            "title": "Windowed stream processing",
            "code": "text.flatMap(new Tokenizer())\n    .keyBy(value -> value.f0)\n    .timeWindow(Time.seconds(5))\n    .sum(1)\n    .print();",
            "explanation": "Counts words in a sliding time window of 5 seconds on a data stream."
          },
          {
            "title": "Stateful stream processing",
            "code": "// Maintain running totals and custom state for complex streaming analytics",
            "explanation": "Flink allows storing and updating state for each key in the stream, enabling advanced real-time computations."
          },
          {
            "title": "Integration with Kafka",
            "code": "import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;\n// Use Kafka consumer to read data streams into Flink",
            "explanation": "Flink can ingest streams from Kafka, RabbitMQ, or other messaging systems for large-scale processing."
          }
        ],
        "best_practices": [
          "Use event-time processing when timestamps matter for streaming analytics.",
          "Leverage checkpointing and state backends for fault-tolerant streaming.",
          "Keep state size manageable for high-throughput streaming pipelines.",
          "Combine Flink ML with Flink streaming for real-time model predictions.",
          "Monitor throughput, latency, and backpressure for optimal performance."
        ],
        "error_handling": [
          {
            "error": "JobExecutionException",
            "solution": "Occurs if Flink job fails during execution. Check logs and configuration settings."
          },
          {
            "error": "CheckpointException",
            "solution": "Thrown if Flink cannot write state checkpoints. Verify state backend and storage configuration."
          },
          {
            "error": "OutOfMemoryError",
            "solution": "Reduce parallelism, optimize state size, or increase JVM heap for large streaming jobs."
          }
        ]
      },
      "references": {
        "official_docs": "https://nightlies.apache.org/flink/flink-docs-stable/",
        "github": "https://github.com/apache/flink"
      }
    },
    {
      "id": "apache-spark",
      "name": "Apache Spark",
      "category": "Big Data / Distributed Computing / ML",
      "description": "Apache Spark is an open-source distributed computing system for big data processing. Spark MLlib provides scalable machine learning algorithms for classification, regression, clustering, and collaborative filtering, usable in Java, Scala, and Python.",
      "story": "Spark was originally developed at UC Berkeleyâ€™s AMPLab to simplify large-scale data processing. Spark MLlib extends Spark for machine learning tasks, enabling high-performance distributed computations on massive datasets. It is widely used in data engineering, analytics, and AI pipelines.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.apache.spark</groupId>\n  <artifactId>spark-core_2.12</artifactId>\n  <version>3.5.1</version>\n</dependency>\n<dependency>\n  <groupId>org.apache.spark</groupId>\n  <artifactId>spark-mllib_2.12</artifactId>\n  <version>3.5.1</version>\n</dependency>",
        "gradle": "implementation 'org.apache.spark:spark-core_2.12:3.5.1'\nimplementation 'org.apache.spark:spark-mllib_2.12:3.5.1'"
      },
      "usage": {
        "overview": "Spark provides RDDs, DataFrames, and Datasets for distributed data processing. MLlib includes scalable implementations of machine learning algorithms, pipelines, feature transformers, and model evaluation methods.",
        "basic_examples": [
          {
            "title": "Creating a Spark session",
            "code": "import org.apache.spark.sql.SparkSession;\n\nSparkSession spark = SparkSession.builder()\n    .appName(\"Spark Example\")\n    .master(\"local[*]\")\n    .getOrCreate();",
            "explanation": "Initializes a Spark session for distributed computing tasks."
          },
          {
            "title": "Loading a dataset",
            "code": "import org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Row;\n\nDataset<Row> df = spark.read().format(\"csv\").option(\"header\", true).load(\"data.csv\");\ndf.show();",
            "explanation": "Loads a CSV dataset into a Spark DataFrame and prints the first few rows."
          }
        ],
        "advanced_examples": [
          {
            "title": "Linear regression with MLlib",
            "code": "import org.apache.spark.ml.regression.LinearRegression;\nLinearRegression lr = new LinearRegression()\n    .setLabelCol(\"label\")\n    .setFeaturesCol(\"features\");\nLinearRegressionModel model = lr.fit(trainingData);\nDataset<Row> predictions = model.transform(testData);",
            "explanation": "Trains a linear regression model and makes predictions on test data using Spark MLlib."
          },
          {
            "title": "K-Means clustering",
            "code": "import org.apache.spark.ml.clustering.KMeans;\nKMeans kmeans = new KMeans().setK(3).setSeed(1L);\nKMeansModel kmModel = kmeans.fit(dataset);\nDataset<Row> predictions = kmModel.transform(dataset);",
            "explanation": "Performs k-means clustering on a dataset with Spark MLlib."
          },
          {
            "title": "Pipeline with transformers and estimators",
            "code": "import org.apache.spark.ml.Pipeline;\nPipeline pipeline = new Pipeline().setStages(new PipelineStage[]{tokenizer, hashingTF, lr});\nPipelineModel model = pipeline.fit(trainingData);",
            "explanation": "Builds an ML pipeline combining preprocessing steps and a learning algorithm for streamlined training and evaluation."
          },
          {
            "title": "Streaming data processing",
            "code": "import org.apache.spark.sql.streaming.StreamingQuery;\nDataset<Row> streamingDF = spark.readStream().format(\"socket\").option(\"host\", \"localhost\").option(\"port\", 9999).load();\nStreamingQuery query = streamingDF.writeStream().format(\"console\").start();",
            "explanation": "Processes real-time streaming data using Spark Structured Streaming."
          }
        ],
        "best_practices": [
          "Cache frequently used RDDs/DataFrames to improve performance.",
          "Use pipelines for repeatable preprocessing and model training.",
          "Partition large datasets for distributed computation.",
          "Monitor job execution using the Spark UI.",
          "Combine batch and streaming workflows as needed for real-time analytics."
        ],
        "error_handling": [
          {
            "error": "org.apache.spark.SparkException",
            "solution": "Check Spark configurations, cluster setup, and data sources for errors."
          },
          {
            "error": "OutOfMemoryError",
            "solution": "Increase executor memory, reduce partitions, or optimize transformations."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Verify schema, feature column types, and algorithm requirements for Spark MLlib."
          }
        ]
      },
      "references": {
        "official_docs": "https://spark.apache.org/docs/latest/",
        "github": "https://github.com/apache/spark"
      }
    },
    {
      "id": "apache-beam",
      "name": "Apache Beam",
      "category": "Big Data / Streaming / Batch Processing",
      "description": "Apache Beam is an open-source unified programming model for defining and executing data processing pipelines, both batch and streaming. It provides Java, Python, and Go SDKs and can run on multiple runners like Flink, Spark, and Dataflow.",
      "story": "Apache Beam was created to provide a consistent model for building portable data processing pipelines. It decouples the pipeline logic from the execution engine, allowing developers to write code once and run it on various runners, making it ideal for hybrid cloud and on-premise processing.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.apache.beam</groupId>\n  <artifactId>beam-sdks-java-core</artifactId>\n  <version>2.49.0</version>\n</dependency>",
        "gradle": "implementation 'org.apache.beam:beam-sdks-java-core:2.49.0'"
      },
      "usage": {
        "overview": "Beam allows defining pipelines using PCollections, transforms, and sinks. It supports windowing, triggers, aggregations, and joins for streaming data, as well as standard batch transformations.",
        "basic_examples": [
          {
            "title": "Simple word count",
            "code": "import org.apache.beam.sdk.Pipeline;\nimport org.apache.beam.sdk.io.TextIO;\nimport org.apache.beam.sdk.transforms.*;\nimport org.apache.beam.sdk.values.*;\n\nPipeline pipeline = Pipeline.create();\npipeline.apply(TextIO.read().from(\"input.txt\"))\n        .apply(FlatMapElements.into(TypeDescriptors.strings()).via((String line) -> Arrays.asList(line.split(\" \"))))\n        .apply(Count.perElement())\n        .apply(MapElements.into(TypeDescriptors.strings()).via(kv -> kv.getKey() + \":\" + kv.getValue()))\n        .apply(TextIO.write().to(\"output.txt\"));\npipeline.run().waitUntilFinish();",
            "explanation": "Builds a simple batch pipeline that reads text, splits words, counts occurrences, and writes results."
          }
        ],
        "advanced_examples": [
          {
            "title": "Windowed stream processing",
            "code": "PCollection<String> stream = pipeline.apply( ... );\nstream.apply(Window.<String>into(FixedWindows.of(Duration.standardMinutes(1))))\n      .apply(Count.perElement());",
            "explanation": "Counts elements in fixed one-minute windows for streaming data."
          },
          {
            "title": "Using ParDo for custom transformations",
            "code": "stream.apply(ParDo.of(new DoFn<String, String>() {\n  @ProcessElement\n  public void processElement(ProcessContext c) {\n    c.output(c.element().toUpperCase());\n  }\n}));",
            "explanation": "Applies a custom transformation to convert each element to uppercase."
          },
          {
            "title": "Connecting to external sources",
            "code": "pipeline.apply(PubsubIO.readStrings().fromTopic(\"projects/my-project/topics/my-topic\"));",
            "explanation": "Reads messages from a Google Cloud Pub/Sub topic for streaming processing."
          },
          {
            "title": "Combining multiple PCollections",
            "code": "PCollectionList.of(pc1).and(pc2).apply(Flatten.pCollections());",
            "explanation": "Merges multiple PCollections into a single PCollection."
          }
        ],
        "best_practices": [
          "Choose the appropriate runner (Flink, Spark, Dataflow) based on use case.",
          "Use windowing and triggers for accurate streaming computations.",
          "Minimize state and side inputs to reduce resource consumption.",
          "Monitor pipeline metrics and logs for optimization.",
          "Write unit tests using Beamâ€™s TestPipeline for correctness."
        ],
        "error_handling": [
          {
            "error": "PipelineExecutionException",
            "solution": "Occurs when a pipeline fails on execution. Check transforms, IO sources, and runner configuration."
          },
          {
            "error": "IOException",
            "solution": "Thrown when reading/writing from external sources. Verify file paths, network access, and permissions."
          },
          {
            "error": "IllegalArgumentException",
            "solution": "Check type specifications and transform parameters for correctness."
          }
        ]
      },
      "references": {
        "official_docs": "https://beam.apache.org/documentation/",
        "github": "https://github.com/apache/beam"
      }
    },
    {
      "id": "apache-camel",
      "name": "Apache Camel",
      "category": "Integration / Enterprise Application",
      "description": "Apache Camel is a versatile open-source integration framework that provides routing and mediation rules for connecting different systems. It implements Enterprise Integration Patterns (EIPs) and supports hundreds of components for various protocols and data formats.",
      "story": "Apache Camel was created to simplify system integration by providing a standard way to define routes and transformations. Developers can use Camel to connect databases, message brokers, REST APIs, and other systems with minimal boilerplate, making it popular in enterprise applications.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.apache.camel</groupId>\n  <artifactId>camel-core</artifactId>\n  <version>3.23.0</version>\n</dependency>",
        "gradle": "implementation 'org.apache.camel:camel-core:3.23.0'"
      },
      "usage": {
        "overview": "Camel allows you to define routes using Java DSL, XML DSL, or Spring Boot integration. It supports message transformation, filtering, aggregation, and protocol bridging, including HTTP, JMS, Kafka, File, and more.",
        "basic_examples": [
          {
            "title": "Simple route from file to console",
            "code": "import org.apache.camel.CamelContext;\nimport org.apache.camel.builder.RouteBuilder;\nimport org.apache.camel.impl.DefaultCamelContext;\n\nCamelContext context = new DefaultCamelContext();\ncontext.addRoutes(new RouteBuilder() {\n    @Override\n    public void configure() {\n        from(\"file:input\").to(\"stream:out\");\n    }\n});\ncontext.start();\nThread.sleep(5000);\ncontext.stop();",
            "explanation": "Reads files from the 'input' directory and prints their contents to the console."
          },
          {
            "title": "HTTP to file route",
            "code": "from(\"jetty:http://0.0.0.0:8080/hello\")\n    .to(\"file:output\");",
            "explanation": "Accepts HTTP requests and writes request bodies to files."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using processors for custom transformations",
            "code": "from(\"file:input\")\n    .process(exchange -> {\n        String body = exchange.getIn().getBody(String.class);\n        exchange.getMessage().setBody(body.toUpperCase());\n    })\n    .to(\"file:output\");",
            "explanation": "Applies custom transformation logic using a Processor before sending messages."
          },
          {
            "title": "Routing with conditions",
            "code": "from(\"file:input\")\n    .choice()\n        .when(header(\"CamelFileName\").endsWith(\".txt\")).to(\"file:txtOutput\")\n        .otherwise().to(\"file:otherOutput\");",
            "explanation": "Routes files to different destinations based on file extension using content-based routing."
          },
          {
            "title": "Integration with Kafka",
            "code": "from(\"kafka:my-topic?brokers=localhost:9092\")\n    .to(\"file:output\");",
            "explanation": "Consumes messages from a Kafka topic and writes them to a file."
          },
          {
            "title": "Error handling",
            "code": "onException(Exception.class)\n    .handled(true)\n    .log(\"Error occurred: ${exception.message}\");",
            "explanation": "Handles exceptions in routes and logs the error message without stopping the route."
          }
        ],
        "best_practices": [
          "Use Camel components appropriate for your protocols and systems.",
          "Define routes using Java DSL for easier IDE support and refactoring.",
          "Apply content-based routing and filtering for clean message flows.",
          "Leverage error handling and dead-letter channels for robust integration.",
          "Monitor routes using JMX or Camelâ€™s management tools."
        ],
        "error_handling": [
          {
            "error": "org.apache.camel.CamelExecutionException",
            "solution": "Occurs when a route fails during execution. Check route configuration, endpoints, and processors."
          },
          {
            "error": "Connection refused",
            "solution": "Ensure target systems (HTTP, JMS, Kafka, etc.) are reachable and listening on correct ports."
          },
          {
            "error": "FileNotFoundException",
            "solution": "Verify source and destination directories exist and have proper permissions."
          }
        ]
      },
      "references": {
        "official_docs": "https://camel.apache.org/manual/latest/",
        "github": "https://github.com/apache/camel"
      }
    },
    {
      "id": "apache-nifi",
      "name": "Apache NiFi",
      "category": "Data Flow / ETL / Integration",
      "description": "Apache NiFi is an open-source data integration and automation tool for designing, managing, and monitoring data flows. It supports real-time data ingestion, routing, transformation, and delivery between systems.",
      "story": "NiFi was created by the NSA and later contributed to the Apache Software Foundation. It provides a visual interface to build data pipelines with minimal coding. NiFi is widely used for streaming, ETL, and IoT data flows, enabling reliable and scalable data integration across heterogeneous systems.",
      "installation": {
        "maven": "<dependency>\n  <groupId>org.apache.nifi</groupId>\n  <artifactId>nifi-api</artifactId>\n  <version>1.25.0</version>\n</dependency>",
        "gradle": "implementation 'org.apache.nifi:nifi-api:1.25.0'"
      },
      "usage": {
        "overview": "NiFi provides processors to ingest, transform, and route data. Developers can create flow-based pipelines using its web-based UI or programmatically via the NiFi API. It supports scheduling, provenance tracking, and backpressure for robust data management.",
        "basic_examples": [
          {
            "title": "Reading from a file and writing to another directory",
            "code": "// Configure GetFile processor to read input files\n// Configure PutFile processor to write files to output directory\n// Connect processors using a connection in the NiFi UI",
            "explanation": "Moves files from input to output directory with monitoring and error handling."
          },
          {
            "title": "HTTP ingestion",
            "code": "// Use ListenHTTP processor to accept incoming HTTP requests\n// Route the data to processors for transformation or storage",
            "explanation": "Ingests data from HTTP endpoints into the NiFi pipeline."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using ExecuteScript for custom processing",
            "code": "// Add ExecuteScript processor with Groovy, Python, or JavaScript code to transform flow files",
            "explanation": "Enables custom transformations within the data flow."
          },
          {
            "title": "Routing based on content",
            "code": "// Use RouteOnAttribute processor to send flow files to different paths based on content attributes",
            "explanation": "Implements content-based routing for dynamic pipeline behavior."
          },
          {
            "title": "Connecting to Kafka",
            "code": "// Use PublishKafkaRecord_2_0 or ConsumeKafkaRecord_2_0 processors to integrate with Kafka topics",
            "explanation": "Enables streaming integration between NiFi pipelines and Kafka messaging system."
          },
          {
            "title": "Monitoring data provenance",
            "code": "// NiFi automatically tracks data provenance for each flow file, allowing traceability",
            "explanation": "Provides audit and debugging capabilities for complex pipelines."
          }
        ],
        "best_practices": [
          "Use backpressure to control flow rates for large pipelines.",
          "Leverage NiFi provenance and monitoring features for auditing.",
          "Design modular flows with reusable processors.",
          "Validate input data and handle errors gracefully using relationships.",
          "Use NiFi Parameter Contexts for environment-specific configurations."
        ],
        "error_handling": [
          {
            "error": "Processor failed to execute",
            "solution": "Check processor configuration, input data format, and dependencies."
          },
          {
            "error": "FlowFile queue full",
            "solution": "Adjust backpressure thresholds or optimize flow to prevent bottlenecks."
          },
          {
            "error": "Kafka connection error",
            "solution": "Ensure Kafka brokers are running, reachable, and credentials are correct."
          }
        ]
      },
      "references": {
        "official_docs": "https://nifi.apache.org/docs.html",
        "github": "https://github.com/apache/nifi"
      }
    }
  ]