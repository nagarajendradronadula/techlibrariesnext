[
    {
      "id": "requests",
      "name": "Requests",
      "category": "Web",
      "description": "Requests is an elegant and simple HTTP library for Python, designed to make sending HTTP/1.1 requests easy and human-friendly. It abstracts the complexities of handling HTTP connections, cookies, headers, and authentication.",
      "story": "Requests was created by Kenneth Reitz in 2011 to simplify HTTP requests in Python. Its goal was to provide a more readable and intuitive API compared to urllib and urllib2. Over the years, it became one of the most widely used Python libraries for web interactions, API clients, and automation tasks.",
      "installation": {
        "pip": "pip install requests",
        "conda": "conda install requests"
      },
      "usage": {
        "overview": "Requests allows you to send HTTP/1.1 requests using methods such as GET, POST, PUT, DELETE, HEAD, and OPTIONS. You can pass parameters, headers, JSON payloads, handle cookies, manage sessions, and handle authentication easily.",
        "basic_examples": [
          {
            "title": "Simple GET request",
            "code": "import requests\nresponse = requests.get('https://httpbin.org/get')\nprint(response.status_code)\nprint(response.json())",
            "explanation": "This example performs a GET request to a URL and prints the HTTP status code and JSON response."
          },
          {
            "title": "POST request with JSON payload",
            "code": "import requests\npayload = {'key':'value'}\nresponse = requests.post('https://httpbin.org/post', json=payload)\nprint(response.json())",
            "explanation": "Sends a POST request with a JSON payload to the specified URL."
          }
        ],
        "advanced_examples": [
          {
            "title": "Session handling",
            "code": "import requests\nsession = requests.Session()\nsession.get('https://httpbin.org/cookies/set/sessioncookie/123456789')\nresponse = session.get('https://httpbin.org/cookies')\nprint(response.text)",
            "explanation": "Uses a Session object to persist cookies and headers across multiple requests."
          },
          {
            "title": "Custom headers",
            "code": "import requests\nheaders = {'User-Agent': 'my-app/0.0.1'}\nresponse = requests.get('https://httpbin.org/headers', headers=headers)\nprint(response.json())",
            "explanation": "Shows how to send custom HTTP headers with a request."
          },
          {
            "title": "Timeouts and retries",
            "code": "import requests\ntry:\n    response = requests.get('https://httpbin.org/delay/10', timeout=5)\nexcept requests.exceptions.Timeout:\n    print('Request timed out')",
            "explanation": "Demonstrates handling of request timeouts."
          }
        ],
        "error_handling": [
          {
            "error": "requests.exceptions.Timeout",
            "solution": "Use the timeout parameter in requests.get/post to prevent indefinite waiting."
          },
          {
            "error": "requests.exceptions.ConnectionError",
            "solution": "Check network connectivity or use retry mechanisms for robustness."
          },
          {
            "error": "requests.exceptions.HTTPError",
            "solution": "Call response.raise_for_status() to catch HTTP errors like 4xx or 5xx."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.python-requests.org/",
        "github": "https://github.com/psf/requests"
      }
    },
    {
      "id": "flask",
      "name": "Flask",
      "category": "Web",
      "description": "Flask is a lightweight and micro web framework for Python, ideal for building small to medium-sized web applications and APIs. It provides the essential tools for web development without imposing a specific project structure, giving developers flexibility and simplicity.",
      "story": "Flask was created by Armin Ronacher in 2010 as part of the Pocoo project. It was designed to provide a minimal yet extensible web framework that doesn’t force particular dependencies or structure. Flask emphasizes simplicity, readability, and freedom of choice, making it a popular choice for web apps, APIs, and rapid prototyping.",
      "installation": {
        "pip": "pip install flask",
        "conda": "conda install flask"
      },
      "usage": {
        "overview": "Flask allows you to define routes, request handlers, templates, and more. It supports RESTful routing, URL parameters, sessions, cookies, and templating via Jinja2. You can build APIs, web services, or full-fledged web applications with ease.",
        "basic_examples": [
          {
            "title": "Simple Hello World App",
            "code": "from flask import Flask\napp = Flask(__name__)\n\n@app.get('/')\ndef home():\n    return 'Hello, World!'\n\nif __name__ == '__main__':\n    app.run(debug=True)",
            "explanation": "This example creates a basic Flask app with a single route `/`. Running this file starts a local server on port 5000 with debug mode enabled."
          },
          {
            "title": "Using URL Parameters",
            "code": "from flask import Flask\napp = Flask(__name__)\n\n@app.get('/user/<username>')\ndef greet_user(username):\n    return f'Hello, {username}!'\n\napp.run(debug=True)",
            "explanation": "Flask supports dynamic URL parameters. Here, `<username>` is captured from the URL and passed to the `greet_user` function."
          }
        ],
        "advanced_examples": [
          {
            "title": "JSON Responses",
            "code": "from flask import Flask, jsonify\napp = Flask(__name__)\n\n@app.get('/data')\ndef data():\n    return jsonify({'name': 'Flask', 'type': 'web framework'})\n\napp.run(debug=True)",
            "explanation": "Use `jsonify` to return JSON responses, suitable for building APIs."
          },
          {
            "title": "Handling POST Requests",
            "code": "from flask import Flask, request, jsonify\napp = Flask(__name__)\n\n@app.post('/submit')\ndef submit():\n    data = request.json\n    return jsonify({'received': data})\n\napp.run(debug=True)",
            "explanation": "Handle POST requests and access JSON data from `request.json`."
          },
          {
            "title": "Using Templates",
            "code": "from flask import Flask, render_template\napp = Flask(__name__)\n\n@app.get('/')\ndef home():\n    return render_template('index.html', title='Welcome')\n\napp.run(debug=True)",
            "explanation": "Flask integrates with Jinja2 templates. `render_template` renders HTML templates with variables."
          }
        ],
        "best_practices": [
          "Organize your app into blueprints for modularity.",
          "Use environment variables for configuration (Flask config object).",
          "Enable debug mode only in development.",
          "Validate user inputs to prevent injection attacks.",
          "Use Flask extensions for added functionality (Flask-Login, Flask-Migrate, etc.)."
        ],
        "error_handling": [
          {
            "error": "404 Not Found",
            "solution": "Use `@app.errorhandler(404)` to define a custom handler for missing routes."
          },
          {
            "error": "500 Internal Server Error",
            "solution": "Use `@app.errorhandler(500)` to catch unhandled exceptions and log them."
          }
        ]
      },
      "references": {
        "official_docs": "https://flask.palletsprojects.com/",
        "github": "https://github.com/pallets/flask"
      }
    },
    {
      "id": "fastapi",
      "name": "FastAPI",
      "category": "Web",
      "description": "FastAPI is a modern, high-performance Python web framework for building APIs with automatic interactive documentation, leveraging Python type hints for data validation and serialization.",
      "story": "FastAPI was created by Sebastián Ramírez in 2018. Its goal was to provide a framework that is fast (high-performance), easy to use, and fully compatible with modern Python features like type hints and async programming. It automatically generates OpenAPI and Swagger documentation for your APIs, making it a popular choice for building RESTful services and microservices.",
      "installation": {
        "pip": "pip install fastapi[all]",
        "conda": "conda install -c conda-forge fastapi uvicorn"
      },
      "usage": {
        "overview": "FastAPI allows you to define API endpoints using Python function definitions with type annotations. It supports async operations, request validation, automatic docs generation, dependency injection, security, and more.",
        "basic_examples": [
          {
            "title": "Simple GET endpoint",
            "code": "from fastapi import FastAPI\napp = FastAPI()\n\n@app.get('/items/{id}')\nasync def read_item(id: int):\n    return {'id': id}",
            "explanation": "Defines a GET endpoint at /items/{id}. The 'id' parameter is type-checked as an integer automatically."
          },
          {
            "title": "POST endpoint with JSON body",
            "code": "from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\nclass Item(BaseModel):\n    name: str\n    price: float\n\n@app.post('/items/')\nasync def create_item(item: Item):\n    return item",
            "explanation": "FastAPI uses Pydantic models to validate and parse JSON request bodies."
          }
        ],
        "advanced_examples": [
          {
            "title": "Query parameters with validation",
            "code": "from fastapi import FastAPI, Query\napp = FastAPI()\n\n@app.get('/search')\nasync def search(q: str = Query(..., min_length=3, max_length=50)):\n    return {'query': q}",
            "explanation": "Defines a query parameter 'q' with minimum and maximum length validation."
          },
          {
            "title": "Path parameters with type enforcement",
            "code": "@app.get('/users/{user_id}')\nasync def get_user(user_id: int):\n    return {'user_id': user_id}",
            "explanation": "Ensures the user_id path parameter is an integer."
          },
          {
            "title": "Automatic interactive API docs",
            "code": "# Run your FastAPI app using uvicorn:\n# uvicorn main:app --reload",
            "explanation": "Once running, visit /docs for Swagger UI or /redoc for ReDoc-generated API docs."
          },
          {
            "title": "Dependency injection",
            "code": "from fastapi import Depends\n\nasync def common_parameters(q: str = None, limit: int = 10):\n    return {'q': q, 'limit': limit}\n\n@app.get('/items/')\nasync def read_items(commons: dict = Depends(common_parameters)):\n    return commons",
            "explanation": "Allows reusing common parameters and logic across endpoints."
          }
        ],
        "best_practices": [
          "Use Pydantic models for request validation and response models.",
          "Leverage async endpoints for IO-bound operations.",
          "Use dependency injection for reusable logic like authentication or DB connections.",
          "Keep path and query parameters explicit for clarity.",
          "Include meaningful tags and summaries for better auto-generated documentation."
        ],
        "error_handling": [
          {
            "error": "422 Unprocessable Entity",
            "solution": "Occurs when request body validation fails. Ensure JSON fields match Pydantic model types."
          },
          {
            "error": "404 Not Found",
            "solution": "Use proper path parameters and raise HTTPException with status_code=404 when resources are missing."
          }
        ]
      },
      "references": {
        "official_docs": "https://fastapi.tiangolo.com/",
        "github": "https://github.com/tiangolo/fastapi"
      }
    },
    {
      "id": "django",
      "name": "Django",
      "category": "Web",
      "description": "Django is a high-level Python web framework that encourages rapid development and clean, pragmatic design. It includes built-in tools for database ORM, authentication, templating, routing, and an admin interface.",
      "story": "Django was created by Adrian Holovaty and Simon Willison in 2005 at the Lawrence Journal-World newspaper. Its goal was to simplify web development by providing reusable components and a 'batteries-included' philosophy. Over time, it became one of the most widely used Python frameworks for building scalable, secure web applications.",
      "installation": {
        "pip": "pip install django",
        "conda": "conda install django"
      },
      "usage": {
        "overview": "Django enables developers to quickly create web applications with structured models, views, templates, and URLs. It provides an admin interface out-of-the-box and includes features like authentication, sessions, forms, and security mechanisms.",
        "basic_examples": [
          {
            "title": "Creating a new project",
            "code": "# Terminal commands\ndjango-admin startproject mysite\ncd mysite\npython manage.py runserver",
            "explanation": "Starts a new Django project named 'mysite'. Running the server starts a local development server at http://127.0.0.1:8000/."
          },
          {
            "title": "Creating a new app",
            "code": "# Terminal commands\npython manage.py startapp blog",
            "explanation": "Creates a new Django app called 'blog' inside your project. Apps encapsulate related models, views, and templates."
          }
        ],
        "advanced_examples": [
          {
            "title": "Defining models and migrations",
            "code": "from django.db import models\n\nclass Post(models.Model):\n    title = models.CharField(max_length=100)\n    content = models.TextField()\n    created_at = models.DateTimeField(auto_now_add=True)",
            "explanation": "Defines a Post model. Use `python manage.py makemigrations` and `python manage.py migrate` to create the database schema."
          },
          {
            "title": "Views and URL routing",
            "code": "from django.shortcuts import render\nfrom django.urls import path\n\n# views.py\ndef home(request):\n    return render(request, 'home.html')\n\n# urls.py\nurlpatterns = [path('', home, name='home')]",
            "explanation": "Defines a view function `home` and maps it to the root URL. Django uses URLconf to connect URLs to views."
          },
          {
            "title": "Using the Django Admin Interface",
            "code": "# Register model in admin.py\nfrom django.contrib import admin\nfrom .models import Post\nadmin.site.register(Post)",
            "explanation": "Adds your model to the admin interface so you can manage database records through the built-in web UI."
          }
        ],
        "best_practices": [
          "Keep apps modular and reusable.",
          "Use Django's built-in authentication and permission system for security.",
          "Leverage class-based views for complex logic.",
          "Separate settings for development and production.",
          "Use environment variables for sensitive data."
        ],
        "error_handling": [
          {
            "error": "OperationalError",
            "solution": "Ensure migrations are applied and database is accessible."
          },
          {
            "error": "TemplateDoesNotExist",
            "solution": "Check the template directory settings and file paths."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.djangoproject.com/",
        "github": "https://github.com/django/django"
      }
    },
    {
      "id": "pandas",
      "name": "Pandas",
      "category": "Data Science",
      "description": "Pandas is a powerful Python library for data manipulation and analysis. It provides fast, flexible, and expressive data structures such as Series and DataFrame for working with structured data.",
      "story": "Pandas was created by Wes McKinney in 2008 to provide a high-performance, user-friendly data analysis tool for Python. It has become the standard library for data manipulation in Python, widely used in data science, finance, research, and analytics.",
      "installation": {
        "pip": "pip install pandas",
        "conda": "conda install pandas"
      },
      "usage": {
        "overview": "Pandas allows for easy reading, writing, and manipulation of data from multiple sources including CSV, Excel, SQL databases, and more. You can filter, aggregate, group, pivot, merge, and reshape datasets efficiently.",
        "basic_examples": [
          {
            "title": "Loading a CSV and viewing data",
            "code": "import pandas as pd\ndf = pd.read_csv('data.csv')\nprint(df.head())",
            "explanation": "Reads a CSV file into a DataFrame and displays the first five rows."
          },
          {
            "title": "Selecting columns and rows",
            "code": "print(df['column_name'])\nprint(df.iloc[0])",
            "explanation": "Access columns by name and rows by index."
          }
        ],
        "advanced_examples": [
          {
            "title": "Filtering and grouping data",
            "code": "filtered = df[df['age'] > 30]\ngrouped = filtered.groupby('department').mean()",
            "explanation": "Filter rows based on a condition and then group by a column to calculate mean values."
          },
          {
            "title": "Merging DataFrames",
            "code": "merged = pd.merge(df1, df2, on='id', how='inner')",
            "explanation": "Combine two DataFrames on a common column using an inner join."
          },
          {
            "title": "Pivot tables",
            "code": "pivot = df.pivot_table(index='department', columns='gender', values='salary', aggfunc='mean')",
            "explanation": "Create a pivot table to summarize data efficiently."
          }
        ],
        "best_practices": [
          "Use vectorized operations instead of loops for performance.",
          "Clean data before analysis: handle missing values, duplicates, and inconsistent types.",
          "Use descriptive column names for readability.",
          "Leverage built-in aggregation functions for efficiency.",
          "Profile large datasets with df.info() and df.describe() before processing."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundError",
            "solution": "Ensure the file path is correct when reading CSV/Excel files."
          },
          {
            "error": "KeyError",
            "solution": "Verify column names exist before accessing them."
          },
          {
            "error": "ValueError",
            "solution": "Check the shape and alignment of DataFrames when merging or concatenating."
          }
        ]
      },
      "references": {
        "official_docs": "https://pandas.pydata.org/docs/",
        "github": "https://github.com/pandas-dev/pandas"
      }
    },
    {
      "id": "numpy",
      "name": "NumPy",
      "category": "Data Science",
      "description": "NumPy is a fundamental package for scientific computing in Python. It provides powerful n-dimensional array objects, vectorized operations, linear algebra functions, random number capabilities, and integration with C/C++ and Fortran code.",
      "story": "NumPy was created in 2005 by Travis Oliphant as an evolution of the older Numeric and Numarray libraries. It standardized array computing in Python and became the backbone of the Python scientific computing ecosystem, enabling high-performance numerical computations.",
      "installation": {
        "pip": "pip install numpy",
        "conda": "conda install numpy"
      },
      "usage": {
        "overview": "NumPy provides ndarray, a multidimensional array object, and functions for fast operations on arrays. It supports element-wise operations, broadcasting, linear algebra, statistical functions, random sampling, and more.",
        "basic_examples": [
          {
            "title": "Creating arrays and basic operations",
            "code": "import numpy as np\narr = np.array([1,2,3])\nprint(arr + 1)\nprint(arr * 2)",
            "explanation": "Create a 1D array and perform element-wise addition and multiplication."
          },
          {
            "title": "2D arrays and matrix multiplication",
            "code": "import numpy as np\nA = np.array([[1,2],[3,4]])\nB = np.array([[5,6],[7,8]])\nprint(A @ B)",
            "explanation": "Create 2x2 matrices and perform matrix multiplication using the @ operator."
          }
        ],
        "advanced_examples": [
          {
            "title": "Broadcasting example",
            "code": "import numpy as np\narr = np.array([[1,2,3],[4,5,6]])\nprint(arr + np.array([10,20,30]))",
            "explanation": "Demonstrates broadcasting: the 1D array is automatically expanded to match the 2D array for element-wise addition."
          },
          {
            "title": "Statistical functions",
            "code": "import numpy as np\narr = np.array([1,2,3,4,5])\nprint(np.mean(arr))\nprint(np.std(arr))",
            "explanation": "Compute mean and standard deviation of a numeric array."
          },
          {
            "title": "Random sampling",
            "code": "import numpy as np\nrand_arr = np.random.randn(3,3)\nprint(rand_arr)",
            "explanation": "Generate a 3x3 array of samples from a standard normal distribution."
          },
          {
            "title": "Linear algebra operations",
            "code": "import numpy as np\nA = np.array([[1,2],[3,4]])\nprint(np.linalg.inv(A))\nprint(np.linalg.eig(A))",
            "explanation": "Compute the inverse and eigenvalues/eigenvectors of a square matrix."
          }
        ],
        "best_practices": [
          "Use vectorized operations instead of Python loops for performance.",
          "Leverage broadcasting for efficient computation on arrays of different shapes.",
          "Prefer NumPy functions over manual Python calculations for large datasets.",
          "Be mindful of array shapes and memory layout (C-contiguous vs F-contiguous).",
          "Use NumPy random functions with fixed seeds for reproducibility in experiments."
        ],
        "error_handling": [
          {
            "error": "ValueError: shapes not aligned",
            "solution": "Check that matrix dimensions match when performing dot products or matrix multiplication."
          },
          {
            "error": "IndexError: index out of bounds",
            "solution": "Ensure array indices are within valid dimensions."
          },
          {
            "error": "TypeError: unsupported operand type",
            "solution": "Verify that arrays have compatible numeric types for operations."
          }
        ]
      },
      "references": {
        "official_docs": "https://numpy.org/doc/",
        "github": "https://github.com/numpy/numpy"
      }
    },
    {
      "id": "scipy",
      "name": "SciPy",
      "category": "Data Science",
      "description": "SciPy is an open-source Python library used for scientific and technical computing. It builds on NumPy arrays and provides a wide range of algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, and signal processing.",
      "story": "SciPy was initially created in 2001 by Travis Oliphant, Eric Jones, and Pearu Peterson. It was designed to extend NumPy’s capabilities by providing high-level functions for scientific computations. SciPy has since become a core library in the Python scientific ecosystem and is widely used in engineering, physics, machine learning, and data analysis.",
      "installation": {
        "pip": "pip install scipy",
        "conda": "conda install scipy"
      },
      "usage": {
        "overview": "SciPy provides modules for optimization, linear algebra, signal and image processing, statistics, integration, and more. It integrates seamlessly with NumPy arrays and allows advanced scientific computations with minimal code.",
        "basic_examples": [
          {
            "title": "Minimizing a function",
            "code": "from scipy import optimize\nf = lambda x: (x - 3)**2\nresult = optimize.minimize(lambda v: f(v[0]), x0=[0])\nprint(result)",
            "explanation": "Demonstrates minimizing a simple quadratic function using SciPy's `optimize.minimize` function."
          },
          {
            "title": "Computing definite integrals",
            "code": "from scipy import integrate\nresult, error = integrate.quad(lambda x: x**2, 0, 1)\nprint(result)",
            "explanation": "Uses `integrate.quad` to compute the definite integral of x² from 0 to 1."
          }
        ],
        "advanced_examples": [
          {
            "title": "Solving linear systems",
            "code": "from scipy import linalg\nimport numpy as np\nA = np.array([[3,2],[1,2]])\nb = np.array([5,5])\nx = linalg.solve(A, b)\nprint(x)",
            "explanation": "Uses SciPy’s linear algebra module to solve a system of linear equations."
          },
          {
            "title": "Signal processing example",
            "code": "from scipy import signal\nimport numpy as np\nb, a = signal.butter(3, 0.05)\nz = signal.lfilter(b, a, np.random.randn(1000))\nprint(z[:10])",
            "explanation": "Designs a 3rd-order Butterworth filter and applies it to a random signal using `signal.lfilter`."
          },
          {
            "title": "Interpolation example",
            "code": "from scipy import interpolate\nimport numpy as np\nx = np.arange(5)\ny = np.sin(x)\nf = interpolate.interp1d(x, y)\nprint(f(2.5))",
            "explanation": "Performs linear interpolation between data points using SciPy’s `interp1d` function."
          }
        ],
        "best_practices": [
          "Use NumPy arrays for input data to ensure compatibility with SciPy functions.",
          "Check function domains and constraints when using optimization routines.",
          "Leverage built-in documentation for each submodule to understand parameter options.",
          "Use `scipy.constants` for physical constants to improve code readability and accuracy.",
          "Profile computations for large datasets using vectorized operations rather than loops."
        ],
        "error_handling": [
          {
            "error": "ValueError",
            "solution": "Ensure inputs have correct shapes and types expected by the function."
          },
          {
            "error": "LinAlgError",
            "solution": "Check that matrices are square and non-singular when performing linear algebra operations."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.scipy.org/doc/scipy/",
        "github": "https://github.com/scipy/scipy"
      }
    },
    {
      "id": "matplotlib",
      "name": "Matplotlib",
      "category": "Data Science",
      "description": "Matplotlib is a comprehensive 2D plotting library for Python. It allows the creation of high-quality graphs, charts, and figures in various formats, suitable for publication and interactive visualization.",
      "story": "Matplotlib was originally created by John D. Hunter in 2003 to provide a MATLAB-like plotting interface for Python. It has become the foundation for many Python visualization libraries, including Seaborn and Pandas plotting utilities, and remains widely used in data analysis, scientific research, and machine learning.",
      "installation": {
        "pip": "pip install matplotlib",
        "conda": "conda install matplotlib"
      },
      "usage": {
        "overview": "Matplotlib allows you to create line plots, scatter plots, bar charts, histograms, 3D plots, and more. The library provides both an object-oriented interface and a state-based interface (pyplot) to build plots programmatically or interactively.",
        "basic_examples": [
          {
            "title": "Simple Line Plot",
            "code": "import matplotlib.pyplot as plt\nplt.plot([1, 2, 3], [2, 3, 5])\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.title('Simple Line Plot')\nplt.show()",
            "explanation": "Creates a basic line plot with labeled axes and a title."
          },
          {
            "title": "Scatter Plot",
            "code": "import matplotlib.pyplot as plt\nx = [1, 2, 3, 4]\ny = [10, 20, 25, 30]\nplt.scatter(x, y, color='red', marker='x')\nplt.show()",
            "explanation": "Generates a scatter plot with custom color and marker type."
          }
        ],
        "advanced_examples": [
          {
            "title": "Subplots",
            "code": "import matplotlib.pyplot as plt\nfig, axs = plt.subplots(2, 1)\naxs[0].plot([1,2,3],[1,4,9])\naxs[1].bar([1,2,3],[5,2,7])\nplt.show()",
            "explanation": "Shows multiple plots in a single figure using subplots."
          },
          {
            "title": "Customizing styles",
            "code": "import matplotlib.pyplot as plt\nplt.style.use('ggplot')\nplt.plot([1,2,3],[1,4,9])\nplt.show()",
            "explanation": "Applies a built-in style to enhance visual aesthetics."
          },
          {
            "title": "3D Plot",
            "code": "from mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nimport numpy as np\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nx = np.linspace(0,5,100)\ny = np.sin(x)\nz = np.cos(x)\nax.plot(x,y,z)\nplt.show()",
            "explanation": "Demonstrates creating a 3D line plot."
          },
          {
            "title": "Histogram",
            "code": "import matplotlib.pyplot as plt\ndata = [1,1,2,3,3,3,4,4,5]\nplt.hist(data, bins=5, color='purple', alpha=0.7)\nplt.show()",
            "explanation": "Plots a histogram with specified number of bins and styling."
          }
        ],
        "best_practices": [
          "Use the object-oriented interface for complex plots for more control.",
          "Label axes and add titles to improve readability.",
          "Use grid lines and legends where appropriate.",
          "Combine Matplotlib with NumPy for efficient data plotting.",
          "Save figures using `plt.savefig()` for reproducibility."
        ],
        "error_handling": [
          {
            "error": "ValueError: x and y must have same first dimension",
            "solution": "Ensure your x and y data arrays have the same length."
          },
          {
            "error": "ImportError: mpl_toolkits not found",
            "solution": "Install Matplotlib fully and ensure the toolkit is available for 3D plots."
          }
        ]
      },
      "references": {
        "official_docs": "https://matplotlib.org/stable/contents.html",
        "github": "https://github.com/matplotlib/matplotlib"
      }
    },
    {
      "id": "seaborn",
      "name": "Seaborn",
      "category": "Data Science",
      "description": "Seaborn is a Python data visualization library based on Matplotlib that provides a high-level interface for drawing attractive and informative statistical graphics.",
      "story": "Seaborn was created by Michael Waskom in 2014 to simplify the creation of complex statistical plots. It integrates closely with Pandas data structures and makes it easy to generate visualizations that include summaries of datasets and categorical relationships.",
      "installation": {
        "pip": "pip install seaborn",
        "conda": "conda install seaborn"
      },
      "usage": {
        "overview": "Seaborn simplifies the process of creating visualizations such as bar plots, box plots, violin plots, heatmaps, and pair plots. It provides aesthetic defaults and works directly with Pandas DataFrames.",
        "basic_examples": [
          {
            "title": "Simple histogram",
            "code": "import seaborn as sns\nsns.histplot([1,1,2,3,5])",
            "explanation": "Plots a histogram of the given list of values using Seaborn’s default styling."
          },
          {
            "title": "Scatter plot with regression line",
            "code": "import seaborn as sns\nimport pandas as pd\ndf = pd.DataFrame({'x':[1,2,3,4],'y':[2,3,5,7]})\nsns.regplot(x='x', y='y', data=df)",
            "explanation": "Creates a scatter plot and automatically fits a regression line to the data."
          }
        ],
        "advanced_examples": [
          {
            "title": "Boxplot for categorical data",
            "code": "import seaborn as sns\nimport pandas as pd\ndf = pd.DataFrame({'category':['A','A','B','B'], 'value':[10,12,20,22]})\nsns.boxplot(x='category', y='value', data=df)",
            "explanation": "Visualizes the distribution of values for each category using a boxplot."
          },
          {
            "title": "Heatmap",
            "code": "import seaborn as sns\nimport numpy as np\ndata = np.random.rand(5,5)\nsns.heatmap(data, annot=True, cmap='coolwarm')",
            "explanation": "Creates a heatmap of a 2D dataset with annotations and a custom color map."
          },
          {
            "title": "Pairplot for relationships",
            "code": "import seaborn as sns\nimport pandas as pd\ndf = sns.load_dataset('iris')\nsns.pairplot(df, hue='species')",
            "explanation": "Plots pairwise relationships in a dataset, colored by species."
          }
        ],
        "best_practices": [
          "Use Pandas DataFrames for structured data input.",
          "Leverage Seaborn’s built-in themes for visually appealing plots.",
          "Combine with Matplotlib for custom modifications.",
          "Use hue, style, and size parameters to enhance multi-dimensional plots.",
          "Always label axes and provide legends for clarity."
        ],
        "error_handling": [
          {
            "error": "ValueError: Could not interpret input",
            "solution": "Ensure the column names used in the plot match those in the DataFrame."
          },
          {
            "error": "ImportError: No module named 'seaborn'",
            "solution": "Install Seaborn using pip or conda before importing."
          }
        ]
      },
      "references": {
        "official_docs": "https://seaborn.pydata.org/",
        "github": "https://github.com/mwaskom/seaborn"
      }
    },
    {
      "id": "scikit-learn",
      "name": "Scikit-learn",
      "category": "ML/AI",
      "description": "Scikit-learn is a Python library for machine learning that provides simple and efficient tools for data mining, analysis, and modeling. It includes algorithms for classification, regression, clustering, dimensionality reduction, and model evaluation.",
      "story": "Scikit-learn was initially developed by David Cournapeau in 2007 and has since evolved into a widely used open-source machine learning library maintained by a large community. It is built on top of NumPy, SciPy, and Matplotlib, and is widely adopted in both academia and industry for machine learning tasks.",
      "installation": {
        "pip": "pip install scikit-learn",
        "conda": "conda install scikit-learn"
      },
      "usage": {
        "overview": "Scikit-learn provides consistent APIs for different machine learning algorithms. You can fit models to data, predict outcomes, evaluate performance, and preprocess datasets with transformers and pipelines.",
        "basic_examples": [
          {
            "title": "Training a simple classifier",
            "code": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nmodel = LogisticRegression(max_iter=200)\nmodel.fit(X_train, y_train)\nprint(model.score(X_test, y_test))",
            "explanation": "Loads the Iris dataset, splits it into training and testing sets, trains a logistic regression model, and evaluates accuracy."
          },
          {
            "title": "K-Means clustering",
            "code": "from sklearn.cluster import KMeans\nimport numpy as np\nX = np.array([[1,2],[1,4],[1,0],[10,2],[10,4],[10,0]])\nkmeans = KMeans(n_clusters=2, random_state=0).fit(X)\nprint(kmeans.labels_)",
            "explanation": "Performs K-Means clustering on a small dataset and prints cluster labels."
          }
        ],
        "advanced_examples": [
          {
            "title": "Pipeline with preprocessing and classifier",
            "code": "from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\npipeline = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\npipeline.fit(X_train, y_train)\nprint(pipeline.score(X_test, y_test))",
            "explanation": "Combines preprocessing and classification into a single pipeline for clean and reproducible ML workflows."
          },
          {
            "title": "Cross-validation",
            "code": "from sklearn.model_selection import cross_val_score\nscores = cross_val_score(model, X, y, cv=5)\nprint(scores)",
            "explanation": "Performs 5-fold cross-validation to evaluate model performance."
          },
          {
            "title": "Feature selection",
            "code": "from sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(f_classif, k=2)\nX_new = selector.fit_transform(X, y)\nprint(X_new[:5])",
            "explanation": "Selects the two most important features from the dataset using ANOVA F-value."
          }
        ],
        "best_practices": [
          "Scale or normalize features when using distance-based algorithms.",
          "Use pipelines to combine preprocessing and modeling steps.",
          "Split data into training, validation, and test sets to avoid overfitting.",
          "Leverage cross-validation for robust performance evaluation.",
          "Understand the assumptions of each algorithm before applying it."
        ],
        "error_handling": [
          {
            "error": "ConvergenceWarning",
            "solution": "Increase `max_iter` or scale features when fitting models like LogisticRegression."
          },
          {
            "error": "ValueError: Input contains NaN",
            "solution": "Handle missing values using `SimpleImputer` or other preprocessing techniques."
          }
        ]
      },
      "references": {
        "official_docs": "https://scikit-learn.org/stable/",
        "github": "https://github.com/scikit-learn/scikit-learn"
      }
    },
    {
      "id": "tensorflow",
      "name": "TensorFlow",
      "category": "ML/AI",
      "description": "TensorFlow is an end-to-end open-source platform for machine learning. It allows you to build and deploy machine learning models easily, from training to inference, across multiple platforms and devices.",
      "story": "TensorFlow was developed by the Google Brain team and released in 2015. It was designed to provide a comprehensive ecosystem for developing, training, and deploying machine learning models. TensorFlow supports deep learning, neural networks, and large-scale numerical computations and has become one of the most widely used ML frameworks in both industry and academia.",
      "installation": {
        "pip": "pip install tensorflow",
        "conda": "conda install -c conda-forge tensorflow"
      },
      "usage": {
        "overview": "TensorFlow provides APIs for building neural networks, performing automatic differentiation, training models, and serving models for production. It supports both eager execution (imperative programming) and graph execution (declarative programming).",
        "basic_examples": [
          {
            "title": "Simple Tensor operations",
            "code": "import tensorflow as tf\nx = tf.constant([[1., 2.],[3., 4.]])\ny = tf.constant([[5., 6.],[7., 8.]])\nprint(tf.matmul(x, y))",
            "explanation": "Defines two constant tensors and performs matrix multiplication."
          },
          {
            "title": "Creating a simple neural network",
            "code": "from tensorflow import keras\nmodel = keras.Sequential([\n    keras.layers.Dense(10, activation='relu', input_shape=(5,)),\n    keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer='adam', loss='binary_crossentropy')",
            "explanation": "Creates a simple feedforward neural network with one hidden layer using the Keras API integrated in TensorFlow."
          }
        ],
        "advanced_examples": [
          {
            "title": "Training a model",
            "code": "import numpy as np\nX_train = np.random.rand(100,5)\ny_train = np.random.randint(0,2, size=(100,1))\nmodel.fit(X_train, y_train, epochs=10, batch_size=8)",
            "explanation": "Trains the previously defined model on synthetic data for 10 epochs with a batch size of 8."
          },
          {
            "title": "Saving and loading a model",
            "code": "model.save('my_model')\nnew_model = keras.models.load_model('my_model')",
            "explanation": "Demonstrates saving a trained model and loading it later for inference or further training."
          },
          {
            "title": "Using TensorFlow Datasets",
            "code": "import tensorflow_datasets as tfds\ndataset = tfds.load('mnist', split='train')\nfor example in dataset.take(1):\n    image, label = example['image'], example['label']\n    print(image.shape, label)",
            "explanation": "Shows how to load standard datasets from TensorFlow Datasets for training or testing."
          },
          {
            "title": "Custom training loop with GradientTape",
            "code": "x = tf.random.normal((10,3))\ny_true = tf.random.normal((10,1))\nweights = tf.Variable(tf.random.normal((3,1)))\nbias = tf.Variable(tf.zeros(1))\noptimizer = tf.optimizers.SGD(0.01)\nfor i in range(100):\n    with tf.GradientTape() as tape:\n        y_pred = tf.matmul(x, weights) + bias\n        loss = tf.reduce_mean(tf.square(y_true - y_pred))\n    grads = tape.gradient(loss, [weights, bias])\n    optimizer.apply_gradients(zip(grads, [weights, bias]))",
            "explanation": "Implements a custom training loop to optimize weights using TensorFlow’s GradientTape and optimizer API."
          }
        ],
        "best_practices": [
          "Use tf.data API for efficient data loading and preprocessing.",
          "Use eager execution for debugging and graph execution for production performance.",
          "Leverage TensorBoard for visualizing training metrics.",
          "Use mixed precision and hardware acceleration (GPU/TPU) for faster training.",
          "Organize models and code using the Keras API for simplicity and modularity."
        ],
        "error_handling": [
          {
            "error": "InvalidArgumentError",
            "solution": "Check input shapes and dtypes to ensure compatibility with model layers."
          },
          {
            "error": "ResourceExhaustedError",
            "solution": "Reduce batch size or use GPU/TPU memory more efficiently."
          },
          {
            "error": "ModuleNotFoundError: No module named 'tensorflow'",
            "solution": "Ensure TensorFlow is installed in the current Python environment using pip or conda."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.tensorflow.org/guide",
        "github": "https://github.com/tensorflow/tensorflow"
      }
    },
    {
      "id": "pytorch",
      "name": "PyTorch",
      "category": "ML/AI",
      "description": "PyTorch is an open-source deep learning framework for Python that provides dynamic computation graphs, GPU acceleration, and a flexible platform for building neural networks and machine learning models.",
      "story": "PyTorch was developed by Facebook's AI Research lab (FAIR) and released in 2016. It was designed to provide a more intuitive and flexible framework than TensorFlow at the time, supporting dynamic computation graphs that make debugging and experimentation easier. PyTorch quickly became popular in both research and production environments.",
      "installation": {
        "pip": "pip install torch torchvision torchaudio",
        "conda": "conda install pytorch torchvision torchaudio cpuonly -c pytorch"
      },
      "usage": {
        "overview": "PyTorch provides tensors, autograd for automatic differentiation, neural network modules (torch.nn), optimizers, and utilities for loading and preprocessing data. It supports CPU and GPU computations seamlessly.",
        "basic_examples": [
          {
            "title": "Creating tensors",
            "code": "import torch\nx = torch.tensor([[1,2],[3,4]])\ny = torch.rand(2,2)\nprint(x + y)",
            "explanation": "Creates a fixed tensor `x` and a random tensor `y` and performs element-wise addition."
          },
          {
            "title": "Matrix multiplication",
            "code": "import torch\nx = torch.rand(2,3)\ny = torch.rand(3,2)\nprint(torch.mm(x, y))",
            "explanation": "Performs matrix multiplication between two tensors using `torch.mm`."
          }
        ],
        "advanced_examples": [
          {
            "title": "Defining a simple neural network",
            "code": "import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(10, 5)\n        self.fc2 = nn.Linear(5, 1)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        return x\n\nmodel = Net()",
            "explanation": "Defines a feedforward neural network with one hidden layer using PyTorch's nn.Module."
          },
          {
            "title": "Training loop example",
            "code": "import torch.optim as optim\nx = torch.rand(100,10)\ny = torch.rand(100,1)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nfor epoch in range(10):\n    optimizer.zero_grad()\n    outputs = model(x)\n    loss = criterion(outputs, y)\n    loss.backward()\n    optimizer.step()\n    print(f'Epoch {epoch+1}, Loss: {loss.item()}')",
            "explanation": "Demonstrates a basic training loop for a regression model using MSE loss and SGD optimizer."
          },
          {
            "title": "Using GPU (CUDA)",
            "code": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nx, y = x.to(device), y.to(device)\noutputs = model(x)",
            "explanation": "Moves the model and tensors to GPU for accelerated computation if available."
          },
          {
            "title": "Automatic differentiation",
            "code": "x = torch.tensor([1.0,2.0,3.0], requires_grad=True)\ny = x.pow(2).sum()\ny.backward()\nprint(x.grad)",
            "explanation": "Uses autograd to automatically compute gradients of `y` with respect to `x`."
          }
        ],
        "best_practices": [
          "Use `torch.nn.Module` to structure neural networks cleanly.",
          "Leverage `torch.utils.data.DataLoader` for batching and shuffling datasets.",
          "Always zero gradients with `optimizer.zero_grad()` before backpropagation.",
          "Move tensors to GPU using `.to(device)` for faster training.",
          "Use PyTorch Lightning or similar frameworks for cleaner training loops in production."
        ],
        "error_handling": [
          {
            "error": "RuntimeError: CUDA out of memory",
            "solution": "Reduce batch size or move computations to CPU if GPU memory is insufficient."
          },
          {
            "error": "RuntimeError: shape mismatch",
            "solution": "Ensure the input and target tensors have compatible shapes for the model and loss function."
          },
          {
            "error": "ModuleNotFoundError: No module named 'torch'",
            "solution": "Install PyTorch using pip or conda in the current Python environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://pytorch.org/docs/stable/index.html",
        "github": "https://github.com/pytorch/pytorch"
      }
    },
    {
      "id": "keras",
      "name": "Keras",
      "category": "ML/AI",
      "description": "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, Microsoft Cognitive Toolkit (CNTK), or Theano. It allows for easy and fast prototyping of deep learning models with minimal code.",
      "story": "Keras was developed by François Chollet and released in March 2015. Its design philosophy focuses on user-friendliness, modularity, and extensibility. Keras became popular for its simple API that abstracts the complexities of deep learning, and it was later integrated tightly with TensorFlow as its official high-level API.",
      "installation": {
        "pip": "pip install keras",
        "conda": "conda install -c conda-forge keras"
      },
      "usage": {
        "overview": "Keras allows you to define deep learning models using Sequential or Functional APIs. You can build layers, compile models, train with fit(), evaluate, and make predictions easily. It supports a wide variety of layers, optimizers, loss functions, and metrics.",
        "basic_examples": [
          {
            "title": "Simple Sequential Model",
            "code": "from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    layers.Dense(32, activation='relu', input_shape=(784,)),\n    layers.Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])",
            "explanation": "Defines a basic feedforward neural network with one hidden layer and a softmax output layer for classification."
          },
          {
            "title": "Training a model",
            "code": "import numpy as np\nX_train = np.random.rand(100,784)\ny_train = np.random.randint(0,10,100)\nmodel.fit(X_train, y_train, epochs=5, batch_size=10)",
            "explanation": "Trains the Keras model on synthetic data for 5 epochs using a batch size of 10."
          }
        ],
        "advanced_examples": [
          {
            "title": "Functional API Example",
            "code": "from tensorflow.keras import Input, Model\ninputs = Input(shape=(784,))\nx = layers.Dense(64, activation='relu')(inputs)\noutputs = layers.Dense(10, activation='softmax')(x)\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])",
            "explanation": "Defines a model using the Functional API, allowing for more flexible architectures than Sequential."
          },
          {
            "title": "Using Callbacks",
            "code": "from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='loss', patience=3)\nmodel.fit(X_train, y_train, epochs=50, callbacks=[early_stop])",
            "explanation": "Demonstrates stopping training early when the loss stops improving to prevent overfitting."
          },
          {
            "title": "Saving and loading models",
            "code": "model.save('my_keras_model.h5')\nnew_model = keras.models.load_model('my_keras_model.h5')",
            "explanation": "Shows how to save a trained Keras model to disk and load it later."
          }
        ],
        "best_practices": [
          "Normalize input data for faster convergence.",
          "Use validation sets and callbacks to prevent overfitting.",
          "Leverage the Functional API for complex models like multi-input/multi-output networks.",
          "Use pretrained models from Keras Applications for transfer learning.",
          "Monitor training with TensorBoard for visual insights."
        ],
        "error_handling": [
          {
            "error": "ValueError: Input arrays should have the same number of samples",
            "solution": "Ensure that your features and labels arrays have the same number of samples."
          },
          {
            "error": "InvalidArgumentError",
            "solution": "Check that the input shape matches the model's expected input."
          },
          {
            "error": "ModuleNotFoundError: No module named 'keras'",
            "solution": "Install Keras using pip or conda in your current Python environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://keras.io/",
        "github": "https://github.com/keras-team/keras"
      }
    },
    {
      "id": "opencv-python",
      "name": "OpenCV-Python",
      "category": "ML/AI",
      "description": "OpenCV-Python is a Python wrapper for the OpenCV C++ library, providing tools for computer vision, image processing, and video analysis. It allows rapid prototyping and deployment of vision applications in Python.",
      "story": "OpenCV (Open Source Computer Vision Library) was initially developed by Intel in 1999. OpenCV-Python provides bindings to access the full power of OpenCV in Python, making it popular for real-time image and video processing, machine learning, and robotics applications.",
      "installation": {
        "pip": "pip install opencv-python",
        "conda": "conda install -c conda-forge opencv"
      },
      "usage": {
        "overview": "OpenCV-Python provides functions for image I/O, color space conversions, filtering, transformations, object detection, and machine learning integration. It supports reading and writing images and videos, as well as performing operations on arrays representing images.",
        "basic_examples": [
          {
            "title": "Read and display an image",
            "code": "import cv2\nimg = cv2.imread('image.jpg')\ncv2.imshow('Image', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
            "explanation": "Reads an image from file and displays it in a window until any key is pressed."
          },
          {
            "title": "Convert image to grayscale",
            "code": "import cv2\nimg = cv2.imread('image.jpg')\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\ncv2.imshow('Gray', gray)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
            "explanation": "Converts a color image to grayscale using OpenCV’s color conversion function."
          }
        ],
        "advanced_examples": [
          {
            "title": "Edge detection using Canny",
            "code": "import cv2\nimg = cv2.imread('image.jpg', 0)\nedges = cv2.Canny(img, 100, 200)\ncv2.imshow('Edges', edges)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
            "explanation": "Detects edges in a grayscale image using the Canny algorithm."
          },
          {
            "title": "Video capture from webcam",
            "code": "import cv2\ncap = cv2.VideoCapture(0)\nwhile True:\n    ret, frame = cap.read()\n    cv2.imshow('Webcam', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\ncap.release()\ncv2.destroyAllWindows()",
            "explanation": "Captures video from the default webcam and displays it in real-time."
          },
          {
            "title": "Drawing shapes",
            "code": "import cv2\nimport numpy as np\nimg = np.zeros((512,512,3), np.uint8)\ncv2.line(img, (0,0), (511,511), (255,0,0), 5)\ncv2.rectangle(img, (100,100), (300,300), (0,255,0), 3)\ncv2.circle(img, (256,256), 50, (0,0,255), -1)\ncv2.imshow('Shapes', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
            "explanation": "Draws lines, rectangles, and circles on an empty image using OpenCV drawing functions."
          },
          {
            "title": "Face detection using Haar cascades",
            "code": "import cv2\nface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\nimg = cv2.imread('group.jpg')\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\nfor (x,y,w,h) in faces:\n    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\ncv2.imshow('Faces', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
            "explanation": "Detects faces in an image using pre-trained Haar cascade classifiers."
          }
        ],
        "best_practices": [
          "Use NumPy arrays for image processing to leverage vectorized operations.",
          "Release video capture objects and destroy windows to avoid resource leaks.",
          "Use proper color conversion codes when changing image color spaces.",
          "Profile and optimize processing pipelines for real-time applications.",
          "Keep pre-trained classifiers and models organized for reuse."
        ],
        "error_handling": [
          {
            "error": "cv2.error: OpenCV(…): error: (-215:Assertion failed)",
            "solution": "Check that image paths are correct and files exist before reading."
          },
          {
            "error": "AttributeError: module 'cv2' has no attribute '…'",
            "solution": "Ensure that the correct OpenCV version is installed; some functions may require opencv-contrib-python."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.opencv.org/4.x/",
        "github": "https://github.com/opencv/opencv"
      }
    },
    {
      "id": "beautifulsoup4",
      "name": "Beautiful Soup",
      "category": "Web",
      "description": "Beautiful Soup is a Python library for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, XML, and other markup languages, making web scraping easier and more reliable.",
      "story": "Beautiful Soup was created by Leonard Richardson in 2004. It was designed to handle poorly-formed HTML and XML documents gracefully, making it ideal for web scraping tasks where the markup is inconsistent. It has become a widely used tool in data extraction, web scraping, and automated web interactions.",
      "installation": {
        "pip": "pip install beautifulsoup4",
        "conda": "conda install -c anaconda beautifulsoup4"
      },
      "usage": {
        "overview": "Beautiful Soup provides Pythonic methods and attributes to navigate, search, and modify a parse tree. You can easily extract tags, attributes, text, or nested elements from HTML/XML documents.",
        "basic_examples": [
          {
            "title": "Parsing HTML",
            "code": "from bs4 import BeautifulSoup\nhtml = '<html><head><title>Test</title></head><body><h1>Hello</h1></body></html>'\nsoup = BeautifulSoup(html, 'html.parser')\nprint(soup.title.text)",
            "explanation": "Parses an HTML string and extracts the text content of the `<title>` tag."
          },
          {
            "title": "Finding all links",
            "code": "from bs4 import BeautifulSoup\nhtml = '<a href=\"https://example.com\">Example</a>'\nsoup = BeautifulSoup(html, 'html.parser')\nlinks = [a['href'] for a in soup.find_all('a')]\nprint(links)",
            "explanation": "Extracts all URLs from `<a>` tags in the HTML."
          }
        ],
        "advanced_examples": [
          {
            "title": "Navigating the parse tree",
            "code": "from bs4 import BeautifulSoup\nhtml = '<div><p>Paragraph 1</p><p>Paragraph 2</p></div>'\nsoup = BeautifulSoup(html, 'html.parser')\ndiv = soup.div\nfor p in div.find_all('p'):\n    print(p.text)",
            "explanation": "Demonstrates navigating the parse tree to extract text from nested `<p>` tags."
          },
          {
            "title": "Selecting elements using CSS selectors",
            "code": "from bs4 import BeautifulSoup\nhtml = '<ul><li>One</li><li>Two</li></ul>'\nsoup = BeautifulSoup(html, 'html.parser')\nitems = soup.select('ul li')\nfor item in items:\n    print(item.text)",
            "explanation": "Uses CSS selectors to find all `<li>` elements inside `<ul>`."
          },
          {
            "title": "Modifying the tree",
            "code": "from bs4 import BeautifulSoup\nhtml = '<p>Old Text</p>'\nsoup = BeautifulSoup(html, 'html.parser')\nsoup.p.string = 'New Text'\nprint(soup.p)",
            "explanation": "Shows how to modify the text content of an element."
          }
        ],
        "best_practices": [
          "Always specify a parser: 'html.parser', 'lxml', or 'html5lib'.",
          "Use `.find()` or `.find_all()` for reliable element searches.",
          "Use `.select()` for CSS selector queries when appropriate.",
          "Handle exceptions when elements might not exist to avoid errors.",
          "Combine with `requests` for fetching web pages efficiently."
        ],
        "error_handling": [
          {
            "error": "AttributeError: 'NoneType' object has no attribute 'text'",
            "solution": "Check if the element exists before accessing its attributes or text."
          },
          {
            "error": "FeatureNotFound: Couldn't find a tree builder with the features you requested",
            "solution": "Install the appropriate parser library like `lxml` or `html5lib`."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/",
        "github": "https://github.com/wention/BeautifulSoup4"
      }
    },
    {
      "id": "scrapy",
      "name": "Scrapy",
      "category": "Web",
      "description": "Scrapy is a fast, open-source web crawling and web scraping framework for Python. It provides tools to extract data from websites, process it, and store it in formats like JSON, CSV, or databases.",
      "story": "Scrapy was created by Pablo Hoffman and released in 2008. It was designed to provide a framework for web scraping that is fast, extensible, and reliable. Scrapy has become popular in both industry and research for automated data extraction, web crawling, and building data pipelines.",
      "installation": {
        "pip": "pip install scrapy",
        "conda": "conda install -c conda-forge scrapy"
      },
      "usage": {
        "overview": "Scrapy allows you to define spiders that navigate through websites, extract information using selectors or XPath/CSS expressions, and export the collected data. It includes support for requests, middleware, pipelines, and asynchronous networking for high performance.",
        "basic_examples": [
          {
            "title": "Creating a Scrapy project",
            "code": "# In terminal:\nscrapy startproject myproject",
            "explanation": "Initializes a new Scrapy project called 'myproject', creating the necessary directory structure and configuration files."
          },
          {
            "title": "Defining a simple spider",
            "code": "import scrapy\n\nclass QuotesSpider(scrapy.Spider):\n    name = 'quotes'\n    start_urls = ['http://quotes.toscrape.com']\n\n    def parse(self, response):\n        for quote in response.css('div.quote'):\n            yield {\n                'text': quote.css('span.text::text').get(),\n                'author': quote.css('small.author::text').get(),\n            }",
            "explanation": "Defines a basic spider that scrapes quotes and authors from a sample website."
          }
        ],
        "advanced_examples": [
          {
            "title": "Running a spider and exporting data",
            "code": "# Terminal command:\nscrapy crawl quotes -o quotes.json",
            "explanation": "Runs the 'quotes' spider and exports the scraped data into a JSON file."
          },
          {
            "title": "Using pipelines",
            "code": "class QuotesPipeline:\n    def process_item(self, item, spider):\n        item['text'] = item['text'].strip()\n        return item",
            "explanation": "Defines a pipeline to process items, e.g., cleaning text before saving it."
          },
          {
            "title": "Handling pagination",
            "code": "def parse(self, response):\n    for quote in response.css('div.quote'):\n        yield {...}\n    next_page = response.css('li.next a::attr(href)').get()\n    if next_page:\n        yield response.follow(next_page, self.parse)",
            "explanation": "Demonstrates navigating through paginated pages by following the 'next' link."
          },
          {
            "title": "Using XPath selectors",
            "code": "response.xpath('//div[@class=\"quote\"]/span[@class=\"text\"]/text()').getall()",
            "explanation": "Extracts quote texts using XPath selectors instead of CSS selectors."
          }
        ],
        "best_practices": [
          "Use pipelines for cleaning, validating, and storing scraped data.",
          "Leverage middlewares for handling retries, user agents, and proxies.",
          "Use asynchronous requests to speed up crawling large sites.",
          "Respect `robots.txt` and website terms of service.",
          "Organize multiple spiders logically within a Scrapy project."
        ],
        "error_handling": [
          {
            "error": "TwistedError: DNS lookup failed",
            "solution": "Check your network connection or domain name validity."
          },
          {
            "error": "HttpError",
            "solution": "Use proper exception handling with Scrapy middleware or retry requests."
          },
          {
            "error": "ValueError: no JSON object could be decoded",
            "solution": "Ensure the response body is correctly formatted before parsing."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.scrapy.org/en/latest/",
        "github": "https://github.com/scrapy/scrapy"
      }
    },
    {
      "id": "sqlalchemy",
      "name": "SQLAlchemy",
      "category": "Data",
      "description": "SQLAlchemy is a Python SQL toolkit and Object-Relational Mapping (ORM) library that gives developers full power and flexibility of SQL along with a high-level, Pythonic interface to relational databases.",
      "story": "SQLAlchemy was created by Mike Bayer in 2005 to provide a powerful and flexible way to interact with relational databases in Python. It allows developers to use both raw SQL and ORM abstractions, making it suitable for both small projects and large-scale enterprise applications.",
      "installation": {
        "pip": "pip install sqlalchemy",
        "conda": "conda install -c anaconda sqlalchemy"
      },
      "usage": {
        "overview": "SQLAlchemy allows you to define database schemas as Python classes (ORM), execute raw SQL queries, and manage connections. It supports multiple relational databases such as SQLite, PostgreSQL, MySQL, and Oracle.",
        "basic_examples": [
          {
            "title": "Creating an Engine and connecting to a database",
            "code": "from sqlalchemy import create_engine\nengine = create_engine('sqlite:///example.db')",
            "explanation": "Creates an engine that connects to a SQLite database file named `example.db`."
          },
          {
            "title": "Defining a table using ORM",
            "code": "from sqlalchemy import Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\n\nBase = declarative_base()\n\nclass User(Base):\n    __tablename__ = 'users'\n    id = Column(Integer, primary_key=True)\n    name = Column(String)\n    age = Column(Integer)",
            "explanation": "Defines a `User` table with columns `id`, `name`, and `age` using the ORM approach."
          },
          {
            "title": "Creating tables in the database",
            "code": "Base.metadata.create_all(engine)",
            "explanation": "Creates all tables defined by ORM classes in the connected database."
          }
        ],
        "advanced_examples": [
          {
            "title": "Inserting data",
            "code": "from sqlalchemy.orm import sessionmaker\nSession = sessionmaker(bind=engine)\nsession = Session()\nnew_user = User(name='Alice', age=25)\nsession.add(new_user)\nsession.commit()",
            "explanation": "Creates a session, adds a new user to the table, and commits the transaction."
          },
          {
            "title": "Querying data",
            "code": "users = session.query(User).filter_by(name='Alice').all()\nfor user in users:\n    print(user.name, user.age)",
            "explanation": "Queries the `User` table for rows where name is 'Alice' and prints the results."
          },
          {
            "title": "Updating data",
            "code": "user = session.query(User).filter_by(name='Alice').first()\nuser.age = 26\nsession.commit()",
            "explanation": "Updates the age of the first user named 'Alice' and commits the change."
          },
          {
            "title": "Deleting data",
            "code": "user = session.query(User).filter_by(name='Alice').first()\nsession.delete(user)\nsession.commit()",
            "explanation": "Deletes the user named 'Alice' from the database."
          }
        ],
        "best_practices": [
          "Use `sessionmaker` to create sessions instead of raw connections.",
          "Close sessions after use to prevent resource leaks.",
          "Use ORM for complex applications and raw SQL for optimized queries when needed.",
          "Define relationships using `relationship` and `ForeignKey` for normalized schemas.",
          "Use transactions to ensure data integrity."
        ],
        "error_handling": [
          {
            "error": "IntegrityError",
            "solution": "Occurs when database constraints are violated. Ensure unique or foreign key constraints are respected."
          },
          {
            "error": "OperationalError",
            "solution": "Check database connectivity, credentials, and correct SQL syntax."
          },
          {
            "error": "ProgrammingError",
            "solution": "Typically arises from invalid queries or table definitions. Verify table and column names."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.sqlalchemy.org/",
        "github": "https://github.com/sqlalchemy/sqlalchemy"
      }
    },
    {
      "id": "pydantic",
      "name": "Pydantic",
      "category": "CLI/Utils",
      "description": "Pydantic is a Python library for data validation and settings management using Python type annotations. It enforces type hints at runtime and provides user-friendly errors when data is invalid.",
      "story": "Pydantic was created by Samuel Colvin in 2018 to simplify the validation of complex data structures. It has become widely used in FastAPI and other modern Python projects where robust input validation and structured data are critical.",
      "installation": {
        "pip": "pip install pydantic",
        "conda": "conda install -c conda-forge pydantic"
      },
      "usage": {
        "overview": "Pydantic uses Python type hints to define data models. It validates input data automatically and can serialize/deserialize data to JSON or Python objects. Pydantic models are immutable by default and support nested models, default values, and custom validation.",
        "basic_examples": [
          {
            "title": "Defining a simple model",
            "code": "from pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name: str\n\nuser = User(id=1, name='Alice')\nprint(user)",
            "explanation": "Defines a basic User model with two fields. Pydantic validates types automatically."
          },
          {
            "title": "Validation and type coercion",
            "code": "from pydantic import BaseModel\n\nclass Item(BaseModel):\n    price: float\n\nitem = Item(price='19.99')\nprint(item.price)",
            "explanation": "Pydantic automatically converts compatible types (str → float) during validation."
          }
        ],
        "advanced_examples": [
          {
            "title": "Nested models",
            "code": "from pydantic import BaseModel\n\nclass Address(BaseModel):\n    city: str\n    zip: str\n\nclass User(BaseModel):\n    name: str\n    address: Address\n\nuser = User(name='Bob', address={'city': 'NYC', 'zip': '10001'})\nprint(user)",
            "explanation": "Demonstrates nested data models and automatic validation of nested dictionaries."
          },
          {
            "title": "Custom validation",
            "code": "from pydantic import BaseModel, validator\n\nclass Product(BaseModel):\n    name: str\n    price: float\n\n    @validator('price')\n    def price_must_be_positive(cls, v):\n        if v <= 0:\n            raise ValueError('Price must be positive')\n        return v\n\nproduct = Product(name='Book', price=10.0)",
            "explanation": "Shows how to create custom validators to enforce business rules on fields."
          },
          {
            "title": "Exporting to JSON",
            "code": "user.json()",
            "explanation": "Serialize the Pydantic model instance to a JSON string."
          },
          {
            "title": "Parsing raw data",
            "code": "User.parse_obj({'id': 2, 'name': 'Charlie'})",
            "explanation": "Parse a Python dictionary into a validated Pydantic model."
          }
        ],
        "best_practices": [
          "Use Pydantic models for API request/response validation.",
          "Leverage type hints to enforce consistent data structures.",
          "Use nested models to represent complex JSON or hierarchical data.",
          "Add custom validators for business-specific constraints.",
          "Use `.dict()` and `.json()` for serialization and data exchange."
        ],
        "error_handling": [
          {
            "error": "ValidationError",
            "solution": "Occurs when input data does not conform to the model types or constraints. Review the error messages to correct invalid fields."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.pydantic.dev/",
        "github": "https://github.com/pydantic/pydantic"
      }
    },
    {
      "id": "celery",
      "name": "Celery",
      "category": "CLI/Utils",
      "description": "Celery is an asynchronous task queue/job queue based on distributed message passing. It is focused on real-time operation but supports scheduling as well.",
      "story": "Celery was created by Ask Solem and released in 2009. It was designed to provide a simple and reliable framework to run background tasks in Python applications, supporting distributed processing across multiple workers, queues, and brokers.",
      "installation": {
        "pip": "pip install celery",
        "conda": "conda install -c conda-forge celery"
      },
      "usage": {
        "overview": "Celery allows you to define tasks in Python functions, which can be executed asynchronously or scheduled periodically. It supports multiple brokers like RabbitMQ, Redis, and Amazon SQS, and provides tools for monitoring and managing task execution.",
        "basic_examples": [
          {
            "title": "Defining a simple task",
            "code": "from celery import Celery\n\napp = Celery('tasks', broker='redis://localhost:6379/0')\n\n@app.task\ndef add(x, y):\n    return x + y",
            "explanation": "Defines a Celery app with Redis as the broker and a simple `add` task that can be executed asynchronously."
          },
          {
            "title": "Calling a task asynchronously",
            "code": "result = add.delay(4, 6)\nprint(result.get(timeout=10))",
            "explanation": "Calls the `add` task asynchronously using `delay()` and retrieves the result with a timeout."
          }
        ],
        "advanced_examples": [
          {
            "title": "Periodic tasks with Celery Beat",
            "code": "from celery.schedules import crontab\napp.conf.beat_schedule = {\n    'add-every-minute': {\n        'task': 'tasks.add',\n        'schedule': crontab(minute='*'),\n        'args': (2, 3),\n    },\n}",
            "explanation": "Schedules the `add` task to run every minute using Celery Beat."
          },
          {
            "title": "Chaining tasks",
            "code": "from celery import chain\nresult = chain(add.s(2,3), add.s(4))().get()",
            "explanation": "Chains tasks together so that the output of one task is used as the input to the next."
          },
          {
            "title": "Using multiple brokers",
            "code": "app = Celery('tasks', broker=['redis://localhost:6379/0', 'amqp://guest@localhost//'])",
            "explanation": "Configures Celery to use multiple brokers for redundancy or load balancing."
          }
        ],
        "best_practices": [
          "Use Redis or RabbitMQ as a reliable broker for production environments.",
          "Keep tasks idempotent to allow retries safely.",
          "Use separate queues for different priorities or types of tasks.",
          "Monitor task execution using Flower or Celery events.",
          "Avoid long-running tasks in synchronous workflows; delegate them to Celery workers."
        ],
        "error_handling": [
          {
            "error": "TimeoutError",
            "solution": "Set appropriate `timeout` when retrieving results and handle task failures with retries."
          },
          {
            "error": "BrokerConnectionError",
            "solution": "Check that your message broker is running and accessible. Ensure network connectivity."
          },
          {
            "error": "TaskRevokedError",
            "solution": "Occurs when a task is revoked before execution. Handle with try/except and consider retries."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.celeryproject.org/",
        "github": "https://github.com/celery/celery"
      }
    },
    {
      "id": "pillow",
      "name": "Pillow",
      "category": "Data Science",
      "description": "Pillow is a modern fork of the Python Imaging Library (PIL) that adds support for opening, manipulating, and saving many different image file formats in Python.",
      "story": "Pillow was created in 2010 as a friendly fork of PIL to continue development and maintain compatibility with newer versions of Python. It has become the de facto library for image processing in Python, widely used for applications such as image manipulation, format conversion, and automated image processing pipelines.",
      "installation": {
        "pip": "pip install pillow",
        "conda": "conda install -c conda-forge pillow"
      },
      "usage": {
        "overview": "Pillow provides an Image class to handle images, along with functions to resize, crop, rotate, convert formats, apply filters, draw text, and handle transparency. It integrates seamlessly with NumPy arrays for advanced image processing.",
        "basic_examples": [
          {
            "title": "Opening and displaying an image",
            "code": "from PIL import Image\nimg = Image.open('image.jpg')\nimg.show()",
            "explanation": "Opens an image file and displays it using the default image viewer."
          },
          {
            "title": "Resizing an image",
            "code": "from PIL import Image\nimg = Image.open('image.jpg')\nresized = img.resize((256, 256))\nresized.show()",
            "explanation": "Resizes the image to 256x256 pixels while maintaining the aspect ratio."
          },
          {
            "title": "Converting image formats",
            "code": "from PIL import Image\nimg = Image.open('image.png')\nimg.save('image.jpg')",
            "explanation": "Converts a PNG image to JPEG format."
          }
        ],
        "advanced_examples": [
          {
            "title": "Cropping an image",
            "code": "from PIL import Image\nimg = Image.open('image.jpg')\ncropped = img.crop((50, 50, 200, 200))\ncropped.show()",
            "explanation": "Crops a rectangular region from the image defined by the bounding box coordinates (left, upper, right, lower)."
          },
          {
            "title": "Rotating an image",
            "code": "from PIL import Image\nimg = Image.open('image.jpg')\nrotated = img.rotate(45)\nrotated.show()",
            "explanation": "Rotates the image 45 degrees counterclockwise."
          },
          {
            "title": "Applying filters",
            "code": "from PIL import Image, ImageFilter\nimg = Image.open('image.jpg')\nblurred = img.filter(ImageFilter.GaussianBlur(5))\nblurred.show()",
            "explanation": "Applies a Gaussian blur filter to the image."
          },
          {
            "title": "Adding text to an image",
            "code": "from PIL import Image, ImageDraw, ImageFont\nimg = Image.open('image.jpg')\ndraw = ImageDraw.Draw(img)\nfont = ImageFont.load_default()\ndraw.text((10,10), 'Hello, Pillow!', fill='white', font=font)\nimg.show()",
            "explanation": "Draws white text on the image at position (10,10) using the default font."
          }
        ],
        "best_practices": [
          "Use `with Image.open(...) as img:` to ensure proper resource handling.",
          "Convert images to RGB mode before saving in formats that don’t support alpha channels.",
          "Use thumbnail() for memory-efficient resizing.",
          "Combine Pillow with NumPy for advanced image processing.",
          "Handle exceptions for file operations to prevent crashes."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundError",
            "solution": "Ensure the image file path is correct before opening."
          },
          {
            "error": "OSError: cannot identify image file",
            "solution": "Verify that the file is a valid image and Pillow supports its format."
          }
        ]
      },
      "references": {
        "official_docs": "https://pillow.readthedocs.io/",
        "github": "https://github.com/python-pillow/Pillow"
      }
    },
    {
      "id": "pypdf",
      "name": "PyPDF",
      "category": "Data Science",
      "description": "PyPDF is a pure Python library for working with PDF documents. It allows you to read, write, merge, split, and manipulate PDF files programmatically.",
      "story": "PyPDF was originally created to provide an easy-to-use library for PDF manipulation in Python without relying on external tools. It has evolved over time to support modern PDF features and remains widely used for automating PDF-related workflows.",
      "installation": {
        "pip": "pip install pypdf",
        "conda": "conda install -c conda-forge pypdf"
      },
      "usage": {
        "overview": "PyPDF allows you to read text from PDFs, merge multiple PDFs into one, split PDFs into pages, rotate pages, encrypt/decrypt PDFs, and extract metadata. It integrates easily into Python scripts for automating document handling.",
        "basic_examples": [
          {
            "title": "Reading a PDF",
            "code": "from pypdf import PdfReader\nreader = PdfReader('document.pdf')\nfor page in reader.pages:\n    print(page.extract_text())",
            "explanation": "Opens a PDF and extracts text from each page."
          },
          {
            "title": "Merging PDFs",
            "code": "from pypdf import PdfMerger\nmerger = PdfMerger()\nmerger.append('file1.pdf')\nmerger.append('file2.pdf')\nmerger.write('merged.pdf')\nmerger.close()",
            "explanation": "Combines multiple PDFs into a single merged PDF."
          }
        ],
        "advanced_examples": [
          {
            "title": "Splitting a PDF",
            "code": "from pypdf import PdfReader, PdfWriter\nreader = PdfReader('document.pdf')\nwriter = PdfWriter()\nwriter.add_page(reader.pages[0])\nwriter.write('page1.pdf')",
            "explanation": "Extracts the first page of a PDF and saves it as a new PDF."
          },
          {
            "title": "Rotating pages",
            "code": "from pypdf import PdfReader, PdfWriter\nreader = PdfReader('document.pdf')\nwriter = PdfWriter()\npage = reader.pages[0]\npage.rotate(90)\nwriter.add_page(page)\nwriter.write('rotated.pdf')",
            "explanation": "Rotates the first page of a PDF by 90 degrees and saves it."
          },
          {
            "title": "Adding metadata",
            "code": "from pypdf import PdfReader, PdfWriter\nreader = PdfReader('document.pdf')\nwriter = PdfWriter()\nwriter.append_pages_from_reader(reader)\nwriter.add_metadata({'/Author': 'John Doe', '/Title': 'Sample PDF'})\nwriter.write('document_with_metadata.pdf')",
            "explanation": "Copies pages from an existing PDF and adds author and title metadata."
          },
          {
            "title": "Encrypting a PDF",
            "code": "from pypdf import PdfReader, PdfWriter\nreader = PdfReader('document.pdf')\nwriter = PdfWriter()\nwriter.append_pages_from_reader(reader)\nwriter.encrypt('password')\nwriter.write('encrypted.pdf')",
            "explanation": "Encrypts a PDF file with a password."
          }
        ],
        "best_practices": [
          "Always close files or use context managers to avoid resource leaks.",
          "Validate PDF input files before processing.",
          "Use `PdfWriter` to create or modify PDFs instead of modifying `PdfReader` objects directly.",
          "Keep backups when manipulating important PDFs.",
          "Use metadata to improve document organization and searchability."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundError",
            "solution": "Ensure the PDF file path is correct."
          },
          {
            "error": "PdfReadError",
            "solution": "The PDF may be corrupted or encrypted. Check the file integrity."
          },
          {
            "error": "PermissionError",
            "solution": "Ensure you have write permissions when creating or modifying PDFs."
          }
        ]
      },
      "references": {
        "official_docs": "https://pypdf.readthedocs.io/",
        "github": "https://github.com/py-pdf/pypdf"
      }
    },
    {
      "id": "tox",
      "name": "tox",
      "category": "CLI/Utils",
      "description": "tox is a Python tool for automated testing in multiple environments. It allows developers to run tests across different Python versions and dependency configurations, ensuring compatibility and reliability.",
      "story": "tox was created to standardize testing in Python projects and simplify the management of virtual environments for testing purposes. It is widely used in open-source projects to ensure that code runs correctly on multiple Python versions and environments.",
      "installation": {
        "pip": "pip install tox",
        "conda": "conda install -c conda-forge tox"
      },
      "usage": {
        "overview": "tox automates creating virtual environments, installing dependencies, running tests, and reporting results. It reads configuration from a `tox.ini` file where you define environments, dependencies, and test commands.",
        "basic_examples": [
          {
            "title": "Creating a basic tox.ini",
            "code": "[tox]\nenvlist = py38, py39\n\n[testenv]\ndeps = pytest\ncommands = pytest",
            "explanation": "Defines two environments (Python 3.8 and 3.9) that install pytest and run the test suite."
          },
          {
            "title": "Running tox",
            "code": "# In terminal:\ntox",
            "explanation": "Creates virtual environments for each Python version defined in `envlist` and runs the specified test commands."
          }
        ],
        "advanced_examples": [
          {
            "title": "Specifying different dependencies per environment",
            "code": "[testenv:py38]\ndeps = pytest==6.2.5\n\n[testenv:py39]\ndeps = pytest==7.0.0",
            "explanation": "Demonstrates how to install specific versions of dependencies for different Python versions."
          },
          {
            "title": "Passing environment variables",
            "code": "[testenv]\nsetenv = DJANGO_SETTINGS_MODULE=myproject.settings\ncommands = pytest",
            "explanation": "Sets environment variables within the virtual environment before running tests."
          },
          {
            "title": "Running multiple commands",
            "code": "[testenv]\ndeps = flake8\ncommands = flake8 src tests\n           pytest",
            "explanation": "Runs linting with flake8 followed by pytest in the same environment."
          }
        ],
        "best_practices": [
          "Use tox to test your code against all supported Python versions.",
          "Keep your `tox.ini` file simple and modular to avoid complexity.",
          "Combine linting, testing, and coverage in tox environments.",
          "Use `skip_missing_interpreters = true` to avoid failures if a Python version isn’t installed.",
          "Integrate tox with CI/CD pipelines for automated testing."
        ],
        "error_handling": [
          {
            "error": "InterpreterNotFound",
            "solution": "Ensure the specified Python versions are installed and accessible in your PATH."
          },
          {
            "error": "Dependency installation failed",
            "solution": "Verify that dependencies are correctly specified and available on PyPI or other indexes."
          },
          {
            "error": "Command failed",
            "solution": "Check the command syntax and ensure all necessary dependencies are installed in the environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://tox.readthedocs.io/",
        "github": "https://github.com/tox-dev/tox"
      }
    },
    {
      "id": "click",
      "name": "Click",
      "category": "CLI/Utils",
      "description": "Click is a Python package for creating command-line interfaces (CLI) with composable commands, automatic help page generation, and support for environment variables and configuration files.",
      "story": "Click was created by Armin Ronacher to simplify the creation of complex command-line interfaces while maintaining code readability and flexibility. It is widely used in Python projects for building robust CLI tools and applications.",
      "installation": {
        "pip": "pip install click",
        "conda": "conda install -c conda-forge click"
      },
      "usage": {
        "overview": "Click allows you to define commands and options as Python functions with decorators. It handles parsing, validation, and help text generation automatically, making CLI development faster and more consistent.",
        "basic_examples": [
          {
            "title": "Simple CLI command",
            "code": "import click\n\n@click.command()\ndef hello():\n    click.echo('Hello, World!')\n\nif __name__ == '__main__':\n    hello()",
            "explanation": "Defines a simple command-line program that prints 'Hello, World!' when run."
          },
          {
            "title": "Command with an option",
            "code": "import click\n\n@click.command()\n@click.option('--name', prompt='Your name', help='The person to greet.')\ndef greet(name):\n    click.echo(f'Hello, {name}!')\n\nif __name__ == '__main__':\n    greet()",
            "explanation": "Adds an option `--name` to the CLI, prompting the user for input if not provided, and then prints a greeting."
          }
        ],
        "advanced_examples": [
          {
            "title": "Multiple commands using a group",
            "code": "import click\n\n@click.group()\ndef cli():\n    pass\n\n@click.command()\ndef init():\n    click.echo('Initialized')\n\n@click.command()\ndef drop():\n    click.echo('Dropped')\n\ncli.add_command(init)\ncli.add_command(drop)\n\nif __name__ == '__main__':\n    cli()",
            "explanation": "Defines a CLI group with multiple commands, allowing structured CLI tools with subcommands."
          },
          {
            "title": "Using arguments",
            "code": "import click\n\n@click.command()\n@click.argument('filename')\ndef read_file(filename):\n    with open(filename) as f:\n        click.echo(f.read())\n\nif __name__ == '__main__':\n    read_file()",
            "explanation": "Uses a positional argument `filename` to read and print the content of a file."
          },
          {
            "title": "Chaining commands",
            "code": "import click\n\n@click.group()\n@click.pass_context\ndef cli(ctx):\n    ctx.ensure_object(dict)\n\n@cli.command()\n@click.pass_context\ndef step1(ctx):\n    click.echo('Step 1')\n    ctx.obj['step'] = 1\n\n@cli.command()\n@click.pass_context\ndef step2(ctx):\n    click.echo(f'Step 2, previous step = {ctx.obj.get(\"step\")}')\n\nif __name__ == '__main__':\n    cli(obj={})",
            "explanation": "Demonstrates sharing context between chained commands in a CLI group."
          }
        ],
        "best_practices": [
          "Use decorators `@click.command`, `@click.option`, and `@click.argument` to define commands clearly.",
          "Organize multiple commands using `@click.group()` for better structure.",
          "Use `click.echo()` instead of `print()` for consistent output handling.",
          "Leverage `click.Context` for passing objects or state between commands.",
          "Use the built-in help system and `prompt` feature to improve CLI usability."
        ],
        "error_handling": [
          {
            "error": "MissingParameter",
            "solution": "Ensure all required options or arguments are provided. Use `--help` to check usage."
          },
          {
            "error": "BadParameter",
            "solution": "Validate that parameter values match expected types or constraints."
          },
          {
            "error": "FileNotFoundError",
            "solution": "Ensure file paths provided as arguments exist and are accessible."
          }
        ]
      },
      "references": {
        "official_docs": "https://click.palletsprojects.com/",
        "github": "https://github.com/pallets/click"
      }
    },
    {
      "id": "typer",
      "name": "Typer",
      "category": "CLI/Utils",
      "description": "Typer is a modern Python library for building command-line interface (CLI) applications. It leverages Python type hints to automatically generate help messages, validate inputs, and provide a smooth developer experience.",
      "story": "Typer was created by Sebastián Ramírez, the author of FastAPI, to make building CLI apps as easy as building web APIs with FastAPI. It emphasizes simplicity, automatic documentation, and type safety while being fully compatible with Python’s type hints.",
      "installation": {
        "pip": "pip install typer[all]",
        "conda": "conda install -c conda-forge typer"
      },
      "usage": {
        "overview": "Typer allows you to define commands and options as Python functions with decorators. It automatically generates help pages, validates input types, and integrates easily with modern Python codebases.",
        "basic_examples": [
          {
            "title": "Simple CLI command",
            "code": "import typer\n\ndef main():\n    typer.echo('Hello, Typer!')\n\nif __name__ == '__main__':\n    typer.run(main)",
            "explanation": "Defines a simple command-line program that prints 'Hello, Typer!' when executed."
          },
          {
            "title": "Command with options",
            "code": "import typer\n\ndef greet(name: str = 'World'):\n    typer.echo(f'Hello, {name}!')\n\nif __name__ == '__main__':\n    typer.run(greet)",
            "explanation": "Adds an optional parameter `name` to the CLI command, defaulting to 'World'. Typer automatically validates input and generates help text."
          }
        ],
        "advanced_examples": [
          {
            "title": "Multiple commands using Typer app",
            "code": "import typer\napp = typer.Typer()\n\n@app.command()\ndef hello():\n    typer.echo('Hello!')\n\n@app.command()\ndef goodbye():\n    typer.echo('Goodbye!')\n\nif __name__ == '__main__':\n    app()",
            "explanation": "Defines a Typer application with multiple commands using the `@app.command()` decorator."
          },
          {
            "title": "Type validation and conversion",
            "code": "import typer\n\ndef square(number: int):\n    typer.echo(number ** 2)\n\nif __name__ == '__main__':\n    typer.run(square)",
            "explanation": "Automatically validates that `number` is an integer and computes its square. Typer will raise an error if input cannot be converted."
          },
          {
            "title": "Using Enum for choices",
            "code": "from enum import Enum\nimport typer\n\nclass Color(str, Enum):\n    red = 'red'\n    green = 'green'\n    blue = 'blue'\n\ndef favorite(color: Color):\n    typer.echo(f'Your favorite color is {color}')\n\nif __name__ == '__main__':\n    typer.run(favorite)",
            "explanation": "Restricts input to predefined choices using Python Enums and provides automatic help messages."
          }
        ],
        "best_practices": [
          "Use Python type hints to enable automatic validation and documentation.",
          "Organize multiple commands with a Typer app instance instead of standalone functions.",
          "Leverage default values and Enums to guide user input.",
          "Use `typer.echo()` instead of `print()` for consistent CLI output.",
          "Combine Typer with rich or colorama for styled terminal outputs."
        ],
        "error_handling": [
          {
            "error": "ValueError",
            "solution": "Ensure input types match function annotations. Typer automatically handles conversion and raises errors if inputs are invalid."
          },
          {
            "error": "typer.Exit",
            "solution": "Use `raise typer.Exit(code=...)` to exit gracefully with a specific exit code."
          }
        ]
      },
      "references": {
        "official_docs": "https://typer.tiangolo.com/",
        "github": "https://github.com/tiangolo/typer"
      }
    },
    {
      "id": "rich",
      "name": "Rich",
      "category": "CLI/Utils",
      "description": "Rich is a Python library for rich text and beautiful formatting in the terminal. It allows you to create colorful and styled console output, including tables, progress bars, markdown, syntax highlighting, and more.",
      "story": "Rich was created by Will McGugan in 2019 to bring modern, visually appealing formatting to Python command-line applications. Its goal is to make terminal output more informative, interactive, and beautiful without sacrificing performance or simplicity.",
      "installation": {
        "pip": "pip install rich",
        "conda": "conda install -c conda-forge rich"
      },
      "usage": {
        "overview": "Rich allows developers to print styled text, tables, progress bars, and render markdown in the terminal. It supports colors, gradients, emojis, and live updates for interactive command-line applications.",
        "basic_examples": [
          {
            "title": "Printing styled text",
            "code": "from rich import print\nprint('[bold red]Hello[/bold red] [green]World[/green]!')",
            "explanation": "Prints 'Hello World!' with 'Hello' in bold red and 'World' in green using Rich's markup syntax."
          },
          {
            "title": "Creating a table",
            "code": "from rich.console import Console\nfrom rich.table import Table\n\nconsole = Console()\ntable = Table(title='Fruits')\ntable.add_column('Name', style='cyan')\ntable.add_column('Quantity', justify='right')\ntable.add_row('Apple', '10')\ntable.add_row('Banana', '5')\nconsole.print(table)",
            "explanation": "Creates and prints a styled table with two columns and multiple rows."
          }
        ],
        "advanced_examples": [
          {
            "title": "Progress bar",
            "code": "from rich.progress import track\nimport time\nfor i in track(range(100), description='Processing...'):\n    time.sleep(0.05)",
            "explanation": "Displays a progress bar that updates in real-time as a loop iterates."
          },
          {
            "title": "Syntax highlighting",
            "code": "from rich.console import Console\nfrom rich.syntax import Syntax\n\ncode = 'print(\"Hello, World!\")'\nsyntax = Syntax(code, 'python', theme='monokai', line_numbers=True)\nconsole = Console()\nconsole.print(syntax)",
            "explanation": "Displays Python code with syntax highlighting, using the Monokai theme and line numbers."
          },
          {
            "title": "Live updating panel",
            "code": "from rich.live import Live\nfrom rich.panel import Panel\nimport time\n\nwith Live(Panel('Starting...'), refresh_per_second=4) as live:\n    for i in range(5):\n        live.update(Panel(f'Progress {i+1}/5'))\n        time.sleep(1)",
            "explanation": "Demonstrates updating terminal content dynamically using Rich's live panels."
          }
        ],
        "best_practices": [
          "Use Rich for logging, progress bars, and tables to make CLI apps more user-friendly.",
          "Use markup syntax for styling text rather than manual ANSI codes.",
          "Combine Rich with Python’s logging module for structured logs.",
          "Use `Live` and `Progress` for interactive real-time updates.",
          "Leverage Rich themes and styles to maintain consistent CLI design."
        ],
        "error_handling": [
          {
            "error": "ModuleNotFoundError: No module named 'rich'",
            "solution": "Install Rich using pip or conda in your current Python environment."
          },
          {
            "error": "Console does not support features",
            "solution": "Ensure your terminal supports ANSI colors and UTF-8 encoding for full Rich functionality."
          }
        ]
      },
      "references": {
        "official_docs": "https://rich.readthedocs.io/",
        "github": "https://github.com/Textualize/rich"
      }
    },
    {
      "id": "poetry",
      "name": "Poetry",
      "category": "CLI/Utils",
      "description": "Poetry is a Python dependency management and packaging tool that simplifies the process of managing project dependencies, building packages, and publishing them. It ensures deterministic installs and isolated environments.",
      "story": "Poetry was created by Sébastien Eustace in 2018 to provide a modern alternative to pip and setuptools for Python projects. It emphasizes simplicity, reproducibility, and a standardized approach to dependency management, making Python project setups more predictable and reliable.",
      "installation": {
        "pip": "pip install poetry",
        "official": "https://python-poetry.org/docs/#installation"
      },
      "usage": {
        "overview": "Poetry provides commands to create new projects, add or remove dependencies, build and publish packages, and manage virtual environments automatically. It uses a `pyproject.toml` file to track project metadata and dependencies.",
        "basic_examples": [
          {
            "title": "Creating a new project",
            "code": "poetry new my-project",
            "explanation": "Creates a new Python project named 'my-project' with a standard directory structure and a `pyproject.toml` file."
          },
          {
            "title": "Adding dependencies",
            "code": "poetry add requests",
            "explanation": "Adds the `requests` library to the project and updates the `pyproject.toml` and `poetry.lock` files."
          },
          {
            "title": "Installing dependencies",
            "code": "poetry install",
            "explanation": "Installs all dependencies listed in `pyproject.toml` into a virtual environment managed by Poetry."
          }
        ],
        "advanced_examples": [
          {
            "title": "Removing a dependency",
            "code": "poetry remove requests",
            "explanation": "Removes the `requests` dependency from the project and updates the lock file."
          },
          {
            "title": "Running commands inside the virtual environment",
            "code": "poetry run python script.py",
            "explanation": "Executes a Python script using the virtual environment managed by Poetry."
          },
          {
            "title": "Publishing a package",
            "code": "poetry publish --build",
            "explanation": "Builds the project package and publishes it to PyPI."
          },
          {
            "title": "Checking dependency status",
            "code": "poetry show --tree",
            "explanation": "Displays a tree of all project dependencies and their versions."
          }
        ],
        "best_practices": [
          "Use `poetry.lock` to ensure deterministic installs across different environments.",
          "Keep development dependencies separate from production dependencies using `--dev` flag.",
          "Regularly update dependencies using `poetry update` to maintain security and compatibility.",
          "Use `poetry check` to verify the integrity of your `pyproject.toml` file.",
          "Leverage virtual environments managed by Poetry instead of system-wide installations."
        ],
        "error_handling": [
          {
            "error": "PackageNotFoundError",
            "solution": "Verify the package name and check PyPI availability before adding it."
          },
          {
            "error": "CommandNotFoundError",
            "solution": "Ensure Poetry is installed correctly and is available in your system PATH."
          },
          {
            "error": "VersionConflict",
            "solution": "Resolve conflicting dependency versions manually or use `poetry update`."
          }
        ]
      },
      "references": {
        "official_docs": "https://python-poetry.org/docs/",
        "github": "https://github.com/python-poetry/poetry"
      }
    },
    {
      "id": "jupyter",
      "name": "Jupyter",
      "category": "Data Science",
      "description": "Jupyter is an open-source project that provides interactive notebooks for creating and sharing documents that contain live code, equations, visualizations, and narrative text.",
      "story": "Jupyter originated from the IPython project in 2014 to support interactive computing across multiple languages (Julia, Python, R – hence the name Ju-Py-R). It has become a standard tool for data analysis, scientific research, and education, allowing users to combine code execution, rich text, and visualizations in a single environment.",
      "installation": {
        "pip": "pip install notebook",
        "conda": "conda install -c conda-forge notebook"
      },
      "usage": {
        "overview": "Jupyter Notebooks allow you to write and execute code in cells, interleave documentation and results, and visualize data interactively. Notebooks can be exported to various formats including HTML, PDF, and slideshows.",
        "basic_examples": [
          {
            "title": "Starting Jupyter Notebook",
            "code": "# Terminal command:\njupyter notebook",
            "explanation": "Starts the Jupyter Notebook server and opens a web interface in your default browser."
          },
          {
            "title": "Creating a new notebook",
            "code": "From the Jupyter web interface, click 'New' → 'Python 3' to create a new notebook.",
            "explanation": "Creates a notebook where you can write Python code in cells and execute them interactively."
          },
          {
            "title": "Running code cells",
            "code": "a = 10\nb = 20\na + b",
            "explanation": "Write Python code in a cell and press Shift+Enter to execute it; the output is displayed directly below the cell."
          }
        ],
        "advanced_examples": [
          {
            "title": "Markdown cells",
            "code": "Use Markdown to write formatted text, equations using LaTeX, or headings in a notebook cell.",
            "explanation": "You can create rich documentation alongside code to explain analysis, show results, or provide instructions."
          },
          {
            "title": "Interactive visualizations",
            "code": "import matplotlib.pyplot as plt\nimport numpy as np\nx = np.linspace(0,10,100)\ny = np.sin(x)\nplt.plot(x,y)\nplt.show()",
            "explanation": "Plots interactive graphs directly in the notebook using Matplotlib."
          },
          {
            "title": "Exporting notebooks",
            "code": "# Terminal command:\njupyter nbconvert --to html notebook.ipynb",
            "explanation": "Converts a notebook to an HTML file for sharing or publication."
          },
          {
            "title": "Using Jupyter with other kernels",
            "code": "Install additional kernels for R, Julia, or other languages to use them in Jupyter notebooks.",
            "explanation": "Jupyter supports multiple programming languages via kernels, making it versatile for different computational tasks."
          }
        ],
        "best_practices": [
          "Keep notebooks organized with clear headings and markdown explanations.",
          "Use version control for notebooks with tools like nbdime to track changes.",
          "Break complex computations into multiple cells for clarity and testing.",
          "Leverage widgets and interactive libraries (like ipywidgets) for interactive dashboards.",
          "Regularly restart the kernel and rerun all cells to ensure reproducibility."
        ],
        "error_handling": [
          {
            "error": "Kernel dies or disconnects",
            "solution": "Restart the kernel and check for infinite loops or excessive memory usage."
          },
          {
            "error": "ModuleNotFoundError",
            "solution": "Ensure required packages are installed in the environment used by the notebook kernel."
          },
          {
            "error": "Notebook not opening",
            "solution": "Check that the Jupyter server is running and accessible via the browser, and verify firewall/network settings."
          }
        ]
      },
      "references": {
        "official_docs": "https://jupyter.org/documentation",
        "github": "https://github.com/jupyter/notebook"
      }
    },
    {
      "id": "networkx",
      "name": "NetworkX",
      "category": "Data Science",
      "description": "NetworkX is a Python library for the creation, manipulation, and study of complex networks of nodes and edges. It provides tools to analyze the structure and dynamics of graphs and networks.",
      "story": "NetworkX was created by Aric Hagberg, Dan Schult, and Pieter Swart in 2004 to provide a flexible framework for analyzing complex networks in Python. It is widely used in research, social network analysis, biology, computer science, and many other fields that involve graph theory.",
      "installation": {
        "pip": "pip install networkx",
        "conda": "conda install -c conda-forge networkx"
      },
      "usage": {
        "overview": "NetworkX allows you to create different types of graphs (undirected, directed, multigraphs), add nodes and edges, compute network metrics, visualize graphs, and perform network algorithms such as shortest paths, clustering, and centrality measures.",
        "basic_examples": [
          {
            "title": "Creating a simple graph",
            "code": "import networkx as nx\nG = nx.Graph()\nG.add_node(1)\nG.add_nodes_from([2, 3])\nG.add_edge(1, 2)\nG.add_edges_from([(2, 3), (3, 1)])\nprint(G.nodes())\nprint(G.edges())",
            "explanation": "Creates a simple undirected graph with three nodes and edges connecting them. Prints the list of nodes and edges."
          },
          {
            "title": "Visualizing a graph",
            "code": "import matplotlib.pyplot as plt\nnx.draw(G, with_labels=True, node_color='lightblue', edge_color='gray')\nplt.show()",
            "explanation": "Visualizes the graph using Matplotlib with labeled nodes and custom colors."
          }
        ],
        "advanced_examples": [
          {
            "title": "Computing shortest path",
            "code": "path = nx.shortest_path(G, source=1, target=3)\nprint(path)",
            "explanation": "Finds the shortest path between two nodes in the graph."
          },
          {
            "title": "Degree centrality",
            "code": "centrality = nx.degree_centrality(G)\nprint(centrality)",
            "explanation": "Calculates the degree centrality for each node, indicating the relative importance of nodes."
          },
          {
            "title": "Directed graph example",
            "code": "DG = nx.DiGraph()\nDG.add_edge('A', 'B')\nDG.add_edge('B', 'C')\nnx.draw(DG, with_labels=True, node_color='lightgreen')\nplt.show()",
            "explanation": "Creates a directed graph and visualizes it."
          },
          {
            "title": "Weighted graph example",
            "code": "G.add_edge(1, 2, weight=4)\nG.add_edge(2, 3, weight=7)\nlength = nx.dijkstra_path_length(G, source=1, target=3)\nprint(length)",
            "explanation": "Adds weighted edges and calculates the shortest path length using Dijkstra’s algorithm."
          }
        ],
        "best_practices": [
          "Choose the appropriate graph type: Graph, DiGraph, MultiGraph, or MultiDiGraph.",
          "Use built-in NetworkX algorithms for analysis rather than manually iterating over nodes and edges.",
          "Combine with Matplotlib, Plotly, or Graphviz for enhanced visualizations.",
          "Label nodes meaningfully for readability in graphs.",
          "Leverage built-in centrality, clustering, and connectivity metrics for network analysis."
        ],
        "error_handling": [
          {
            "error": "NetworkXError: The node {} is not in the graph",
            "solution": "Ensure the node exists in the graph before performing operations on it."
          },
          {
            "error": "NetworkXNoPath",
            "solution": "Check connectivity between source and target nodes when computing shortest paths."
          }
        ]
      },
      "references": {
        "official_docs": "https://networkx.org/documentation/stable/",
        "github": "https://github.com/networkx/networkx"
      }
    },
    {
      "id": "aiohttp",
      "name": "aiohttp",
      "category": "Web",
      "description": "aiohttp is an asynchronous HTTP client/server framework for Python, built on top of asyncio for high-performance networking.",
      "story": "aiohttp was created to enable async HTTP requests and web servers in Python. It allows handling many connections concurrently, making it suitable for real-time web applications and APIs.",
      "installation": {
        "pip": "pip install aiohttp",
        "conda": "conda install -c conda-forge aiohttp"
      },
      "usage": {
        "overview": "aiohttp allows asynchronous HTTP requests and building async web servers using Python’s asyncio. It supports request handling, middleware, routing, and websockets.",
        "basic_examples": [
          {
            "title": "Simple async GET request",
            "code": "import aiohttp\nimport asyncio\n\nasync def fetch():\n    async with aiohttp.ClientSession() as session:\n        async with session.get('https://httpbin.org/get') as resp:\n            print(await resp.text())\n\nasyncio.run(fetch())",
            "explanation": "Performs an async GET request and prints the response body."
          }
        ],
        "advanced_examples": [
          {
            "title": "Creating an async web server",
            "code": "from aiohttp import web\n\nasync def hello(request):\n    return web.Response(text='Hello, aiohttp!')\n\napp = web.Application()\napp.add_routes([web.get('/', hello)])\nweb.run_app(app)",
            "explanation": "Starts a basic async web server using aiohttp."
          }
        ],
        "best_practices": [
          "Use `async with` for client sessions to ensure proper cleanup.",
          "Avoid blocking code in async functions; use asyncio-compatible libraries.",
          "Leverage middlewares for authentication and logging."
        ],
        "error_handling": [
          {
            "error": "aiohttp.ClientError",
            "solution": "Handle network exceptions when making HTTP requests asynchronously."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.aiohttp.org/",
        "github": "https://github.com/aio-libs/aiohttp"
      }
    },
    {
      "id": "httpx",
      "name": "httpx",
      "category": "Web",
      "description": "httpx is a fully featured HTTP client for Python 3, supporting both synchronous and asynchronous requests, connection pooling, and HTTP/2.",
      "story": "httpx was created by Encode to provide a modern, high-performance HTTP client for Python. It is designed as a next-generation replacement for `requests` with async support and better HTTP/2 handling, making it ideal for modern web applications and APIs.",
      "installation": {
        "pip": "pip install httpx",
        "conda": "conda install -c conda-forge httpx"
      },
      "usage": {
        "overview": "httpx allows sending HTTP requests synchronously or asynchronously. It supports custom headers, cookies, timeout handling, streaming responses, and HTTP/2 features.",
        "basic_examples": [
          {
            "title": "Synchronous GET request",
            "code": "import httpx\nresponse = httpx.get('https://httpbin.org/get')\nprint(response.status_code)\nprint(response.json())",
            "explanation": "Performs a simple synchronous GET request and prints the status code and JSON response."
          },
          {
            "title": "Asynchronous GET request",
            "code": "import httpx\nimport asyncio\n\nasync def fetch():\n    async with httpx.AsyncClient() as client:\n        r = await client.get('https://httpbin.org/get')\n        print(r.json())\n\nasyncio.run(fetch())",
            "explanation": "Demonstrates performing an asynchronous GET request using httpx."
          }
        ],
        "advanced_examples": [
          {
            "title": "Custom headers and cookies",
            "code": "import httpx\nheaders = {'User-Agent': 'my-app/0.0.1'}\ncookies = {'session_id': '12345'}\nresponse = httpx.get('https://httpbin.org/headers', headers=headers, cookies=cookies)\nprint(response.json())",
            "explanation": "Sends custom HTTP headers and cookies in a request."
          },
          {
            "title": "Timeouts and retries",
            "code": "import httpx\ntry:\n    response = httpx.get('https://httpbin.org/delay/10', timeout=5)\nexcept httpx.TimeoutException:\n    print('Request timed out')",
            "explanation": "Demonstrates handling request timeouts."
          },
          {
            "title": "Streaming responses",
            "code": "import httpx\nwith httpx.stream('GET', 'https://httpbin.org/stream/20') as response:\n    for chunk in response.iter_bytes():\n        print(chunk)",
            "explanation": "Streams the response content in chunks without loading everything into memory."
          }
        ],
        "best_practices": [
          "Use `AsyncClient` for concurrent requests to improve performance.",
          "Reuse client instances to take advantage of connection pooling.",
          "Always set timeouts to avoid hanging requests.",
          "Handle exceptions such as `httpx.RequestError` for robust error management.",
          "Leverage HTTP/2 support for faster multiplexed requests when possible."
        ],
        "error_handling": [
          {
            "error": "httpx.RequestError",
            "solution": "Catch network exceptions, invalid URLs, or connection issues."
          },
          {
            "error": "httpx.TimeoutException",
            "solution": "Set a reasonable timeout and handle it appropriately in your code."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.python-httpx.org/",
        "github": "https://github.com/encode/httpx"
      }
    },
    {
      "id": "sanic",
      "name": "Sanic",
      "category": "Web",
      "description": "Sanic is a Python 3.7+ web server and web framework that’s designed for fast HTTP responses using asynchronous capabilities powered by `asyncio`. It is ideal for building high-performance APIs and web applications.",
      "story": "Sanic was created by Kenneth Reitz in 2016 to provide an asynchronous Python web framework capable of handling high loads efficiently. It leverages Python's `async`/`await` syntax for non-blocking request handling and has been adopted for real-time APIs and web services requiring speed.",
      "installation": {
        "pip": "pip install sanic",
        "conda": "conda install -c conda-forge sanic"
      },
      "usage": {
        "overview": "Sanic allows defining routes with async request handlers, middleware, blueprints, and WebSocket support. It emphasizes high performance while maintaining simple and readable syntax.",
        "basic_examples": [
          {
            "title": "Simple Hello World App",
            "code": "from sanic import Sanic\nfrom sanic.response import text\n\napp = Sanic('my_app')\n\n@app.get('/')\nasync def hello(request):\n    return text('Hello, Sanic!')\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=8000)",
            "explanation": "Creates a basic Sanic app with a single GET route that responds with 'Hello, Sanic!'."
          },
          {
            "title": "Dynamic Route with URL Parameter",
            "code": "from sanic import Sanic\nfrom sanic.response import json\n\napp = Sanic('my_app')\n\n@app.get('/user/<name>')\nasync def greet_user(request, name):\n    return json({'message': f'Hello, {name}!'})\n\napp.run(host='0.0.0.0', port=8000)",
            "explanation": "Defines a dynamic route that captures the `<name>` parameter from the URL and returns it in a JSON response."
          }
        ],
        "advanced_examples": [
          {
            "title": "Middleware Example",
            "code": "from sanic import Sanic\nfrom sanic.response import text\n\napp = Sanic('my_app')\n\n@app.middleware('request')\nasync def print_request(request):\n    print(f'Received request: {request.method} {request.path}')\n\n@app.get('/')\nasync def hello(request):\n    return text('Hello, Sanic!')\n\napp.run(host='0.0.0.0', port=8000)",
            "explanation": "Demonstrates request middleware that executes before each request, logging method and path."
          },
          {
            "title": "Using Blueprints",
            "code": "from sanic import Sanic, Blueprint\nfrom sanic.response import json\n\nbp = Blueprint('api')\n\n@bp.get('/status')\nasync def status(request):\n    return json({'status': 'ok'})\n\napp = Sanic('my_app')\napp.blueprint(bp, url_prefix='/api')\n\napp.run(host='0.0.0.0', port=8000)",
            "explanation": "Shows how to modularize routes using Blueprints and a URL prefix."
          },
          {
            "title": "WebSocket Example",
            "code": "from sanic import Sanic\nfrom sanic.websocket import WebSocketProtocol\n\napp = Sanic('my_app')\n\n@app.websocket('/feed')\nasync def feed(request, ws):\n    while True:\n        data = await ws.recv()\n        await ws.send(f'Received: {data}')\n\napp.run(host='0.0.0.0', port=8000, protocol=WebSocketProtocol)",
            "explanation": "Implements a WebSocket route that echoes back messages received from the client."
          }
        ],
        "best_practices": [
          "Use async request handlers to leverage non-blocking performance.",
          "Organize large applications using Blueprints for modular routing.",
          "Use middleware for authentication, logging, and request preprocessing.",
          "Leverage Sanic’s built-in support for HTTP/2 for improved speed.",
          "Monitor performance using Sanic’s built-in metrics or custom logging."
        ],
        "error_handling": [
          {
            "error": "SanicException",
            "solution": "Use try/except blocks in handlers or Sanic’s error handlers to manage exceptions gracefully."
          },
          {
            "error": "Invalid usage of async/await",
            "solution": "Ensure all route handlers performing I/O operations are defined as async functions."
          }
        ]
      },
      "references": {
        "official_docs": "https://sanic.dev/en/",
        "github": "https://github.com/sanic-org/sanic"
      }
    },
    {
      "id": "starlette",
      "name": "Starlette",
      "category": "Web",
      "description": "Starlette is a lightweight ASGI framework/toolkit for building high-performance asynchronous web services in Python. It provides routing, middleware, sessions, background tasks, WebSockets, and testing utilities.",
      "story": "Starlette was created by Tom Christie, the author of Django REST Framework, to provide a minimal, fast, and flexible ASGI framework. It serves as the foundation for FastAPI and is widely used for building modern asynchronous web applications and APIs.",
      "installation": {
        "pip": "pip install starlette",
        "conda": "conda install -c conda-forge starlette"
      },
      "usage": {
        "overview": "Starlette allows you to define routes, mount applications, add middleware, handle background tasks, manage sessions, and work with WebSockets. Its asynchronous design ensures high performance for I/O-bound applications.",
        "basic_examples": [
          {
            "title": "Simple Starlette app",
            "code": "from starlette.applications import Starlette\nfrom starlette.responses import JSONResponse\nfrom starlette.routing import Route\n\nasync def homepage(request):\n    return JSONResponse({'message': 'Hello, Starlette!'})\n\nroutes = [\n    Route('/', homepage)\n]\n\napp = Starlette(debug=True, routes=routes)",
            "explanation": "Defines a basic Starlette application with one GET route returning JSON."
          },
          {
            "title": "Running the app with Uvicorn",
            "code": "# Terminal command:\nuvicorn main:app --reload",
            "explanation": "Starts the Starlette app using Uvicorn as the ASGI server with automatic reload on code changes."
          }
        ],
        "advanced_examples": [
          {
            "title": "Middleware example",
            "code": "from starlette.middleware.base import BaseHTTPMiddleware\n\nclass SimpleMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request, call_next):\n        response = await call_next(request)\n        response.headers['X-Custom-Header'] = 'Value'\n        return response\n\napp.add_middleware(SimpleMiddleware)",
            "explanation": "Adds middleware to process requests and responses, such as adding custom headers."
          },
          {
            "title": "Background task",
            "code": "from starlette.background import BackgroundTask\n\nasync def write_log():\n    with open('log.txt', 'a') as f:\n        f.write('Task executed\\n')\n\nasync def homepage(request):\n    return JSONResponse({'message': 'Hello!'}, background=BackgroundTask(write_log))",
            "explanation": "Runs a background task after sending the response to the client."
          },
          {
            "title": "WebSocket example",
            "code": "from starlette.endpoints import WebSocketEndpoint\nfrom starlette.websockets import WebSocket\n\nclass Echo(WebSocketEndpoint):\n    async def on_connect(self, websocket: WebSocket):\n        await websocket.accept()\n\n    async def on_receive(self, websocket: WebSocket, data):\n        await websocket.send_text(f'Received: {data}')\n\n    async def on_disconnect(self, websocket: WebSocket, close_code):\n        pass\n\napp.add_websocket_route('/ws', Echo)",
            "explanation": "Creates a WebSocket endpoint that echoes messages back to the client."
          },
          {
            "title": "Mounting sub-applications",
            "code": "from starlette.routing import Mount\nfrom starlette.staticfiles import StaticFiles\napp.mount('/static', StaticFiles(directory='static'), name='static')",
            "explanation": "Mounts a static file directory to serve assets under the `/static` path."
          }
        ],
        "best_practices": [
          "Use async endpoints for I/O-bound operations to maximize performance.",
          "Leverage middleware for cross-cutting concerns like logging, authentication, and CORS.",
          "Use Starlette’s BackgroundTask for non-blocking background operations.",
          "Combine with Uvicorn or Hypercorn for production-ready ASGI deployment.",
          "Test routes using Starlette’s built-in TestClient for automated testing."
        ],
        "error_handling": [
          {
            "error": "404 Not Found",
            "solution": "Ensure that the requested route is defined. Use exception handlers for custom responses."
          },
          {
            "error": "500 Internal Server Error",
            "solution": "Check asynchronous function exceptions and middleware to catch unhandled errors."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.starlette.io/",
        "github": "https://github.com/encode/starlette"
      }
    },
    {
      "id": "dask",
      "name": "Dask",
      "category": "Data Science",
      "description": "Dask is a flexible library for parallel computing in Python. It allows you to scale NumPy, Pandas, and Python functions to multi-core machines or distributed clusters for large-scale data processing.",
      "story": "Dask was created by Matthew Rocklin in 2014 to enable scalable analytics in Python. It provides parallel collections that mimic the interfaces of NumPy arrays, Pandas DataFrames, and Python iterators, making it easy to transition existing code to parallel or distributed computing.",
      "installation": {
        "pip": "pip install dask[complete]",
        "conda": "conda install -c conda-forge dask"
      },
      "usage": {
        "overview": "Dask allows you to parallelize computations on large datasets by providing data structures like Dask Array, Dask DataFrame, and Dask Bag. It integrates seamlessly with NumPy, Pandas, and Scikit-learn, and can run on a single machine or distributed cluster.",
        "basic_examples": [
          {
            "title": "Dask Array basic operations",
            "code": "import dask.array as da\nx = da.arange(1000, chunks=100)\ny = x + 1\nprint(y.sum().compute())",
            "explanation": "Creates a Dask array, performs an element-wise addition, and computes the sum in parallel."
          },
          {
            "title": "Dask DataFrame operations",
            "code": "import dask.dataframe as dd\ndf = dd.read_csv('data/*.csv')\nprint(df.head())\nprint(df['column'].mean().compute())",
            "explanation": "Reads multiple CSV files as a Dask DataFrame and computes the mean of a column in parallel."
          }
        ],
        "advanced_examples": [
          {
            "title": "Delayed computations",
            "code": "from dask import delayed\n\n@delayed\ndef inc(x):\n    return x + 1\n\n@delayed\ndef add(x, y):\n    return x + y\n\nx = inc(10)\ny = inc(20)\nz = add(x, y)\nprint(z.compute())",
            "explanation": "Demonstrates Dask’s delayed interface for building computation graphs lazily, then executing them in parallel."
          },
          {
            "title": "Parallel machine learning with Dask-ML",
            "code": "import dask_ml.linear_model as dlm\nfrom dask.distributed import Client\nclient = Client()\nmodel = dlm.LinearRegression()\n# Fit model on Dask arrays or DataFrames",
            "explanation": "Shows how to scale machine learning computations using Dask-ML and distributed clients."
          },
          {
            "title": "Distributed computing",
            "code": "from dask.distributed import Client\nclient = Client('tcp://scheduler-address:8786')\n# Submit tasks to the cluster\nfuture = client.submit(pow, 2, 10)\nprint(future.result())",
            "explanation": "Connects to a Dask distributed cluster and submits tasks for parallel execution."
          }
        ],
        "best_practices": [
          "Break large datasets into appropriately sized chunks to optimize parallelism.",
          "Use Dask collections that mimic familiar NumPy/Pandas interfaces to reduce learning curve.",
          "Leverage `compute()` only when necessary to trigger execution; avoid multiple small `compute()` calls.",
          "Use Dask’s distributed scheduler for multi-machine setups for large-scale computation.",
          "Monitor tasks with the Dask dashboard to detect bottlenecks and improve performance."
        ],
        "error_handling": [
          {
            "error": "ValueError: Chunk size too large",
            "solution": "Adjust chunk sizes to fit in memory when creating Dask arrays or DataFrames."
          },
          {
            "error": "FileNotFoundError",
            "solution": "Ensure all file paths exist when using Dask’s read functions."
          },
          {
            "error": "dask.distributed.core.TimeoutError",
            "solution": "Check connectivity to the distributed cluster and adjust timeout settings."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.dask.org/en/latest/",
        "github": "https://github.com/dask/dask"
      }
    },
    {
      "id": "vaex",
      "name": "Vaex",
      "category": "Data Science",
      "description": "Vaex is a high-performance Python library for out-of-core DataFrames, enabling visualization and exploration of datasets larger than memory. It allows fast filtering, grouping, aggregations, and statistical computations without loading the full dataset into RAM.",
      "story": "Vaex was created by Jovan Popovic in 2015 to handle very large tabular datasets efficiently. It leverages memory mapping, lazy evaluations, and optimized algorithms to provide a pandas-like interface while scaling to billions of rows, making it ideal for big data analysis and visualization.",
      "installation": {
        "pip": "pip install vaex",
        "conda": "conda install -c conda-forge vaex"
      },
      "usage": {
        "overview": "Vaex allows you to manipulate, filter, group, and aggregate large datasets efficiently. It uses lazy evaluations to compute results only when needed, which minimizes memory usage. Vaex integrates well with NumPy and Pandas-like syntax.",
        "basic_examples": [
          {
            "title": "Loading a CSV file",
            "code": "import vaex\ndf = vaex.from_csv('data.csv', convert=True)\nprint(df.head())",
            "explanation": "Loads a CSV file into a Vaex DataFrame. `convert=True` converts it to a fast HDF5-backed format for faster future access."
          },
          {
            "title": "Basic filtering",
            "code": "filtered = df[df['age'] > 30]\nprint(filtered.head())",
            "explanation": "Filters rows where the 'age' column is greater than 30 without loading the full dataset into memory."
          }
        ],
        "advanced_examples": [
          {
            "title": "Group by and aggregation",
            "code": "agg = df.groupby('department', agg={'avg_salary': vaex.agg.mean('salary')})\nprint(agg)",
            "explanation": "Performs a group-by operation and calculates the average salary per department."
          },
          {
            "title": "Virtual columns",
            "code": "df['bmi'] = df['weight'] / (df['height']/100)**2\nprint(df[['weight','height','bmi']].head())",
            "explanation": "Creates a virtual column 'bmi' based on existing columns. Computation is lazy and memory-efficient."
          },
          {
            "title": "Visualization",
            "code": "import matplotlib.pyplot as plt\n\nagg = df.count(binby=df['age'], limits=[0,100], shape=100)\nplt.plot(agg)\nplt.show()",
            "explanation": "Generates a histogram for the 'age' column using Vaex's fast binning."
          },
          {
            "title": "Exporting to other formats",
            "code": "df.export_csv('filtered.csv')\ndf.export_hdf5('filtered.hdf5')",
            "explanation": "Exports Vaex DataFrames to CSV or HDF5 formats for further use."
          }
        ],
        "best_practices": [
          "Use HDF5 or Arrow format for very large datasets for faster access.",
          "Leverage virtual columns to avoid unnecessary memory usage.",
          "Apply filtering and aggregation lazily to scale computations efficiently.",
          "Use `vaex.open()` or `vaex.from_csv(convert=True)` to optimize repeated data loads.",
          "Combine with visualization tools like Matplotlib or Bokeh for interactive plotting of large datasets."
        ],
        "error_handling": [
          {
            "error": "ValueError: Column not found",
            "solution": "Check that the column name exists in the DataFrame. Use `df.columns` to list available columns."
          },
          {
            "error": "MemoryError",
            "solution": "Ensure you use out-of-core processing features and avoid loading extremely large datasets fully into memory."
          },
          {
            "error": "FileNotFoundError",
            "solution": "Verify the path to the CSV or HDF5 file is correct before loading."
          }
        ]
      },
      "references": {
        "official_docs": "https://vaex.io/docs/",
        "github": "https://github.com/vaexio/vaex"
      }
    },
    {
      "id": "statsmodels",
      "name": "Statsmodels",
      "category": "Data Science",
      "description": "Statsmodels is a Python library that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests and statistical data exploration.",
      "story": "Statsmodels was created by Skipper Seabold and Josef Perktold to provide a Python package for classical statistics and econometrics. It complements libraries like NumPy, SciPy, and Pandas, enabling researchers and analysts to fit statistical models, perform hypothesis testing, and explore data efficiently.",
      "installation": {
        "pip": "pip install statsmodels",
        "conda": "conda install -c conda-forge statsmodels"
      },
      "usage": {
        "overview": "Statsmodels supports regression models (linear, logistic, etc.), time series analysis, generalized linear models, and more. It provides detailed statistical output, making it ideal for rigorous analysis and reporting.",
        "basic_examples": [
          {
            "title": "Linear Regression",
            "code": "import statsmodels.api as sm\nimport numpy as np\nX = np.array([1,2,3,4,5])\ny = np.array([2,4,5,4,5])\nX = sm.add_constant(X)  # add intercept\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())",
            "explanation": "Performs ordinary least squares (OLS) linear regression and prints a detailed statistical summary."
          },
          {
            "title": "Logistic Regression",
            "code": "import statsmodels.api as sm\nimport numpy as np\nX = np.array([[1],[2],[3],[4],[5]])\ny = np.array([0,0,0,1,1])\nX = sm.add_constant(X)\nmodel = sm.Logit(y, X).fit()\nprint(model.summary())",
            "explanation": "Fits a logistic regression model for binary outcome data and outputs statistical details."
          }
        ],
        "advanced_examples": [
          {
            "title": "Time Series ARIMA Model",
            "code": "import statsmodels.api as sm\nimport pandas as pd\ndata = pd.Series([1,2,3,4,5,6,7,8,9,10])\nmodel = sm.tsa.ARIMA(data, order=(1,1,0))\nresults = model.fit()\nprint(results.summary())",
            "explanation": "Fits an ARIMA model to a time series and outputs coefficients and diagnostics."
          },
          {
            "title": "Generalized Linear Models (GLM)",
            "code": "import statsmodels.api as sm\nimport numpy as np\nX = np.array([1,2,3,4,5])\ny = np.array([2,3,5,4,6])\nX = sm.add_constant(X)\nmodel = sm.GLM(y, X, family=sm.families.Poisson()).fit()\nprint(model.summary())",
            "explanation": "Fits a Poisson regression model using GLM and prints the summary."
          },
          {
            "title": "Hypothesis Testing",
            "code": "from statsmodels.stats.weightstats import ztest\nimport numpy as np\ndata1 = np.array([1,2,3,4,5])\ndata2 = np.array([2,3,4,5,6])\nz_stat, p_val = ztest(data1, data2)\nprint(f'Z-statistic: {z_stat}, p-value: {p_val}')",
            "explanation": "Performs a Z-test to compare two samples."
          }
        ],
        "best_practices": [
          "Always inspect `model.summary()` for statistical diagnostics and model fit.",
          "Preprocess data (standardize, handle missing values) before modeling.",
          "Choose appropriate model type based on data distribution and research question.",
          "Use statistical tests to validate assumptions (normality, heteroscedasticity, etc.).",
          "Combine with Pandas for data manipulation and cleaning prior to modeling."
        ],
        "error_handling": [
          {
            "error": "LinAlgError: Singular matrix",
            "solution": "Check for multicollinearity or duplicate columns in the predictor matrix."
          },
          {
            "error": "ValueError: endog and exog matrices are not aligned",
            "solution": "Ensure that response (`y`) and predictor (`X`) arrays have compatible dimensions."
          },
          {
            "error": "PerfectSeparationError",
            "solution": "Occurs in logistic regression if one predictor perfectly predicts the outcome; consider removing or regularizing variables."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.statsmodels.org/stable/index.html",
        "github": "https://github.com/statsmodels/statsmodels"
      }
    },
    {
      "id": "openpyxl",
      "name": "Openpyxl",
      "category": "Data",
      "description": "Openpyxl is a Python library to read, write, and modify Excel 2010 xlsx/xlsm/xltx/xltm files. It allows you to create spreadsheets, read data, and perform operations on Excel files programmatically.",
      "story": "Openpyxl was created by Eric Gazoni and Charlie Clark to provide Python developers with a tool to interact with Excel files without relying on Microsoft Excel itself. It has become the standard library for working with modern Excel files in Python, widely used for data automation, reporting, and spreadsheet manipulation.",
      "installation": {
        "pip": "pip install openpyxl",
        "conda": "conda install -c anaconda openpyxl"
      },
      "usage": {
        "overview": "Openpyxl allows creating new Excel workbooks, reading existing files, modifying cells, formatting, adding charts, and saving changes. It supports formulas, styles, merged cells, and more.",
        "basic_examples": [
          {
            "title": "Creating a new workbook and adding data",
            "code": "from openpyxl import Workbook\nwb = Workbook()\nsheet = wb.active\nsheet['A1'] = 'Name'\nsheet['B1'] = 'Age'\nsheet.append(['Alice', 30])\nsheet.append(['Bob', 25])\nwb.save('example.xlsx')",
            "explanation": "Creates a new Excel file with headers and two rows of data, then saves it."
          },
          {
            "title": "Reading an existing workbook",
            "code": "from openpyxl import load_workbook\nwb = load_workbook('example.xlsx')\nsheet = wb.active\nfor row in sheet.iter_rows(values_only=True):\n    print(row)",
            "explanation": "Opens an existing Excel file and prints all rows in the active sheet."
          }
        ],
        "advanced_examples": [
          {
            "title": "Formatting cells",
            "code": "from openpyxl.styles import Font\nsheet['A1'].font = Font(bold=True, color='FF0000')\nwb.save('example.xlsx')",
            "explanation": "Applies bold and red font to a specific cell."
          },
          {
            "title": "Adding formulas",
            "code": "sheet['C2'] = '=SUM(B2:B3)'\nwb.save('example.xlsx')",
            "explanation": "Adds a formula to sum values in a column."
          },
          {
            "title": "Merging and unmerging cells",
            "code": "sheet.merge_cells('A4:B4')\nsheet['A4'] = 'Merged Cell'\nwb.save('example.xlsx')",
            "explanation": "Merges two cells and assigns a value to the merged area."
          },
          {
            "title": "Adding charts",
            "code": "from openpyxl.chart import BarChart, Reference\nchart = BarChart()\ndata = Reference(sheet, min_col=2, min_row=1, max_row=3, max_col=2)\nchart.add_data(data, titles_from_data=True)\nsheet.add_chart(chart, 'E5')\nwb.save('example.xlsx')",
            "explanation": "Adds a bar chart to visualize the data in the worksheet."
          }
        ],
        "best_practices": [
          "Always close or save the workbook after modifications to persist changes.",
          "Use `iter_rows(values_only=True)` when reading large files to save memory.",
          "Leverage cell styles and formats for readability in reports.",
          "Avoid modifying open files from multiple processes simultaneously.",
          "Use formulas and charts to enhance automation and reporting capabilities."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundError",
            "solution": "Ensure the path to the Excel file exists when using `load_workbook()`."
          },
          {
            "error": "InvalidFileException",
            "solution": "Make sure the file is a valid .xlsx, .xlsm, .xltx, or .xltm file."
          },
          {
            "error": "KeyError: Worksheet",
            "solution": "Check that the worksheet name exists before accessing it with `wb[sheet_name]`."
          }
        ]
      },
      "references": {
        "official_docs": "https://openpyxl.readthedocs.io/",
        "github": "https://github.com/openpyxl/openpyxl"
      }
    },
    {
      "id": "xlrd-xlwt",
      "name": "xlrd / xlwt",
      "category": "Data",
      "description": "xlrd and xlwt are Python libraries used for reading (xlrd) and writing (xlwt) Excel files in the old .xls format. They provide tools to extract, manipulate, and create Excel spreadsheets programmatically.",
      "story": "xlrd and xlwt were created to handle Excel 97–2003 files in Python. They predate modern libraries like openpyxl, and are still used in legacy systems for reading and writing .xls files efficiently.",
      "installation": {
        "pip": "pip install xlrd xlwt",
        "conda": "conda install -c anaconda xlrd xlwt"
      },
      "usage": {
        "overview": "xlrd is used to read data from .xls files, while xlwt is used to write data to .xls files. Both libraries provide access to sheets, rows, and cells, allowing for reading, writing, formatting, and basic Excel manipulation.",
        "basic_examples": [
          {
            "title": "Reading an Excel file with xlrd",
            "code": "import xlrd\nworkbook = xlrd.open_workbook('example.xls')\nsheet = workbook.sheet_by_index(0)\nfor row_idx in range(sheet.nrows):\n    print(sheet.row_values(row_idx))",
            "explanation": "Opens an existing Excel file, accesses the first sheet, and prints all rows."
          },
          {
            "title": "Writing an Excel file with xlwt",
            "code": "import xlwt\nworkbook = xlwt.Workbook()\nsheet = workbook.add_sheet('Sheet1')\nsheet.write(0, 0, 'Name')\nsheet.write(0, 1, 'Age')\nsheet.write(1, 0, 'Alice')\nsheet.write(1, 1, 30)\nworkbook.save('output.xls')",
            "explanation": "Creates a new Excel file, adds headers and data, and saves it as `output.xls`."
          }
        ],
        "advanced_examples": [
          {
            "title": "Formatting cells with xlwt",
            "code": "import xlwt\nstyle = xlwt.easyxf('font: bold on, color red; align: horiz center')\nsheet.write(0, 0, 'Header', style)\nworkbook.save('styled.xls')",
            "explanation": "Applies bold, red, and center-aligned style to a cell while writing to Excel."
          },
          {
            "title": "Reading specific columns and rows with xlrd",
            "code": "for row_idx in range(1, sheet.nrows):\n    name = sheet.cell_value(row_idx, 0)\n    age = sheet.cell_value(row_idx, 1)\n    print(f'{name} - {age}')",
            "explanation": "Reads only specific columns from each row, skipping headers."
          },
          {
            "title": "Writing formulas with xlwt",
            "code": "sheet.write(2, 1, xlwt.Formula('B2+B3'))\nworkbook.save('formulas.xls')",
            "explanation": "Writes a formula to a cell to calculate the sum of other cells."
          }
        ],
        "best_practices": [
          "Use xlrd strictly for reading old .xls files; for .xlsx files, use openpyxl or pandas.",
          "Use xlwt for writing small to medium .xls files; xlwt does not support .xlsx.",
          "Organize sheets and cell writes carefully to avoid overwriting data.",
          "Use cell formatting sparingly for readability; complex formatting may be limited.",
          "Always close or save the workbook to persist changes."
        ],
        "error_handling": [
          {
            "error": "XLRDError: Unsupported format, or corrupt file",
            "solution": "Ensure you are opening an .xls file. xlrd no longer supports .xlsx files in recent versions."
          },
          {
            "error": "TypeError: write() argument 3 must be a string or number",
            "solution": "Convert data to a string or numeric type before writing to a cell."
          },
          {
            "error": "FileNotFoundError",
            "solution": "Check that the path to the Excel file exists before reading."
          }
        ]
      },
      "references": {
        "official_docs": "https://xlrd.readthedocs.io/ https://xlwt.readthedocs.io/",
        "github": "https://github.com/python-excel/xlrd https://github.com/python-excel/xlwt"
      }
    },
    {
      "id": "pyarrow",
      "name": "PyArrow",
      "category": "Data",
      "description": "PyArrow is a cross-language development platform for in-memory data, primarily designed for columnar data processing. It provides a Python interface for the Apache Arrow columnar memory format and enables efficient data interchange and analytics.",
      "story": "PyArrow was created by the Apache Arrow project to provide fast, standardized, and language-agnostic data structures. It allows Python applications to work efficiently with large datasets in memory, perform zero-copy reads, and interoperate with systems like Pandas, Parquet, and Spark.",
      "installation": {
        "pip": "pip install pyarrow",
        "conda": "conda install -c conda-forge pyarrow"
      },
      "usage": {
        "overview": "PyArrow provides tools for handling Arrow arrays, tables, and memory-mapped files. It supports reading and writing Parquet and Feather formats, interacting with Pandas DataFrames efficiently, and integrating with big data frameworks.",
        "basic_examples": [
          {
            "title": "Creating an Arrow Table from Pandas",
            "code": "import pyarrow as pa\nimport pandas as pd\ndf = pd.DataFrame({'col1': [1,2,3], 'col2': ['a','b','c']})\ntable = pa.Table.from_pandas(df)\nprint(table)",
            "explanation": "Converts a Pandas DataFrame into a PyArrow Table for columnar processing."
          },
          {
            "title": "Writing to Parquet file",
            "code": "import pyarrow.parquet as pq\npq.write_table(table, 'example.parquet')",
            "explanation": "Writes a PyArrow Table to a Parquet file on disk."
          },
          {
            "title": "Reading from Parquet file",
            "code": "table = pq.read_table('example.parquet')\ndf = table.to_pandas()\nprint(df)",
            "explanation": "Reads a Parquet file into a PyArrow Table and converts it back to Pandas for analysis."
          }
        ],
        "advanced_examples": [
          {
            "title": "Zero-copy data sharing with NumPy",
            "code": "import numpy as np\narr = np.array([1,2,3,4])\narrow = pa.array(arr)\nprint(arrow_array)",
            "explanation": "Demonstrates converting a NumPy array to an Arrow array without copying memory."
          },
          {
            "title": "Feather format for fast I/O",
            "code": "import pyarrow.feather as feather\nfeather.write_feather(df, 'example.feather')\ndf2 = feather.read_feather('example.feather')\nprint(df2)",
            "explanation": "Reads and writes Feather files for fast, language-agnostic serialization of dataframes."
          },
          {
            "title": "Using Arrow Memory Pool",
            "code": "import pyarrow as pa\npool = pa.memory_pool()\narr = pa.array([1,2,3], memory_pool=pool)\nprint(pool.bytes_allocated())",
            "explanation": "Demonstrates memory allocation tracking using PyArrow’s memory pool for optimized memory management."
          }
        ],
        "best_practices": [
          "Use Arrow Tables for columnar, in-memory analytics for speed and efficiency.",
          "Prefer Feather or Parquet formats for storage and interoperability between Python and other languages.",
          "Use PyArrow with Pandas for zero-copy operations when dealing with large datasets.",
          "Leverage memory pools to reduce memory fragmentation and improve performance.",
          "Combine PyArrow with Dask for parallel processing of large datasets."
        ],
        "error_handling": [
          {
            "error": "ArrowInvalid",
            "solution": "Check the data type compatibility when creating Arrow arrays or tables."
          },
          {
            "error": "ParquetFileError",
            "solution": "Ensure that the Parquet file exists and is not corrupted."
          },
          {
            "error": "MemoryError",
            "solution": "Use Arrow memory pools or process data in batches to avoid running out of memory."
          }
        ]
      },
      "references": {
        "official_docs": "https://arrow.apache.org/docs/python/",
        "github": "https://github.com/apache/arrow"
      }
    },
    {
      "id": "bokeh",
      "name": "Bokeh",
      "category": "Data Science",
      "description": "Bokeh is an interactive visualization library for Python that targets modern web browsers for presentation. It allows the creation of interactive plots, dashboards, and data applications with high-performance interactivity over large datasets.",
      "story": "Bokeh was created by Bryan Van de Ven and Continuum Analytics (now Anaconda Inc.) in 2013 to enable Python users to build interactive, browser-based visualizations without needing to write JavaScript. Its goal is to provide elegant, concise construction of versatile graphics and dashboards suitable for web presentation.",
      "installation": {
        "pip": "pip install bokeh",
        "conda": "conda install -c bokeh bokeh"
      },
      "usage": {
        "overview": "Bokeh provides a Python interface to generate interactive plots that render in browsers using HTML and JavaScript. It supports line plots, scatter plots, bar charts, heatmaps, widgets, and server-side apps with real-time interactivity.",
        "basic_examples": [
          {
            "title": "Simple line plot",
            "code": "from bokeh.plotting import figure, show\n\np = figure(title='Simple Line Plot', x_axis_label='x', y_axis_label='y')\np.line([1,2,3,4,5], [6,7,2,4,5], line_width=2)\nshow(p)",
            "explanation": "Creates a simple line plot with labeled axes and displays it in a browser."
          },
          {
            "title": "Scatter plot",
            "code": "from bokeh.plotting import figure, show\np = figure(title='Scatter Plot', x_axis_label='x', y_axis_label='y')\np.circle([1,2,3,4], [4,7,2,5], size=10, color='navy', alpha=0.5)\nshow(p)",
            "explanation": "Generates a scatter plot with circle markers, color, and transparency settings."
          }
        ],
        "advanced_examples": [
          {
            "title": "Adding Hover Tooltips",
            "code": "from bokeh.models import HoverTool\nhover = HoverTool(tooltips=[('x','@x'),('y','@y')])\np.add_tools(hover)",
            "explanation": "Adds interactive hover tooltips that display x and y values when the user hovers over points."
          },
          {
            "title": "Creating a Bar Chart",
            "code": "from bokeh.models import ColumnDataSource\nfrom bokeh.plotting import figure, show\nsource = ColumnDataSource(data=dict(fruits=['Apple','Banana','Orange'], counts=[10,20,15]))\np = figure(x_range=source.data['fruits'], title='Fruit Counts')\np.vbar(x='fruits', top='counts', width=0.9, source=source)\nshow(p)",
            "explanation": "Creates a vertical bar chart from a ColumnDataSource."
          },
          {
            "title": "Interactive Bokeh Server App",
            "code": "from bokeh.io import curdoc\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource\nsource = ColumnDataSource(data=dict(x=[1,2,3], y=[4,5,6]))\np = figure()\np.line('x','y', source=source)\ncurdoc().add_root(p)",
            "explanation": "Demonstrates creating a Bokeh app that can be served with `bokeh serve` for real-time interactivity."
          },
          {
            "title": "Linking multiple plots",
            "code": "from bokeh.layouts import row\np1 = figure()\np1.circle([1,2,3],[4,5,6])\np2 = figure(x_range=p1.x_range)\np2.line([1,2,3],[6,5,4])\nshow(row(p1,p2))",
            "explanation": "Links x-axis range between two plots to allow synchronized zooming and panning."
          }
        ],
        "best_practices": [
          "Use ColumnDataSource for better performance and easier interactivity.",
          "Leverage Bokeh server for live-updating dashboards.",
          "Keep visualizations clean and label axes and legends for clarity.",
          "Combine with Pandas for easy data handling and plotting.",
          "Profile complex plots for performance with large datasets."
        ],
        "error_handling": [
          {
            "error": "ValueError: mismatched data lengths",
            "solution": "Ensure that all lists or arrays passed to Bokeh glyphs have the same length."
          },
          {
            "error": "ImportError: No module named 'bokeh'",
            "solution": "Install Bokeh using pip or conda in your Python environment."
          },
          {
            "error": "RuntimeError: Bokeh server not running",
            "solution": "Start the Bokeh server using `bokeh serve --show script.py` for interactive apps."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.bokeh.org/",
        "github": "https://github.com/bokeh/bokeh"
      }
    },
    {
      "id": "plotly",
      "name": "Plotly",
      "category": "Data Science",
      "description": "Plotly is a Python graphing library that makes interactive, publication-quality graphs online. It supports a wide variety of chart types, including line plots, scatter plots, bar charts, 3D plots, maps, and dashboards.",
      "story": "Plotly was created by Chris Parmer, Jack Parmer, and Alex Johnson in 2013 to provide a framework for interactive, web-ready visualizations. It integrates seamlessly with Python, R, MATLAB, and JavaScript, and allows users to create interactive plots for analysis, reporting, and dashboards.",
      "installation": {
        "pip": "pip install plotly",
        "conda": "conda install -c plotly plotly"
      },
      "usage": {
        "overview": "Plotly allows the creation of interactive visualizations with Python. You can generate figures using Plotly Express for simple charts or use the lower-level Graph Objects API for more complex and customized visualizations.",
        "basic_examples": [
          {
            "title": "Simple line plot with Plotly Express",
            "code": "import plotly.express as px\nimport pandas as pd\ndf = pd.DataFrame({'x':[1,2,3,4], 'y':[10,15,13,17]})\nfig = px.line(df, x='x', y='y', title='Line Plot')\nfig.show()",
            "explanation": "Creates an interactive line plot from a Pandas DataFrame and displays it in a browser or notebook."
          },
          {
            "title": "Scatter plot with Plotly Express",
            "code": "import plotly.express as px\ndf = px.data.iris()\nfig = px.scatter(df, x='sepal_width', y='sepal_length', color='species')\nfig.show()",
            "explanation": "Generates a scatter plot with color-coded species categories using Plotly Express."
          }
        ],
        "advanced_examples": [
          {
            "title": "Customizing layout with Graph Objects",
            "code": "import plotly.graph_objects as go\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=[1,2,3], y=[4,5,6], mode='lines+markers', name='Line 1'))\nfig.update_layout(title='Custom Layout', xaxis_title='X Axis', yaxis_title='Y Axis')\nfig.show()",
            "explanation": "Demonstrates using Graph Objects to create a scatter plot with custom layout titles and styling."
          },
          {
            "title": "3D Surface plot",
            "code": "import plotly.graph_objects as go\nimport numpy as np\nx = np.linspace(-5,5,50)\ny = np.linspace(-5,5,50)\nx, y = np.meshgrid(x, y)\nz = np.sin(np.sqrt(x**2 + y**2))\nfig = go.Figure(data=[go.Surface(z=z, x=x, y=y)])\nfig.show()",
            "explanation": "Creates an interactive 3D surface plot of a mathematical function."
          },
          {
            "title": "Subplots and multiple traces",
            "code": "from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nfig = make_subplots(rows=1, cols=2)\nfig.add_trace(go.Bar(x=[1,2,3], y=[2,5,3]), row=1, col=1)\nfig.add_trace(go.Scatter(x=[1,2,3], y=[5,3,6]), row=1, col=2)\nfig.show()",
            "explanation": "Shows how to create multiple plots in a single figure using subplots with different trace types."
          },
          {
            "title": "Interactive animations",
            "code": "import plotly.express as px\ndf = px.data.gapminder()\nfig = px.scatter(df.query('year==2007'), x='gdpPercap', y='lifeExp', size='pop', color='continent', hover_name='country', size_max=60, animation_frame='year')\nfig.show()",
            "explanation": "Creates an animated scatter plot showing changes over years using Plotly Express."
          }
        ],
        "best_practices": [
          "Use Plotly Express for quick, simple visualizations; use Graph Objects for detailed, customized figures.",
          "Leverage hover labels, annotations, and legends for better interactivity.",
          "Combine subplots to display multiple visualizations in one figure.",
          "Use color scales and consistent styling for clarity and accessibility.",
          "Export figures to HTML for sharing interactive visualizations easily."
        ],
        "error_handling": [
          {
            "error": "ValueError: Invalid value",
            "solution": "Check that your x and y data arrays have the same length and that column names match your DataFrame."
          },
          {
            "error": "ModuleNotFoundError: No module named 'plotly'",
            "solution": "Ensure Plotly is installed in your environment using pip or conda."
          },
          {
            "error": "TypeError: figure.show() missing",
            "solution": "Verify you have created a valid figure object using Plotly Express or Graph Objects."
          }
        ]
      },
      "references": {
        "official_docs": "https://plotly.com/python/",
        "github": "https://github.com/plotly/plotly.py"
      }
    },
    {
      "id": "altair",
      "name": "Altair",
      "category": "Data Science",
      "description": "Altair is a declarative statistical visualization library for Python. It allows users to create interactive and concise charts based on the Vega and Vega-Lite visualization grammars.",
      "story": "Altair was created by Jake VanderPlas and the Altair development team to provide a simple, declarative way to create rich visualizations in Python. Its focus is on producing high-quality, interactive charts with minimal code while maintaining clear semantics and good integration with Pandas.",
      "installation": {
        "pip": "pip install altair",
        "conda": "conda install -c conda-forge altair"
      },
      "usage": {
        "overview": "Altair leverages a declarative API where you specify 'what' to plot rather than 'how' to plot it. It supports bar charts, line charts, scatter plots, heatmaps, and more, with built-in interactivity like selections, tooltips, and filtering.",
        "basic_examples": [
          {
            "title": "Simple Bar Chart",
            "code": "import altair as alt\nimport pandas as pd\ndf = pd.DataFrame({'category': ['A', 'B', 'C'], 'value': [4, 7, 1]})\nchart = alt.Chart(df).mark_bar().encode(x='category', y='value')\nchart.show()",
            "explanation": "Creates a simple bar chart using a Pandas DataFrame and displays it."
          },
          {
            "title": "Line Chart with Tooltips",
            "code": "import altair as alt\nimport pandas as pd\ndf = pd.DataFrame({'x': [1, 2, 3, 4], 'y': [10, 15, 13, 17]})\nchart = alt.Chart(df).mark_line(point=True).encode(x='x', y='y', tooltip=['x','y'])\nchart.show()",
            "explanation": "Generates a line chart with points and interactive tooltips showing x and y values."
          }
        ],
        "advanced_examples": [
          {
            "title": "Scatter Plot with Selection",
            "code": "import altair as alt\nimport pandas as pd\ndf = pd.DataFrame({'x':[1,2,3,4],'y':[10,20,25,30],'category':['A','A','B','B']})\nselector = alt.selection_multi(fields=['category'])\nchart = alt.Chart(df).mark_circle(size=100).encode(x='x', y='y', color='category').add_selection(selector)\nchart.show()",
            "explanation": "Creates an interactive scatter plot where users can select points by category using a selection object."
          },
          {
            "title": "Faceted Charts",
            "code": "import altair as alt\nimport pandas as pd\ndf = pd.DataFrame({'x':[1,2,3,4],'y':[10,20,25,30],'group':['A','A','B','B']})\nchart = alt.Chart(df).mark_line().encode(x='x', y='y').facet('group')\nchart.show()",
            "explanation": "Facets data into multiple small charts based on the 'group' column."
          },
          {
            "title": "Interactive Filtering",
            "code": "import altair as alt\nimport pandas as pd\ndf = pd.DataFrame({'x':[1,2,3,4],'y':[10,20,25,30],'group':['A','A','B','B']})\ninput_dropdown = alt.binding_select(options=['A','B'], name='Select Group:')\nselection = alt.selection_single(fields=['group'], bind=input_dropdown)\nchart = alt.Chart(df).mark_bar().encode(x='x', y='y', color='group').add_selection(selection).transform_filter(selection)\nchart.show()",
            "explanation": "Demonstrates interactive filtering using a dropdown selection to display only selected group data."
          }
        ],
        "best_practices": [
          "Use Pandas DataFrames as input data for better integration.",
          "Leverage declarative syntax to keep code clean and readable.",
          "Combine charts with layering and faceting for richer visualizations.",
          "Use selections and interactions to enhance user exploration.",
          "Export charts to HTML or JSON for embedding in web applications."
        ],
        "error_handling": [
          {
            "error": "ValueError: Data format not recognized",
            "solution": "Ensure the input data is a Pandas DataFrame or a compatible data format."
          },
          {
            "error": "AltairError: chart has no encodings",
            "solution": "Make sure to specify at least one encoding (x, y, color, etc.) for the chart."
          },
          {
            "error": "Renderer not found",
            "solution": "Use `chart.show()` in Jupyter or `alt.renderers.enable('default')` to specify a renderer."
          }
        ]
      },
      "references": {
        "official_docs": "https://altair-viz.github.io/",
        "github": "https://github.com/altair-viz/altair"
      }
    },
    {
      "id": "plotnine",
      "name": "plotnine",
      "category": "Data Science",
      "description": "plotnine is a Python data visualization library based on the Grammar of Graphics, similar to ggplot2 in R. It allows building complex plots by layering components such as data, aesthetics, and geometric objects.",
      "story": "plotnine was created by Claus Wilke and contributors to bring the powerful and expressive Grammar of Graphics approach from R’s ggplot2 to Python. It integrates tightly with Pandas DataFrames, enabling users to create aesthetically pleasing and complex visualizations in Python with a concise syntax.",
      "installation": {
        "pip": "pip install plotnine",
        "conda": "conda install -c conda-forge plotnine"
      },
      "usage": {
        "overview": "plotnine allows you to construct plots by mapping data variables to aesthetics, adding layers for geoms, facets, scales, and themes. It supports line plots, scatter plots, bar charts, histograms, boxplots, and more, with full customization options.",
        "basic_examples": [
          {
            "title": "Simple scatter plot",
            "code": "from plotnine import ggplot, aes, geom_point\nimport pandas as pd\ndf = pd.DataFrame({'x':[1,2,3,4], 'y':[5,7,9,6]})\nplot = ggplot(df, aes('x','y')) + geom_point()\nprint(plot)",
            "explanation": "Creates a simple scatter plot mapping 'x' and 'y' from a Pandas DataFrame."
          },
          {
            "title": "Bar plot",
            "code": "from plotnine import ggplot, aes, geom_bar\nimport pandas as pd\ndf = pd.DataFrame({'category':['A','B','C'], 'value':[10,20,15]})\nplot = ggplot(df, aes(x='category', y='value')) + geom_bar(stat='identity')\nprint(plot)",
            "explanation": "Creates a bar chart from a DataFrame using geom_bar with `stat='identity'` to use actual values."
          }
        ],
        "advanced_examples": [
          {
            "title": "Line plot with color grouping",
            "code": "from plotnine import ggplot, aes, geom_line\nimport pandas as pd\ndf = pd.DataFrame({'x':[1,2,3,1,2,3], 'y':[2,3,4,5,6,7], 'group':['A','A','A','B','B','B']})\nplot = ggplot(df, aes('x','y', color='group')) + geom_line()\nprint(plot)",
            "explanation": "Plots multiple lines colored by group using the color aesthetic."
          },
          {
            "title": "Adding facets",
            "code": "from plotnine import facet_wrap\nplot = ggplot(df, aes('x','y')) + geom_point() + facet_wrap('~group')\nprint(plot)",
            "explanation": "Splits data into multiple panels based on the 'group' column using facet_wrap."
          },
          {
            "title": "Customizing themes",
            "code": "from plotnine import theme_bw, theme\nplot = ggplot(df, aes('x','y')) + geom_point() + theme_bw() + theme(figure_size=(6,4))\nprint(plot)",
            "explanation": "Applies a black-and-white theme and sets figure size."
          },
          {
            "title": "Histograms",
            "code": "from plotnine import geom_histogram\nplot = ggplot(df, aes('x')) + geom_histogram(binwidth=1, fill='blue', color='black')\nprint(plot)",
            "explanation": "Creates a histogram with specified bin width and styling."
          }
        ],
        "best_practices": [
          "Always use Pandas DataFrames for data input for full compatibility.",
          "Build plots incrementally using layers (geoms, scales, facets, themes).",
          "Use themes for consistent styling across multiple plots.",
          "Label axes and titles for clarity.",
          "Leverage facets for comparing subsets of data."
        ],
        "error_handling": [
          {
            "error": "ValueError: Column not found",
            "solution": "Ensure the column names in the DataFrame match those used in `aes()`."
          },
          {
            "error": "TypeError: geom_x() missing 1 required positional argument",
            "solution": "Check that all required aesthetics for the geom are specified."
          },
          {
            "error": "ImportError: No module named 'plotnine'",
            "solution": "Install plotnine using pip or conda before importing."
          }
        ]
      },
      "references": {
        "official_docs": "https://plotnine.readthedocs.io/",
        "github": "https://github.com/has2k1/plotnine"
      }
    },
    {
      "id": "xgboost",
      "name": "XGBoost",
      "category": "ML/AI",
      "description": "XGBoost (Extreme Gradient Boosting) is a high-performance, scalable, and flexible library for gradient boosting. It is widely used for supervised learning tasks such as regression, classification, and ranking.",
      "story": "XGBoost was developed by Tianqi Chen in 2014 to provide a fast and efficient implementation of gradient boosting algorithms. It gained popularity for winning many Kaggle competitions due to its speed, accuracy, and robustness, supporting regularization to prevent overfitting.",
      "installation": {
        "pip": "pip install xgboost",
        "conda": "conda install -c conda-forge xgboost"
      },
      "usage": {
        "overview": "XGBoost provides APIs to train gradient boosted decision trees. It supports sparse data, parallel processing, and GPU acceleration. Models can be trained using the `XGBClassifier`, `XGBRegressor`, or `DMatrix` interfaces.",
        "basic_examples": [
          {
            "title": "Training a simple classifier",
            "code": "import xgboost as xgb\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('Accuracy:', accuracy_score(y_test, y_pred))",
            "explanation": "Trains an XGBoost classifier on the Iris dataset and evaluates accuracy."
          },
          {
            "title": "Training a regressor",
            "code": "import xgboost as xgb\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX, y = load_boston(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = xgb.XGBRegressor()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('MSE:', mean_squared_error(y_test, y_pred))",
            "explanation": "Trains an XGBoost regressor on the Boston housing dataset and computes the mean squared error."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using DMatrix for efficient training",
            "code": "import xgboost as xgb\nimport numpy as np\nX = np.random.rand(100,5)\ny = np.random.randint(0,2,100)\ndtrain = xgb.DMatrix(X, label=y)\nparams = {'max_depth':3, 'eta':0.1, 'objective':'binary:logistic'}\nbst = xgb.train(params, dtrain, num_boost_round=10)",
            "explanation": "Uses XGBoost’s DMatrix for efficient memory usage and training performance."
          },
          {
            "title": "Hyperparameter tuning with sklearn API",
            "code": "from sklearn.model_selection import GridSearchCV\nparams = {'max_depth':[3,5], 'n_estimators':[50,100]}\ngrid = GridSearchCV(estimator=xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid=params, cv=3)\ngrid.fit(X_train, y_train)\nprint(grid.best_params_)",
            "explanation": "Performs grid search to find the best hyperparameters for the XGBoost classifier."
          },
          {
            "title": "Feature importance",
            "code": "import matplotlib.pyplot as plt\nxgb.plot_importance(model)\nplt.show()",
            "explanation": "Visualizes feature importance after training a model."
          },
          {
            "title": "Early stopping",
            "code": "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\nmodel.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=5)",
            "explanation": "Stops training early if the validation metric does not improve for a number of rounds."
          }
        ],
        "best_practices": [
          "Use `DMatrix` for large datasets to improve training efficiency.",
          "Tune hyperparameters such as `max_depth`, `learning_rate`, and `n_estimators` for optimal performance.",
          "Use early stopping to prevent overfitting.",
          "Leverage GPU acceleration if available for large datasets.",
          "Visualize feature importance to understand model behavior."
        ],
        "error_handling": [
          {
            "error": "ValueError: feature_names mismatch",
            "solution": "Ensure the feature names in the DMatrix match the training data columns."
          },
          {
            "error": "XGBoostError: Invalid parameter",
            "solution": "Check that all parameters are valid and correctly spelled for the chosen API."
          },
          {
            "error": "ImportError: No module named 'xgboost'",
            "solution": "Install XGBoost using pip or conda in your current Python environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://xgboost.readthedocs.io/",
        "github": "https://github.com/dmlc/xgboost"
      }
    },
    {
      "id": "lightgbm",
      "name": "LightGBM",
      "category": "ML/AI",
      "description": "LightGBM is a fast, distributed, high-performance gradient boosting framework based on decision tree algorithms. It is designed for efficiency and scalability, supporting large datasets and GPU acceleration.",
      "story": "LightGBM was developed by Microsoft in 2016 as part of the Distributed Machine Learning Toolkit (DMTK). It is optimized for speed and memory usage and has become a popular choice for Kaggle competitions and large-scale machine learning tasks due to its accuracy and efficiency.",
      "installation": {
        "pip": "pip install lightgbm",
        "conda": "conda install -c conda-forge lightgbm"
      },
      "usage": {
        "overview": "LightGBM provides APIs for training gradient boosted decision tree models for classification, regression, and ranking tasks. It supports categorical features natively, early stopping, custom evaluation metrics, and efficient handling of large datasets.",
        "basic_examples": [
          {
            "title": "Training a classifier",
            "code": "import lightgbm as lgb\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = lgb.LGBMClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('Accuracy:', accuracy_score(y_test, y_pred))",
            "explanation": "Trains a LightGBM classifier on the Iris dataset and evaluates accuracy."
          },
          {
            "title": "Training a regressor",
            "code": "import lightgbm as lgb\nfrom sklearn.datasets import load_boston\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX, y = load_boston(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = lgb.LGBMRegressor()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('MSE:', mean_squared_error(y_test, y_pred))",
            "explanation": "Trains a LightGBM regressor on the Boston housing dataset and computes mean squared error."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using LightGBM Dataset",
            "code": "import lightgbm as lgb\nimport numpy as np\nX = np.random.rand(100,5)\ny = np.random.randint(0,2,100)\ndtrain = lgb.Dataset(X, label=y)\nparams = {'objective': 'binary', 'metric': 'binary_logloss'}\nbst = lgb.train(params, dtrain, num_boost_round=20)",
            "explanation": "Uses LightGBM's Dataset class for efficient training."
          },
          {
            "title": "Early stopping",
            "code": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nX, y = load_iris(return_X_y=True)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = lgb.LGBMClassifier()\nmodel.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5)",
            "explanation": "Stops training early if the validation metric does not improve for a number of rounds."
          },
          {
            "title": "Feature importance",
            "code": "import matplotlib.pyplot as plt\nlgb.plot_importance(model)\nplt.show()",
            "explanation": "Visualizes feature importance after training the model."
          },
          {
            "title": "Custom evaluation metric",
            "code": "def f1_score_metric(y_true, y_pred):\n    from sklearn.metrics import f1_score\n    y_pred_labels = (y_pred > 0.5).astype(int)\n    return 'f1', f1_score(y_true, y_pred_labels), True\n\nmodel.fit(X_train, y_train, eval_set=[(X_val, y_val)], feval=f1_score_metric)",
            "explanation": "Demonstrates using a custom evaluation metric during training."
          }
        ],
        "best_practices": [
          "Use categorical features as category dtype for better performance.",
          "Tune hyperparameters like `num_leaves`, `max_depth`, `learning_rate`, and `n_estimators`.",
          "Use early stopping to avoid overfitting.",
          "Use GPU acceleration for large datasets when possible.",
          "Visualize feature importance to understand model decisions."
        ],
        "error_handling": [
          {
            "error": "LightGBMError: Check failed",
            "solution": "Ensure your data format and labels are correct. Use LightGBM Dataset for large datasets."
          },
          {
            "error": "ValueError: Input contains NaN",
            "solution": "Handle missing values with imputation or let LightGBM handle missing data natively."
          },
          {
            "error": "ImportError: No module named 'lightgbm'",
            "solution": "Install LightGBM using pip or conda in the current Python environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://lightgbm.readthedocs.io/",
        "github": "https://github.com/microsoft/LightGBM"
      }
    },
    {
      "id": "catboost",
      "name": "CatBoost",
      "category": "ML/AI",
      "description": "CatBoost is a high-performance gradient boosting library from Yandex that handles categorical features automatically and efficiently. It is designed for classification, regression, and ranking tasks with minimal preprocessing.",
      "story": "CatBoost was developed by Yandex in 2017 to provide an easy-to-use, fast, and accurate gradient boosting implementation that natively handles categorical variables. It reduces the need for extensive data preprocessing and is widely used in machine learning competitions and production systems.",
      "installation": {
        "pip": "pip install catboost",
        "conda": "conda install -c conda-forge catboost"
      },
      "usage": {
        "overview": "CatBoost can handle categorical and numerical features directly, supports GPU acceleration, and provides Python, R, and CLI interfaces. Models can be trained using `CatBoostClassifier` or `CatBoostRegressor` and can be evaluated with built-in metrics.",
        "basic_examples": [
          {
            "title": "Training a classifier",
            "code": "from catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris\n\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = CatBoostClassifier(verbose=0)\nmodel.fit(X_train, y_train)\nprint(model.score(X_test, y_test))",
            "explanation": "Trains a CatBoost classifier on the Iris dataset and evaluates accuracy."
          },
          {
            "title": "Training a regressor",
            "code": "from catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_boston\n\nX, y = load_boston(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel = CatBoostRegressor(verbose=0)\nmodel.fit(X_train, y_train)\nprint(model.score(X_test, y_test))",
            "explanation": "Trains a CatBoost regressor on the Boston housing dataset and evaluates performance."
          }
        ],
        "advanced_examples": [
          {
            "title": "Handling categorical features",
            "code": "from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(cat_features=[0,2,5], verbose=0)",
            "explanation": "Specifies categorical feature indices so CatBoost can handle them natively."
          },
          {
            "title": "Using Pool for efficient training",
            "code": "from catboost import Pool\ntrain_pool = Pool(X_train, y_train, cat_features=[0,2,5])\nmodel.fit(train_pool)",
            "explanation": "Uses CatBoost Pool object to efficiently store data and categorical features for training."
          },
          {
            "title": "Early stopping",
            "code": "model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=10)",
            "explanation": "Stops training early if validation metric does not improve for a specified number of rounds."
          },
          {
            "title": "Feature importance",
            "code": "import matplotlib.pyplot as plt\nfeature_importances = model.get_feature_importance()\nplt.bar(range(len(feature_importances)), feature_importances)\nplt.show()",
            "explanation": "Visualizes the importance of each feature after training the model."
          }
        ],
        "best_practices": [
          "Use CatBoost Pool to handle categorical features efficiently.",
          "Enable early stopping to prevent overfitting.",
          "Leverage GPU acceleration for large datasets.",
          "Use built-in evaluation metrics to monitor model performance.",
          "Tune hyperparameters such as `depth`, `learning_rate`, and `iterations` for optimal results."
        ],
        "error_handling": [
          {
            "error": "CatBoostError: Invalid feature index",
            "solution": "Ensure the specified categorical feature indices exist in the dataset."
          },
          {
            "error": "CatBoostError: GPU not available",
            "solution": "Install CatBoost with GPU support and ensure a compatible GPU is available."
          },
          {
            "error": "ModuleNotFoundError: No module named 'catboost'",
            "solution": "Install CatBoost using pip or conda in your current Python environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://catboost.ai/docs/",
        "github": "https://github.com/catboost/catboost"
      }
    },
    {
      "id": "transformers",
      "name": "Hugging Face Transformers",
      "category": "ML/AI",
      "description": "Transformers is a Python library developed by Hugging Face that provides state-of-the-art pre-trained models for Natural Language Processing (NLP) tasks such as text classification, translation, summarization, question answering, and more.",
      "story": "Hugging Face released Transformers in 2018 to simplify the use of transformer-based models like BERT, GPT, RoBERTa, and T5. The library provides easy access to pre-trained models and tokenizers, enabling developers and researchers to leverage powerful NLP models without extensive training or setup.",
      "installation": {
        "pip": "pip install transformers",
        "conda": "conda install -c conda-forge transformers"
      },
      "usage": {
        "overview": "Transformers provides pre-trained models that can be used directly for inference or fine-tuned on custom datasets. It supports PyTorch, TensorFlow, and JAX backends. The library also includes tokenizers, pipelines, and trainer APIs for streamlined workflows.",
        "basic_examples": [
          {
            "title": "Text classification with pipeline",
            "code": "from transformers import pipeline\nclassifier = pipeline('sentiment-analysis')\nresult = classifier('I love using Hugging Face Transformers!')\nprint(result)",
            "explanation": "Uses a pre-trained sentiment analysis model via a simple pipeline to classify the sentiment of text."
          },
          {
            "title": "Tokenizing text",
            "code": "from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\ninputs = tokenizer('Hello, Hugging Face!', return_tensors='pt')\nprint(inputs)",
            "explanation": "Uses a BERT tokenizer to convert text into token IDs suitable for model input."
          }
        ],
        "advanced_examples": [
          {
            "title": "Fine-tuning a pre-trained model",
            "code": "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Prepare dataset, tokenize, and create Trainer object\ntraining_args = TrainingArguments(output_dir='./results', num_train_epochs=1, per_device_train_batch_size=8)\ntrainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=eval_dataset)\ntrainer.train()",
            "explanation": "Shows fine-tuning a pre-trained BERT model for a custom classification task using the Trainer API."
          },
          {
            "title": "Question answering",
            "code": "from transformers import pipeline\nqa_pipeline = pipeline('question-answering')\ncontext = 'Hugging Face is creating a Transformers library.'\nquestion = 'Who is creating Transformers?'\nresult = qa_pipeline(question=question, context=context)\nprint(result)",
            "explanation": "Uses a pre-trained question-answering model to find answers in a given context."
          },
          {
            "title": "Text generation",
            "code": "from transformers import pipeline\ngenerator = pipeline('text-generation', model='gpt2')\nresult = generator('Once upon a time', max_length=50)\nprint(result)",
            "explanation": "Generates text continuations using a GPT-2 model."
          },
          {
            "title": "Summarization",
            "code": "from transformers import pipeline\nsummarizer = pipeline('summarization')\ntext = 'Hugging Face Transformers provides thousands of pre-trained models to perform tasks on texts, images, and audio.'\nsummary = summarizer(text, max_length=50, min_length=25, do_sample=False)\nprint(summary)",
            "explanation": "Uses a summarization pipeline to produce a condensed version of the input text."
          }
        ],
        "best_practices": [
          "Use pipelines for quick inference without dealing with tokenization and model objects directly.",
          "Fine-tune pre-trained models on custom datasets for better performance on specific tasks.",
          "Leverage GPU acceleration for large models and batch inference.",
          "Use the `AutoModel` and `AutoTokenizer` classes to easily switch between architectures.",
          "Keep track of model versions to ensure reproducibility."
        ],
        "error_handling": [
          {
            "error": "OSError: Model name 'xyz' was not found",
            "solution": "Check the model name on Hugging Face Hub or ensure it is correctly spelled."
          },
          {
            "error": "RuntimeError: CUDA out of memory",
            "solution": "Reduce batch size or move computations to CPU if GPU memory is insufficient."
          },
          {
            "error": "ValueError: Shape mismatch",
            "solution": "Ensure input tokens match the expected input shape for the model."
          }
        ]
      },
      "references": {
        "official_docs": "https://huggingface.co/docs/transformers/",
        "github": "https://github.com/huggingface/transformers"
      }
    },
    {
      "id": "openai-gym",
      "name": "OpenAI Gym",
      "category": "Reinforcement Learning",
      "description": "OpenAI Gym is a toolkit for developing and comparing reinforcement learning (RL) algorithms. It provides a wide variety of environments, from classic control problems and Atari games to robotics simulations, to test and benchmark RL agents.",
      "story": "OpenAI Gym was released by OpenAI in 2016 to standardize the process of developing and comparing reinforcement learning algorithms. Its modular design and extensive suite of environments have made it a key tool for researchers and practitioners in the RL community.",
      "installation": {
        "pip": "pip install gym",
        "conda": "conda install -c conda-forge gym"
      },
      "usage": {
        "overview": "OpenAI Gym provides a unified interface for all environments. Agents interact with environments by taking actions and receiving observations and rewards. The library supports vectorized environments, wrappers, and custom environment creation.",
        "basic_examples": [
          {
            "title": "Basic environment interaction",
            "code": "import gym\nenv = gym.make('CartPole-v1')\nobs = env.reset()\nfor _ in range(100):\n    env.render()\n    action = env.action_space.sample()\n    obs, reward, done, info = env.step(action)\n    if done:\n        obs = env.reset()\nenv.close()",
            "explanation": "Creates the CartPole-v1 environment, samples random actions, and renders the environment while interacting with it."
          },
          {
            "title": "Inspecting action and observation spaces",
            "code": "import gym\nenv = gym.make('MountainCar-v0')\nprint(env.action_space)\nprint(env.observation_space)",
            "explanation": "Shows the possible actions the agent can take and the shape/range of observations."
          }
        ],
        "advanced_examples": [
          {
            "title": "Custom environment wrapper",
            "code": "from gym import Wrapper\n\nclass NormalizeWrapper(Wrapper):\n    def step(self, action):\n        obs, reward, done, info = self.env.step(action)\n        obs = obs / 10.0  # simple normalization example\n        return obs, reward, done, info\n\nenv = gym.make('CartPole-v1')\nenv = NormalizeWrapper(env)",
            "explanation": "Demonstrates creating a custom wrapper to preprocess observations or modify rewards."
          },
          {
            "title": "Vectorized environments",
            "code": "from gym.vector import SyncVectorEnv\nimport gym\n\ndef make_env():\n    return gym.make('CartPole-v1')\n\nenv = SyncVectorEnv([make_env for _ in range(4)])\nobs = env.reset()\nprint(obs.shape)",
            "explanation": "Runs multiple environments in parallel to speed up training of RL agents."
          },
          {
            "title": "Seeding environments for reproducibility",
            "code": "env = gym.make('CartPole-v1')\nenv.seed(42)\nimport numpy as np\nnp.random.seed(42)",
            "explanation": "Sets seeds for the environment and NumPy to ensure reproducible results."
          }
        ],
        "best_practices": [
          "Always call `env.close()` after finishing to release resources.",
          "Use environment wrappers to preprocess observations and rewards.",
          "Vectorize environments to improve training efficiency for RL agents.",
          "Monitor environment performance using `gym.wrappers.Monitor`.",
          "Set seeds for reproducibility when experimenting with algorithms."
        ],
        "error_handling": [
          {
            "error": "Error: Environment ID not found",
            "solution": "Ensure the environment name passed to `gym.make()` is correct and installed."
          },
          {
            "error": "Action out of bounds",
            "solution": "Make sure the action is within the range defined by `env.action_space`."
          },
          {
            "error": "Observation dimension mismatch",
            "solution": "Check that your agent handles the correct observation shape from `env.observation_space`."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.gymlibrary.ml/",
        "github": "https://github.com/openai/gym"
      }
    },
    {
      "id": "fastai",
      "name": "FastAI",
      "category": "ML/AI",
      "description": "FastAI is a high-level deep learning library built on top of PyTorch, designed to make training neural networks fast, accurate, and accessible. It provides abstractions and best practices for vision, text, tabular, and collaborative filtering tasks.",
      "story": "FastAI was created by Jeremy Howard and Rachel Thomas in 2018 to simplify deep learning workflows while retaining flexibility. It emphasizes practical, hands-on learning, and is widely used in both research and production for rapid prototyping of AI models.",
      "installation": {
        "pip": "pip install fastai",
        "conda": "conda install -c fastai fastai"
      },
      "usage": {
        "overview": "FastAI provides high-level APIs for building, training, and interpreting models with minimal boilerplate. It integrates with PyTorch for low-level control and includes utilities for data preprocessing, augmentation, and visualization.",
        "basic_examples": [
          {
            "title": "Image classification with a pre-trained model",
            "code": "from fastai.vision.all import *\npath = untar_data(URLs.PETS)\ndls = ImageDataLoaders.from_name_re(path, get_image_files(path/'images'), pat=r'(.+)_\\d+.jpg$', item_tfms=Resize(224))\nlearn = vision_learner(dls, resnet34, metrics=accuracy)\nlearn.fine_tune(1)",
            "explanation": "Loads a pet image dataset, creates data loaders, defines a ResNet34 model, and fine-tunes it for one epoch."
          },
          {
            "title": "Text classification",
            "code": "from fastai.text.all import *\ndls = TextDataLoaders.from_csv(path, 'texts.csv', text_col='text', label_col='label')\nlearn = text_classifier_learner(dls, AWD_LSTM, metrics=accuracy)\nlearn.fine_tune(1)",
            "explanation": "Loads text data from CSV, creates a data loader, defines an AWD_LSTM model, and fine-tunes it."
          }
        ],
        "advanced_examples": [
          {
            "title": "Tabular data modeling",
            "code": "from fastai.tabular.all import *\ndf = pd.read_csv('data.csv')\nsplits = RandomSplitter()(range_of(df))\ntb = TabularPandas(df, y_names='target', cat_names=['cat1','cat2'], cont_names=['cont1','cont2'], procs=[Categorify, FillMissing, Normalize], splits=splits)\ndls = tb.dataloaders()\nlearn = tabular_learner(dls, metrics=accuracy)\nlearn.fit_one_cycle(5)",
            "explanation": "Prepares tabular data with categorical and continuous columns, applies preprocessing, and trains a tabular model."
          },
          {
            "title": "Collaborative filtering",
            "code": "from fastai.collab import *\ndf = pd.read_csv('ratings.csv')\ndls = CollabDataLoaders.from_df(df, item_name='movie', user_name='user', rating_name='rating')\nlearn = collab_learner(dls, n_factors=50, y_range=(0,5.5))\nlearn.fit_one_cycle(5)",
            "explanation": "Uses FastAI to build a collaborative filtering model for predicting ratings."
          },
          {
            "title": "Learning rate finder",
            "code": "learn.lr_find()",
            "explanation": "Plots a learning rate curve to help select an optimal learning rate for training."
          },
          {
            "title": "Model interpretation",
            "code": "interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()",
            "explanation": "Generates a confusion matrix to analyze model predictions."
          }
        ],
        "best_practices": [
          "Use pre-trained models for transfer learning when possible.",
          "Use `fit_one_cycle` for efficient and stable training.",
          "Leverage FastAI's data block API for flexible data preprocessing.",
          "Visualize results and errors using built-in interpretation methods.",
          "Combine FastAI with PyTorch for full control over model architecture."
        ],
        "error_handling": [
          {
            "error": "RuntimeError: CUDA out of memory",
            "solution": "Reduce batch size or move computation to CPU if GPU memory is insufficient."
          },
          {
            "error": "ValueError: DataLoader empty",
            "solution": "Check that your dataset paths and preprocessing steps are correct."
          },
          {
            "error": "ModuleNotFoundError: No module named 'fastai'",
            "solution": "Install FastAI using pip or conda in your current Python environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.fast.ai/",
        "github": "https://github.com/fastai/fastai"
      }
    },
    {
      "id": "scikit-image",
      "name": "scikit-image",
      "category": "Data Science",
      "description": "scikit-image is a Python library for image processing that provides a collection of algorithms for segmentation, geometric transformations, color space manipulation, filtering, morphology, feature detection, and more.",
      "story": "scikit-image was developed as part of the scikit-learn ecosystem to provide easy-to-use image processing tools in Python. It integrates closely with NumPy arrays and scientific Python libraries, making it popular for academic research, prototyping, and real-world image processing applications.",
      "installation": {
        "pip": "pip install scikit-image",
        "conda": "conda install -c conda-forge scikit-image"
      },
      "usage": {
        "overview": "scikit-image provides functions for reading and writing images, performing geometric and color transformations, applying filters, detecting features, and extracting image statistics. It works seamlessly with NumPy arrays for numerical computations and can be combined with Matplotlib for visualization.",
        "basic_examples": [
          {
            "title": "Reading and displaying an image",
            "code": "from skimage import io\nimg = io.imread('image.jpg')\nio.imshow(img)\nio.show()",
            "explanation": "Reads an image from a file and displays it using scikit-image’s I/O functions."
          },
          {
            "title": "Converting to grayscale",
            "code": "from skimage.color import rgb2gray\ngray_img = rgb2gray(img)\nio.imshow(gray_img)\nio.show()",
            "explanation": "Converts an RGB image to grayscale using `rgb2gray`."
          }
        ],
        "advanced_examples": [
          {
            "title": "Edge detection using Canny",
            "code": "from skimage import feature\nedges = feature.canny(gray_img)\nio.imshow(edges)\nio.show()",
            "explanation": "Detects edges in a grayscale image using the Canny algorithm."
          },
          {
            "title": "Resizing an image",
            "code": "from skimage.transform import resize\nresized_img = resize(img, (200, 200))\nio.imshow(resized_img)\nio.show()",
            "explanation": "Resizes the input image to 200x200 pixels."
          },
          {
            "title": "Applying a Gaussian filter",
            "code": "from skimage.filters import gaussian\nsmoothed_img = gaussian(gray_img, sigma=1)\nio.imshow(smoothed_img)\nio.show()",
            "explanation": "Applies Gaussian smoothing to reduce noise in an image."
          },
          {
            "title": "Labeling connected components",
            "code": "from skimage.measure import label\nlabeled_img = label(gray_img > 0.5)\nio.imshow(labeled_img)\nio.show()",
            "explanation": "Labels connected regions in a binary image."
          }
        ],
        "best_practices": [
          "Use NumPy arrays as the primary image representation for efficiency.",
          "Normalize images to float in [0, 1] when using scikit-image filters.",
          "Leverage built-in visualization functions or Matplotlib for displaying results.",
          "Use modular functions to chain processing steps cleanly.",
          "Handle images with varying shapes and channels appropriately."
        ],
        "error_handling": [
          {
            "error": "ValueError: image dtype not supported",
            "solution": "Convert images to supported dtypes (e.g., float or uint8) using `img_as_float` or `img_as_ubyte`."
          },
          {
            "error": "IndexError: tuple index out of range",
            "solution": "Check the image shape and ensure operations are applied to valid dimensions."
          },
          {
            "error": "ImportError: No module named 'skimage'",
            "solution": "Install scikit-image using pip or conda in your current Python environment."
          }
        ]
      },
      "references": {
        "official_docs": "https://scikit-image.org/docs/stable/",
        "github": "https://github.com/scikit-image/scikit-image"
      }
    },
    {
      "id": "imageio",
      "name": "ImageIO",
      "category": "Data Science",
      "description": "ImageIO is a Python library that provides an easy interface to read and write images in a wide range of formats, including PNG, JPEG, BMP, GIF, TIFF, and more. It also supports reading and writing video files and volumetric data.",
      "story": "ImageIO was developed to unify the reading and writing of images and videos in Python with a simple and consistent API. It is widely used in scientific computing, machine learning, and multimedia applications for processing image and video data.",
      "installation": {
        "pip": "pip install imageio",
        "conda": "conda install -c conda-forge imageio"
      },
      "usage": {
        "overview": "ImageIO allows you to read, write, and process images and videos using NumPy arrays. It provides a simple API to load images into arrays, perform operations, and save results. Plugins are available for handling different formats and compression options.",
        "basic_examples": [
          {
            "title": "Reading an image",
            "code": "import imageio\nimg = imageio.imread('example.png')\nprint(img.shape)",
            "explanation": "Reads an image from a file and loads it as a NumPy array."
          },
          {
            "title": "Writing an image",
            "code": "import imageio\nimageio.imwrite('output.png', img)",
            "explanation": "Saves a NumPy array as an image file."
          }
        ],
        "advanced_examples": [
          {
            "title": "Reading a video",
            "code": "import imageio\nreader = imageio.get_reader('video.mp4')\nfor frame in reader:\n    print(frame.shape)\nreader.close()",
            "explanation": "Reads frames from a video file and prints their dimensions."
          },
          {
            "title": "Writing a video",
            "code": "import imageio\nwriter = imageio.get_writer('output.mp4', fps=24)\nfor frame in frames:  # frames is a list of NumPy arrays\n    writer.append_data(frame)\nwriter.close()",
            "explanation": "Writes a series of frames (NumPy arrays) to a video file at 24 FPS."
          },
          {
            "title": "Reading images from URLs",
            "code": "import imageio\nimg = imageio.imread('https://example.com/image.jpg')",
            "explanation": "Directly reads an image from a web URL into a NumPy array."
          },
          {
            "title": "Using plugins for format-specific options",
            "code": "import imageio\nimg = imageio.imread('example.tiff', format='TIFF')",
            "explanation": "Specifies a plugin format explicitly when reading an image to handle special format options."
          }
        ],
        "best_practices": [
          "Use NumPy arrays for all image and video processing for efficiency.",
          "Close readers and writers properly to free resources.",
          "Specify formats explicitly when needed to avoid ambiguities.",
          "Use plugins for advanced format handling (e.g., TIFF, GIF, DICOM).",
          "Combine ImageIO with libraries like NumPy, OpenCV, or PIL for processing pipelines."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundError",
            "solution": "Ensure the file path exists and is accessible."
          },
          {
            "error": "ValueError: Cannot identify image file",
            "solution": "Check that the file format is supported or specify the format explicitly."
          },
          {
            "error": "RuntimeError: Cannot write frames",
            "solution": "Ensure that the writer is opened properly and frames are valid NumPy arrays with correct shape and dtype."
          }
        ]
      },
      "references": {
        "official_docs": "https://imageio.readthedocs.io/en/stable/",
        "github": "https://github.com/imageio/imageio"
      }
    },
    {
      "id": "dlib",
      "name": "dlib",
      "category": "ML/AI",
      "description": "dlib is a modern C++ toolkit with Python bindings for machine learning and computer vision tasks. It includes algorithms for image processing, object detection, facial landmark detection, and general-purpose machine learning.",
      "story": "dlib was created by Davis King to provide a toolkit for making real-world machine learning and computer vision applications. It is widely used for facial recognition, object tracking, and other vision-related tasks due to its performance, accuracy, and extensive feature set.",
      "installation": {
        "pip": "pip install dlib",
        "conda": "conda install -c conda-forge dlib"
      },
      "usage": {
        "overview": "dlib provides functions for image I/O, feature extraction, object detection, machine learning algorithms, and tools for linear algebra. It supports both CPU and GPU acceleration for high-performance computations.",
        "basic_examples": [
          {
            "title": "Loading and displaying an image",
            "code": "import dlib\nfrom skimage import io\nimg = io.imread('image.jpg')\ndlib.imshow(img)",
            "explanation": "Loads an image using skimage and displays it using dlib's simple image viewer."
          },
          {
            "title": "Face detection",
            "code": "import dlib\nfrom skimage import io\nimg = io.imread('faces.jpg')\ndetector = dlib.get_frontal_face_detector()\ndets = detector(img, 1)\nfor i, d in enumerate(dets):\n    print(f'Face {i}: Left: {d.left()} Top: {d.top()} Right: {d.right()} Bottom: {d.bottom()}')",
            "explanation": "Detects faces in an image using dlib’s frontal face detector and prints bounding box coordinates."
          }
        ],
        "advanced_examples": [
          {
            "title": "Facial landmarks detection",
            "code": "import dlib\nfrom skimage import io\nimg = io.imread('face.jpg')\ndetector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\ndets = detector(img, 1)\nfor d in dets:\n    shape = predictor(img, d)\n    for i in range(68):\n        print(f'Landmark {i}: ({shape.part(i).x}, {shape.part(i).y})')",
            "explanation": "Detects facial landmarks using a pre-trained 68-point shape predictor."
          },
          {
            "title": "Training a simple SVM classifier",
            "code": "import dlib\n# Example with feature vectors\nX_train, y_train = [...], [...]\nsvm = dlib.svm_c_linear_trainer()\nclassifier = svm.train(X_train, y_train)",
            "explanation": "Uses dlib’s SVM trainer to fit a linear classifier on training data."
          },
          {
            "title": "Object detection with HOG features",
            "code": "import dlib\nfrom skimage import io\nimg = io.imread('image.jpg')\ndetector = dlib.simple_object_detector('detector.svm')\ndets = detector(img)\nfor d in dets:\n    print(f'Object found at: {d}')",
            "explanation": "Loads a pre-trained object detector and detects objects in an image using HOG features."
          },
          {
            "title": "Face recognition using embeddings",
            "code": "import dlib\nface_rec_model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n# Use detected face rectangles to compute 128D embeddings",
            "explanation": "Computes 128-dimensional embeddings for detected faces for recognition tasks."
          }
        ],
        "best_practices": [
          "Use dlib’s pre-trained models for face detection and recognition for accuracy and efficiency.",
          "Convert images to RGB if they are loaded in a different color space to avoid detection errors.",
          "Leverage GPU acceleration when training custom models for faster performance.",
          "Use HOG-based detection for faster CPU-based inference and CNN detectors for higher accuracy.",
          "Always handle exceptions for file paths and model loading."
        ],
        "error_handling": [
          {
            "error": "RuntimeError: Unable to open file",
            "solution": "Ensure the image or model file path is correct and the file exists."
          },
          {
            "error": "ModuleNotFoundError: No module named 'dlib'",
            "solution": "Install dlib using pip or conda in your current Python environment."
          },
          {
            "error": "ValueError: input image is empty",
            "solution": "Check that the image file is not corrupted and loaded correctly using skimage or OpenCV."
          }
        ]
      },
      "references": {
        "official_docs": "http://dlib.net/python/index.html",
        "github": "https://github.com/davisking/dlib"
      }
    },
    {
      "id": "loguru",
      "name": "Loguru",
      "category": "CLI/Utils",
      "description": "Loguru is a Python library that simplifies logging by providing an easy-to-use, flexible, and powerful logging system. It reduces boilerplate code and adds features like sink management, message formatting, and exception catching.",
      "story": "Loguru was created by Delgan in 2017 to offer a simpler, more intuitive logging experience than Python's built-in `logging` module. It aims to streamline logging setup and usage while providing advanced capabilities such as structured logging, colored outputs, and file rotation.",
      "installation": {
        "pip": "pip install loguru",
        "conda": "conda install -c conda-forge loguru"
      },
      "usage": {
        "overview": "Loguru allows you to log messages with various severity levels, format logs with colors, redirect logs to files, and catch exceptions automatically. It supports both synchronous and asynchronous applications and can be easily integrated into existing projects.",
        "basic_examples": [
          {
            "title": "Simple logging",
            "code": "from loguru import logger\n\nlogger.info('This is an info message')\nlogger.warning('This is a warning')",
            "explanation": "Logs messages at different severity levels (info, warning) with minimal setup."
          },
          {
            "title": "Logging to a file",
            "code": "from loguru import logger\n\nlogger.add('file.log')\nlogger.info('This message is saved to a file')",
            "explanation": "Redirects log output to a file, creating it automatically if it doesn’t exist."
          }
        ],
        "advanced_examples": [
          {
            "title": "Custom formatting",
            "code": "from loguru import logger\n\nlogger.add('file.log', format='{time} | {level} | {message}', level='INFO')\nlogger.info('Custom formatted log')",
            "explanation": "Uses a custom log format including time, severity level, and message."
          },
          {
            "title": "Rotating log files",
            "code": "from loguru import logger\n\nlogger.add('file_{time}.log', rotation='1 MB')\nlogger.info('This log will rotate after reaching 1 MB')",
            "explanation": "Automatically rotates log files when they reach a specified size."
          },
          {
            "title": "Catching exceptions",
            "code": "from loguru import logger\n\n@logger.catch\ndef faulty():\n    x = 1 / 0\n\nfaulty()",
            "explanation": "Automatically catches exceptions in functions, logs stack traces, and prevents application crash."
          },
          {
            "title": "Multiple sinks",
            "code": "from loguru import logger\n\nlogger.add('file.log')\nlogger.add(sys.stderr, colorize=True, format='<green>{time}</green> | {level} | {message>')\nlogger.info('Logged to both file and console')",
            "explanation": "Logs messages to multiple outputs (file and console) with independent formatting."
          }
        ],
        "best_practices": [
          "Use `logger.add()` to manage multiple log destinations and formats.",
          "Use `@logger.catch` to simplify exception handling and logging.",
          "Set appropriate log levels for different environments (DEBUG for development, WARNING/ERROR for production).",
          "Rotate and compress log files to prevent storage issues.",
          "Avoid excessive logging in performance-critical code sections."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundError",
            "solution": "Ensure the specified log file path exists or use a valid path."
          },
          {
            "error": "PermissionError",
            "solution": "Check file permissions and ensure the application can write to the log file."
          }
        ]
      },
      "references": {
        "official_docs": "https://loguru.readthedocs.io/",
        "github": "https://github.com/Delgan/loguru"
      }
    },
    {
      "id": "python-fire",
      "name": "Python Fire",
      "category": "CLI/Utils",
      "description": "Python Fire is a library for automatically generating command-line interfaces (CLIs) from any Python object, such as functions, classes, or dictionaries. It enables rapid CLI creation without boilerplate code.",
      "story": "Python Fire was created by Google in 2017 to make it easy to turn existing Python code into CLI tools. It allows developers to quickly expose functionality without writing repetitive argument parsing code, making it popular for scripting, automation, and testing.",
      "installation": {
        "pip": "pip install fire",
        "conda": "conda install -c conda-forge python-fire"
      },
      "usage": {
        "overview": "Python Fire generates a CLI automatically from Python code. It parses command-line arguments and maps them to function parameters, class methods, or dictionary keys. It supports nested objects and provides help and error messages automatically.",
        "basic_examples": [
          {
            "title": "Creating a CLI from a function",
            "code": "import fire\n\ndef greet(name='World'):\n    return f'Hello, {name}!'\n\nif __name__ == '__main__':\n    fire.Fire(greet)",
            "explanation": "Generates a command-line interface where you can run `python script.py --name Alice` to print `Hello, Alice!`."
          },
          {
            "title": "Creating a CLI from a class",
            "code": "import fire\n\nclass Calculator:\n    def add(self, x, y):\n        return x + y\n\nif __name__ == '__main__':\n    fire.Fire(Calculator)",
            "explanation": "Generates a CLI from the `Calculator` class. You can run `python script.py add 3 5` to get `8`."
          }
        ],
        "advanced_examples": [
          {
            "title": "Nested commands",
            "code": "import fire\n\nclass Math:\n    class Operations:\n        @staticmethod\n        def multiply(x, y):\n            return x * y\n\nif __name__ == '__main__':\n    fire.Fire(Math)",
            "explanation": "Supports nested objects. You can run `python script.py Operations multiply 3 4` to get `12`."
          },
          {
            "title": "Using dictionaries",
            "code": "import fire\n\nconfig = {\n    'host': 'localhost',\n    'port': 8080\n}\n\nif __name__ == '__main__':\n    fire.Fire(config)",
            "explanation": "Exposes a dictionary as a CLI. Running `python script.py host` prints `localhost`."
          },
          {
            "title": "Customizing CLI behavior",
            "code": "import fire\n\nclass App:\n    def run(self, debug=False):\n        print(f'Running app with debug={debug}')\n\nif __name__ == '__main__':\n    fire.Fire(App)",
            "explanation": "Supports flags and optional arguments. Running `python script.py run --debug True` enables debug mode."
          }
        ],
        "best_practices": [
          "Use Python Fire for quick CLI tools without manually parsing arguments.",
          "Avoid exposing sensitive functions or credentials via Fire CLIs.",
          "Keep CLI entry points simple and delegate complex logic to underlying functions or classes.",
          "Use docstrings to provide helpful documentation for automatically generated CLI help.",
          "Combine Fire with logging or exception handling for robust command-line tools."
        ],
        "error_handling": [
          {
            "error": "TypeError: Missing required positional argument",
            "solution": "Ensure that all required function parameters are provided in the CLI call."
          },
          {
            "error": "FireError: Unsupported type",
            "solution": "Python Fire may not handle certain types; convert objects to standard Python types (str, int, float, list, dict) before exposing."
          }
        ]
      },
      "references": {
        "official_docs": "https://github.com/google/python-fire",
        "github": "https://github.com/google/python-fire"
      }
    },
    {
      "id": "invoke",
      "name": "Invoke",
      "category": "CLI/Utils",
      "description": "Invoke is a Python task execution library that provides a clean, high-level API for defining and running shell-oriented tasks from Python scripts. It is designed to help automate repetitive workflows, build processes, and command-line operations.",
      "story": "Invoke was created by the same team behind Fabric to provide a standalone Pythonic task execution tool. It simplifies running and organizing shell commands, tasks, and workflows in a maintainable way, allowing developers to automate build systems, deployment scripts, and other routine tasks.",
      "installation": {
        "pip": "pip install invoke",
        "conda": "conda install -c conda-forge invoke"
      },
      "usage": {
        "overview": "Invoke allows you to define tasks as Python functions and execute them via the command line. Tasks can accept arguments, run shell commands, and be organized hierarchically. It provides features like namespaces, command-line parsing, and pre/post task hooks.",
        "basic_examples": [
          {
            "title": "Defining a simple task",
            "code": "from invoke import task\n\n@task\ndef hello(c):\n    print('Hello, Invoke!')",
            "explanation": "Defines a simple task named `hello`. Tasks are decorated with `@task` and receive a context `c` for running commands."
          },
          {
            "title": "Running a task from the CLI",
            "code": "# Terminal command:\n# inv hello",
            "explanation": "Executes the `hello` task defined in `tasks.py` using the `inv` command-line tool."
          }
        ],
        "advanced_examples": [
          {
            "title": "Task with arguments",
            "code": "from invoke import task\n\n@task\ndef greet(c, name='World'):\n    print(f'Hello, {name}!')",
            "explanation": "Defines a task that accepts an argument `name`. You can call it with `inv greet --name=Alice`."
          },
          {
            "title": "Running shell commands",
            "code": "from invoke import task\n\n@task\ndef list_files(c):\n    c.run('ls -l')",
            "explanation": "Uses the context `c` to run shell commands directly from a task."
          },
          {
            "title": "Task namespaces",
            "code": "from invoke import Collection, task\n\n@task\ndef clean(c):\n    c.run('rm -rf build/')\n\nns = Collection()\nns.add_task(clean, 'clean')",
            "explanation": "Organizes tasks into namespaces for better project structure and management."
          },
          {
            "title": "Pre/post task hooks",
            "code": "from invoke import task\n\n@task(pre=[setup])\ndef build(c):\n    c.run('make')",
            "explanation": "Executes a `setup` task automatically before running the `build` task."
          }
        ],
        "best_practices": [
          "Keep tasks small and modular for clarity and maintainability.",
          "Use namespaces to group related tasks together.",
          "Use context (`c`) to run shell commands instead of using `os.system`.",
          "Document tasks with docstrings so that `inv --list` provides helpful descriptions.",
          "Combine with version control and CI/CD pipelines to automate build and deployment workflows."
        ],
        "error_handling": [
          {
            "error": "invoke.exceptions.Exit",
            "solution": "Occurs when a shell command executed via `c.run()` exits with a non-zero status. Handle by using `warn=True` or try/except."
          },
          {
            "error": "NameError: name 'task' is not defined",
            "solution": "Ensure `from invoke import task` is included at the top of your tasks file."
          },
          {
            "error": "No tasks found",
            "solution": "Make sure the tasks are defined in a `tasks.py` file or properly added to a namespace and the `inv` command is run in the correct directory."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.pyinvoke.org/",
        "github": "https://github.com/pyinvoke/invoke"
      }
    },
    {
      "id": "pyinquirer",
      "name": "PyInquirer",
      "category": "CLI/Utils",
      "description": "PyInquirer is a Python library that enables the creation of beautiful, interactive command-line interfaces with prompts, lists, checkboxes, and other input types inspired by Inquirer.js.",
      "story": "PyInquirer was created as a Python adaptation of the popular Inquirer.js library for Node.js. It allows developers to easily build interactive CLIs, making terminal-based tools more user-friendly and visually appealing.",
      "installation": {
        "pip": "pip install PyInquirer",
        "conda": "conda install -c conda-forge pyinquirer"
      },
      "usage": {
        "overview": "PyInquirer provides different types of prompts such as input, confirm, list, checkbox, password, and rawlist. It supports nested questions, validation, and default values, enabling interactive CLI experiences.",
        "basic_examples": [
          {
            "title": "Simple input prompt",
            "code": "from PyInquirer import prompt\n\nquestions = [{\n    'type': 'input',\n    'name': 'username',\n    'message': 'Enter your username:'\n}]\nanswers = prompt(questions)\nprint(answers['username'])",
            "explanation": "Prompts the user to enter a username and prints the input."
          },
          {
            "title": "Confirm prompt",
            "code": "from PyInquirer import prompt\n\nquestions = [{\n    'type': 'confirm',\n    'name': 'continue',\n    'message': 'Do you want to continue?',\n    'default': True\n}]\nanswers = prompt(questions)\nprint(answers['continue'])",
            "explanation": "Asks a yes/no question and returns True or False."
          }
        ],
        "advanced_examples": [
          {
            "title": "List selection",
            "code": "from PyInquirer import prompt\n\nquestions = [{\n    'type': 'list',\n    'name': 'color',\n    'message': 'Pick a color:',\n    'choices': ['Red', 'Green', 'Blue']\n}]\nanswers = prompt(questions)\nprint(answers['color'])",
            "explanation": "Displays a list of options and lets the user select one."
          },
          {
            "title": "Checkbox selection",
            "code": "from PyInquirer import prompt\n\nquestions = [{\n    'type': 'checkbox',\n    'name': 'features',\n    'message': 'Select features:',\n    'choices': [\n        {'name': 'Feature A'},\n        {'name': 'Feature B'},\n        {'name': 'Feature C'}\n    ]\n}]\nanswers = prompt(questions)\nprint(answers['features'])",
            "explanation": "Allows multiple selections from a list using checkboxes."
          },
          {
            "title": "Validation example",
            "code": "from PyInquirer import prompt\n\nquestions = [{\n    'type': 'input',\n    'name': 'age',\n    'message': 'Enter your age:',\n    'validate': lambda val: val.isdigit() or 'Please enter a number'\n}]\nanswers = prompt(questions)\nprint(answers['age'])",
            "explanation": "Validates user input; here it ensures the input is numeric."
          },
          {
            "title": "Nested questions",
            "code": "from PyInquirer import prompt\n\nquestions = [{\n    'type': 'input',\n    'name': 'name',\n    'message': 'What is your name?'\n}, {\n    'type': 'confirm',\n    'name': 'confirm',\n    'message': 'Is that correct?'\n}]\nanswers = prompt(questions)\nprint(answers)",
            "explanation": "Shows multiple questions sequentially and collects responses in a dictionary."
          }
        ],
        "best_practices": [
          "Use descriptive messages for prompts to improve user experience.",
          "Validate inputs to avoid invalid data.",
          "Group related questions for clarity.",
          "Use defaults when appropriate to simplify the workflow.",
          "Keep the interface simple and intuitive for command-line users."
        ],
        "error_handling": [
          {
            "error": "EOFError",
            "solution": "Occurs when input stream is closed unexpectedly. Ensure the terminal is interactive and supports input."
          },
          {
            "error": "KeyboardInterrupt",
            "solution": "Handle user interruption gracefully by wrapping prompts in try/except blocks."
          }
        ]
      },
      "references": {
        "official_docs": "https://github.com/CITGuru/PyInquirer",
        "github": "https://github.com/CITGuru/PyInquirer"
      }
    },
    {
      "id": "mechanize",
      "name": "Mechanize",
      "category": "Web",
      "description": "Mechanize is a Python library for stateful programmatic web browsing. It allows you to automate interaction with websites, including filling forms, clicking links, and handling cookies and sessions, similar to a web browser.",
      "story": "Mechanize was created as a Python port of Perl’s Mechanize module, enabling automated browsing and web scraping in Python. It is particularly useful for automating repetitive web tasks or interacting with websites that require form submissions.",
      "installation": {
        "pip": "pip install mechanize",
        "conda": "conda install -c conda-forge mechanize"
      },
      "usage": {
        "overview": "Mechanize provides a browser-like interface in Python. You can navigate pages, select forms, fill them out, submit them, and retrieve responses. It supports handling cookies, redirects, and headers automatically.",
        "basic_examples": [
          {
            "title": "Opening a webpage",
            "code": "import mechanize\nbr = mechanize.Browser()\nbr.open('http://example.com')\nprint(br.title())",
            "explanation": "Creates a Mechanize browser instance, opens a URL, and prints the page title."
          },
          {
            "title": "Following a link",
            "code": "link = br.find_link(text='More information')\nbr.follow_link(link)\nprint(br.geturl())",
            "explanation": "Finds a link by its text and navigates to the linked page."
          }
        ],
        "advanced_examples": [
          {
            "title": "Filling and submitting a form",
            "code": "br.select_form(nr=0)\nbr['username'] = 'myuser'\nbr['password'] = 'mypassword'\nbr.submit()",
            "explanation": "Selects the first form on the page, fills in username and password fields, and submits the form."
          },
          {
            "title": "Handling cookies",
            "code": "br.set_cookiejar(mechanize.CookieJar())\nbr.open('http://example.com')",
            "explanation": "Enables cookie handling to maintain sessions across multiple requests."
          },
          {
            "title": "Setting headers",
            "code": "br.addheaders = [('User-agent', 'Mozilla/5.0')]\nbr.open('http://example.com')",
            "explanation": "Adds a custom User-Agent header to mimic a real browser."
          },
          {
            "title": "Handling redirects",
            "code": "br.set_handle_redirect(True)\nbr.open('http://example.com')",
            "explanation": "Ensures the browser automatically follows HTTP redirects."
          }
        ],
        "best_practices": [
          "Always set a User-Agent to avoid being blocked by websites.",
          "Use CookieJar to manage sessions when scraping multiple pages.",
          "Avoid scraping websites without permission; respect robots.txt.",
          "Use proper exception handling for HTTP errors and timeouts.",
          "Combine Mechanize with BeautifulSoup for parsing page content efficiently."
        ],
        "error_handling": [
          {
            "error": "mechanize.HTTPError",
            "solution": "Check the response status code and ensure the URL is correct."
          },
          {
            "error": "mechanize.URLError",
            "solution": "Verify network connectivity and the validity of the URL."
          },
          {
            "error": "mechanize.LinkNotFoundError",
            "solution": "Ensure the link text exists on the page or use different selection criteria."
          }
        ]
      },
      "references": {
        "official_docs": "https://mechanize.readthedocs.io/",
        "github": "https://github.com/python-mechanize/mechanize"
      }
    },
    {
      "id": "playwright-python",
      "name": "Playwright-Python",
      "category": "Web Automation",
      "description": "Playwright-Python is a Python library for automating web browsers. It enables end-to-end testing, web scraping, and browser automation across Chromium, Firefox, and WebKit with a single API.",
      "story": "Playwright was developed by Microsoft to provide a reliable and fast automation library for testing modern web applications. The Python bindings allow developers to use Playwright's cross-browser capabilities, including headless and headful modes, to automate interactions with web pages.",
      "installation": {
        "pip": "pip install playwright\nplaywright install",
        "conda": "conda install -c conda-forge playwright"
      },
      "usage": {
        "overview": "Playwright allows you to launch browsers, navigate pages, interact with elements, capture screenshots, and evaluate JavaScript code. It supports synchronous and asynchronous APIs and provides robust mechanisms for waiting, network interception, and handling popups or frames.",
        "basic_examples": [
          {
            "title": "Opening a page and taking a screenshot",
            "code": "from playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True)\n    page = browser.new_page()\n    page.goto('https://example.com')\n    page.screenshot(path='example.png')\n    browser.close()",
            "explanation": "Launches a Chromium browser in headless mode, navigates to a URL, takes a screenshot, and closes the browser."
          },
          {
            "title": "Clicking a button",
            "code": "from playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch()\n    page = browser.new_page()\n    page.goto('https://example.com')\n    page.click('text=More information')\n    browser.close()",
            "explanation": "Navigates to a page and clicks a button or link with the text 'More information'."
          }
        ],
        "advanced_examples": [
          {
            "title": "Filling a form and submitting",
            "code": "from playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch()\n    page = browser.new_page()\n    page.goto('https://example.com/login')\n    page.fill('#username', 'myuser')\n    page.fill('#password', 'mypassword')\n    page.click('#login')\n    browser.close()",
            "explanation": "Fills a login form using selectors and submits it."
          },
          {
            "title": "Waiting for elements",
            "code": "page.goto('https://example.com')\npage.wait_for_selector('#content')",
            "explanation": "Waits until the specified element appears in the DOM before continuing."
          },
          {
            "title": "Handling popups",
            "code": "page.on('dialog', lambda dialog: dialog.accept())\npage.click('#open-popup')",
            "explanation": "Listens for dialog popups and automatically accepts them."
          },
          {
            "title": "Extracting page content",
            "code": "content = page.inner_text('#main')\nprint(content)",
            "explanation": "Extracts the text content of a specific element on the page."
          }
        ],
        "best_practices": [
          "Use synchronous API for simple scripts and asynchronous API for large-scale automation.",
          "Prefer headless mode for faster execution unless debugging.",
          "Leverage selectors efficiently to avoid brittle scripts.",
          "Wait explicitly for elements or network events to ensure reliability.",
          "Organize automation scripts into reusable functions or classes for maintainability."
        ],
        "error_handling": [
          {
            "error": "TimeoutError",
            "solution": "Increase the timeout or ensure the element is correctly targeted and visible before interaction."
          },
          {
            "error": "PlaywrightError: No node found for selector",
            "solution": "Verify the selector is correct and matches an element on the page."
          },
          {
            "error": "BrowserError",
            "solution": "Ensure the browser binaries are installed with `playwright install` and the environment supports GUI if headless=False."
          }
        ]
      },
      "references": {
        "official_docs": "https://playwright.dev/python/",
        "github": "https://github.com/microsoft/playwright-python"
      }
    },
    {
      "id": "selenium",
      "name": "Selenium",
      "category": "Web Automation",
      "description": "Selenium is a powerful Python library for automating web browsers. It allows you to programmatically interact with web pages, simulate user actions, and perform browser testing across multiple browsers.",
      "story": "Selenium was originally developed in 2004 by Jason Huggins at ThoughtWorks as an internal tool for automated testing of web applications. Over time, it evolved into a widely-used framework for browser automation, supporting multiple programming languages and browser drivers. Selenium WebDriver became the standard API for reliable cross-browser automation.",
      "installation": {
        "pip": "pip install selenium",
        "conda": "conda install -c conda-forge selenium"
      },
      "usage": {
        "overview": "Selenium allows you to control browsers using WebDriver. You can navigate pages, click buttons, fill forms, extract text, take screenshots, handle alerts, and perform automated testing. It supports Chrome, Firefox, Edge, Safari, and other major browsers.",
        "basic_examples": [
          {
            "title": "Opening a webpage",
            "code": "from selenium import webdriver\n\ndriver = webdriver.Chrome()\ndriver.get('https://example.com')\nprint(driver.title)\ndriver.quit()",
            "explanation": "Launches Chrome, navigates to the URL, prints the page title, and closes the browser."
          },
          {
            "title": "Finding elements by ID or Name",
            "code": "from selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\ndriver = webdriver.Chrome()\ndriver.get('https://example.com')\nelement = driver.find_element(By.ID, 'username')\nelement.send_keys('myuser')\ndriver.quit()",
            "explanation": "Locates an input field using its ID and types text into it."
          }
        ],
        "advanced_examples": [
          {
            "title": "Clicking a button",
            "code": "from selenium.webdriver.common.by import By\nbutton = driver.find_element(By.XPATH, '//button[text()=\"Submit\"]')\nbutton.click()",
            "explanation": "Finds a button by XPath and simulates a click."
          },
          {
            "title": "Waiting for elements",
            "code": "from selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\nwait = WebDriverWait(driver, 10)\nelement = wait.until(EC.presence_of_element_located((By.ID, 'result')))",
            "explanation": "Waits up to 10 seconds for an element to appear before proceeding."
          },
          {
            "title": "Handling alerts",
            "code": "alert = driver.switch_to.alert\nalert.accept()",
            "explanation": "Switches to a JavaScript alert and accepts it."
          },
          {
            "title": "Taking screenshots",
            "code": "driver.save_screenshot('screenshot.png')",
            "explanation": "Saves a screenshot of the current browser window."
          },
          {
            "title": "Headless mode",
            "code": "from selenium.webdriver.chrome.options import Options\noptions = Options()\noptions.headless = True\ndriver = webdriver.Chrome(options=options)",
            "explanation": "Runs Chrome in headless mode for faster automation without opening a visible window."
          }
        ],
        "best_practices": [
          "Use explicit waits (`WebDriverWait`) instead of arbitrary sleep times for stability.",
          "Close or quit browser instances to free resources.",
          "Use headless mode for automation scripts that don't require UI interaction.",
          "Leverage browser-specific options and capabilities for optimized performance.",
          "Keep WebDriver versions compatible with the browser version installed."
        ],
        "error_handling": [
          {
            "error": "NoSuchElementException",
            "solution": "Verify the selector used to locate the element and ensure it exists on the page."
          },
          {
            "error": "WebDriverException: Message: 'chromedriver' executable needs to be in PATH",
            "solution": "Download the correct WebDriver for your browser and ensure it is in your system PATH."
          },
          {
            "error": "TimeoutException",
            "solution": "Increase the wait time or check that the expected condition is correct."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.selenium.dev/documentation/",
        "github": "https://github.com/SeleniumHQ/selenium"
      }
    },
    {
      "id": "requests-html",
      "name": "Requests-HTML",
      "category": "Web",
      "description": "Requests-HTML is a Python library that combines the simplicity of the Requests library with powerful HTML parsing, web scraping, and asynchronous capabilities. It allows developers to easily fetch, parse, and manipulate HTML content.",
      "story": "Requests-HTML was created by Kenneth Reitz as an extension to the popular Requests library. Its goal was to simplify web scraping and HTML parsing in Python by providing a high-level, Pythonic API. It supports JavaScript rendering using Pyppeteer, making it suitable for modern websites with dynamic content.",
      "installation": {
        "pip": "pip install requests-html",
        "conda": "conda install -c conda-forge requests-html"
      },
      "usage": {
        "overview": "Requests-HTML allows sending HTTP requests, parsing HTML content, executing JavaScript, and extracting data using CSS selectors or XPath. It provides synchronous and asynchronous APIs for web scraping and automation tasks.",
        "basic_examples": [
          {
            "title": "Fetching a webpage",
            "code": "from requests_html import HTMLSession\nsession = HTMLSession()\nresponse = session.get('https://example.com')\nprint(response.html.title)",
            "explanation": "Creates an HTML session, fetches a webpage, and prints the page title."
          },
          {
            "title": "Finding elements with CSS selectors",
            "code": "links = response.html.find('a')\nfor link in links:\n    print(link.text, link.attrs.get('href'))",
            "explanation": "Uses CSS selectors to find all anchor tags and prints their text and href attributes."
          }
        ],
        "advanced_examples": [
          {
            "title": "Rendering JavaScript",
            "code": "r = session.get('https://example.com')\nr.html.render()\nprint(r.html.html)",
            "explanation": "Renders JavaScript on the page, allowing scraping of dynamically generated content."
          },
          {
            "title": "Extracting data with XPath",
            "code": "titles = response.html.xpath('//h1/text()')\nprint(titles)",
            "explanation": "Uses XPath expressions to extract the text of all `<h1>` elements."
          },
          {
            "title": "Using asynchronous requests",
            "code": "from requests_html import AsyncHTMLSession\nasession = AsyncHTMLSession()\n\nasync def get_page():\n    r = await asession.get('https://example.com')\n    print(r.html.title)\n\nasession.run(get_page)",
            "explanation": "Demonstrates asynchronous fetching of a webpage using AsyncHTMLSession."
          },
          {
            "title": "Handling forms",
            "code": "form = response.html.find('form', first=True)\ndata = {input.attrs['name']: 'value' for input in form.find('input')}\nresponse = session.post(form.attrs['action'], data=data)",
            "explanation": "Extracts a form from the page, prepares the data, and submits it via POST."
          }
        ],
        "best_practices": [
          "Use `.render()` only when necessary since JavaScript rendering is resource-intensive.",
          "Leverage CSS selectors for simple element extraction and XPath for complex queries.",
          "Use sessions to persist cookies and headers across multiple requests.",
          "Combine Requests-HTML with other libraries like BeautifulSoup or Pandas for processing and analysis.",
          "Handle exceptions for network issues or rendering errors gracefully."
        ],
        "error_handling": [
          {
            "error": "HTMLSessionError",
            "solution": "Ensure the session is properly created and the URL is correct."
          },
          {
            "error": "RenderError",
            "solution": "Ensure Pyppeteer is installed and the environment supports headless browser execution."
          },
          {
            "error": "ConnectionError",
            "solution": "Check network connectivity and the validity of the target URL."
          }
        ]
      },
      "references": {
        "official_docs": "https://requests-html.kennethreitz.org/",
        "github": "https://github.com/psf/requests-html"
      }
    },
    {
      "id": "tortoise-orm",
      "name": "Tortoise-ORM",
      "category": "Data",
      "description": "Tortoise-ORM is an easy-to-use, asyncio-supporting Object-Relational Mapper (ORM) for Python, designed to provide a simple, familiar interface similar to Django ORM but fully asynchronous.",
      "story": "Tortoise-ORM was created to offer a lightweight, asynchronous ORM for Python developers using async frameworks like FastAPI and Starlette. It emphasizes simplicity, performance, and developer-friendly APIs, supporting multiple database backends including SQLite, PostgreSQL, and MySQL.",
      "installation": {
        "pip": "pip install tortoise-orm[aiohttp,asyncpg]",
        "conda": "conda install -c conda-forge tortoise-orm"
      },
      "usage": {
        "overview": "Tortoise-ORM allows you to define models as Python classes, perform asynchronous CRUD operations, manage relationships, and use querysets similar to Django ORM. It supports migrations via Aerich and integrates seamlessly with async web frameworks.",
        "basic_examples": [
          {
            "title": "Defining a simple model",
            "code": "from tortoise import Tortoise, fields, models\n\nclass User(models.Model):\n    id = fields.IntField(pk=True)\n    name = fields.CharField(max_length=50)\n    email = fields.CharField(max_length=100, unique=True)",
            "explanation": "Defines a `User` model with id, name, and unique email fields using Tortoise ORM."
          },
          {
            "title": "Initializing the ORM and connecting to the database",
            "code": "import asyncio\n\nasync def init():\n    await Tortoise.init(db_url='sqlite://db.sqlite3', modules={'models': ['__main__']})\n    await Tortoise.generate_schemas()\n\nasyncio.run(init())",
            "explanation": "Initializes Tortoise ORM with a SQLite database and generates database tables based on the models."
          }
        ],
        "advanced_examples": [
          {
            "title": "Creating a record asynchronously",
            "code": "async def create_user():\n    user = await User.create(name='Alice', email='alice@example.com')\n    print(user.id)\n\nasyncio.run(create_user())",
            "explanation": "Creates a new user record asynchronously and prints its auto-generated ID."
          },
          {
            "title": "Querying data",
            "code": "async def get_users():\n    users = await User.filter(name='Alice')\n    for user in users:\n        print(user.name, user.email)\n\nasyncio.run(get_users())",
            "explanation": "Fetches all users with the name 'Alice' and prints their details asynchronously."
          },
          {
            "title": "Updating a record",
            "code": "async def update_user():\n    user = await User.get(id=1)\n    user.name = 'Bob'\n    await user.save()\n\nasyncio.run(update_user())",
            "explanation": "Fetches a user by ID, updates the name, and saves the changes asynchronously."
          },
          {
            "title": "Deleting a record",
            "code": "async def delete_user():\n    user = await User.get(id=1)\n    await user.delete()\n\nasyncio.run(delete_user())",
            "explanation": "Fetches a user by ID and deletes it from the database asynchronously."
          },
          {
            "title": "Defining relationships",
            "code": "class Post(models.Model):\n    id = fields.IntField(pk=True)\n    title = fields.CharField(max_length=100)\n    author = fields.ForeignKeyField('models.User', related_name='posts')",
            "explanation": "Defines a `Post` model with a foreign key relationship to the `User` model."
          },
          {
            "title": "Querying related objects",
            "code": "async def get_user_posts():\n    user = await User.get(id=1)\n    posts = await user.posts.all()\n    for post in posts:\n        print(post.title)\n\nasyncio.run(get_user_posts())",
            "explanation": "Fetches all posts authored by a specific user using the related name."
          }
        ],
        "best_practices": [
          "Use async/await syntax consistently when interacting with the database.",
          "Define related_name for relationships for cleaner reverse lookups.",
          "Use Aerich for database migrations to track schema changes.",
          "Keep models modular and organized per app/module.",
          "Handle exceptions such as DoesNotExist and IntegrityError when performing CRUD operations."
        ],
        "error_handling": [
          {
            "error": "tortoise.exceptions.DoesNotExist",
            "solution": "Occurs when querying a model instance that does not exist. Use try/except or `.first()` to avoid exceptions."
          },
          {
            "error": "tortoise.exceptions.IntegrityError",
            "solution": "Raised when unique constraints or foreign key constraints are violated. Ensure input data respects constraints."
          },
          {
            "error": "OperationalError",
            "solution": "Occurs when the database connection fails. Check DB URL, network, or migrations."
          }
        ]
      },
      "references": {
        "official_docs": "https://tortoise-orm.readthedocs.io/",
        "github": "https://github.com/tortoise/tortoise-orm"
      }
    },
    {
      "id": "peewee",
      "name": "Peewee",
      "category": "Data",
      "description": "Peewee is a small, expressive ORM (Object-Relational Mapping) library for Python. It provides a simple and lightweight way to interact with databases using Pythonic models and queries, supporting SQLite, MySQL, and PostgreSQL.",
      "story": "Peewee was created by Charles Leifer to provide a minimalistic ORM alternative that is easy to learn and integrate into Python projects. It emphasizes simplicity and readability while still offering sufficient functionality for most database tasks, making it popular for small to medium-sized applications.",
      "installation": {
        "pip": "pip install peewee",
        "conda": "conda install -c conda-forge peewee"
      },
      "usage": {
        "overview": "Peewee allows you to define models as Python classes that map to database tables. You can perform CRUD operations, define relationships, execute queries, and manage transactions with a simple and intuitive API.",
        "basic_examples": [
          {
            "title": "Defining a model",
            "code": "from peewee import Model, CharField, SqliteDatabase\n\ndb = SqliteDatabase('my_database.db')\n\nclass User(Model):\n    name = CharField()\n    email = CharField(unique=True)\n\n    class Meta:\n        database = db\n\ndb.connect()\ndb.create_tables([User])",
            "explanation": "Defines a `User` model with `name` and unique `email` fields, connects to a SQLite database, and creates the corresponding table."
          },
          {
            "title": "Inserting a record",
            "code": "user = User.create(name='Alice', email='alice@example.com')",
            "explanation": "Creates a new user record and saves it to the database."
          }
        ],
        "advanced_examples": [
          {
            "title": "Querying records",
            "code": "users = User.select().where(User.name == 'Alice')\nfor user in users:\n    print(user.name, user.email)",
            "explanation": "Selects all users with the name 'Alice' and prints their details."
          },
          {
            "title": "Updating records",
            "code": "query = User.update(email='alice_new@example.com').where(User.name=='Alice')\nquery.execute()",
            "explanation": "Updates the email of users with name 'Alice'."
          },
          {
            "title": "Deleting records",
            "code": "query = User.delete().where(User.name=='Alice')\nquery.execute()",
            "explanation": "Deletes users with name 'Alice' from the database."
          },
          {
            "title": "Defining relationships",
            "code": "from peewee import ForeignKeyField\n\nclass Post(Model):\n    title = CharField()\n    author = ForeignKeyField(User, backref='posts')\n\n    class Meta:\n        database = db",
            "explanation": "Defines a `Post` model with a foreign key relationship to the `User` model, allowing reverse lookups via `user.posts`."
          },
          {
            "title": "Transactions",
            "code": "with db.atomic():\n    User.create(name='Bob', email='bob@example.com')\n    User.create(name='Charlie', email='charlie@example.com')",
            "explanation": "Performs multiple database operations within a transaction, ensuring atomicity."
          }
        ],
        "best_practices": [
          "Use `db.atomic()` for grouping multiple operations to ensure atomicity.",
          "Define relationships with `ForeignKeyField` and `backref` for clean data access.",
          "Use Peewee’s built-in query methods instead of raw SQL for consistency and safety.",
          "Keep models modular and separated per app/module for maintainability.",
          "Close database connections after use to prevent resource leaks."
        ],
        "error_handling": [
          {
            "error": "IntegrityError",
            "solution": "Occurs when unique constraints or foreign key constraints are violated. Ensure input data respects constraints."
          },
          {
            "error": "OperationalError",
            "solution": "Check database connectivity, schema, or syntax for errors."
          },
          {
            "error": "DoesNotExist",
            "solution": "Raised when a query for a specific record does not return any results. Handle with try/except blocks or use `.get_or_none()`."
          }
        ]
      },
      "references": {
        "official_docs": "http://docs.peewee-orm.com/en/latest/",
        "github": "https://github.com/coleifer/peewee"
      }
    },
    {
      "id": "mongoengine",
      "name": "MongoEngine",
      "category": "Data",
      "description": "MongoEngine is an Object-Document Mapper (ODM) for Python that provides a high-level abstraction for working with MongoDB. It allows developers to define schemas and interact with MongoDB documents using Python classes instead of raw queries.",
      "story": "MongoEngine was created by Michael Bayer and others to provide a Pythonic interface for MongoDB, similar to how SQLAlchemy provides an ORM for SQL databases. It is widely used in Python web applications and projects requiring flexible NoSQL data storage, offering schema validation, query building, and relationship management.",
      "installation": {
        "pip": "pip install mongoengine",
        "conda": "conda install -c conda-forge mongoengine"
      },
      "usage": {
        "overview": "MongoEngine allows you to define document schemas as Python classes, perform CRUD operations, build queries, and handle embedded documents and references. It integrates well with web frameworks like Flask and Django.",
        "basic_examples": [
          {
            "title": "Connecting to MongoDB",
            "code": "from mongoengine import connect\nconnect('mydb')",
            "explanation": "Connects to a MongoDB database named 'mydb'. You can also specify host, port, username, and password."
          },
          {
            "title": "Defining a simple document",
            "code": "from mongoengine import Document, StringField, IntField\n\nclass User(Document):\n    name = StringField(required=True, max_length=50)\n    age = IntField()",
            "explanation": "Defines a `User` document with `name` and `age` fields, including basic validation."
          },
          {
            "title": "Creating a document",
            "code": "user = User(name='Alice', age=25)\nuser.save()",
            "explanation": "Creates a new `User` document and saves it to the database."
          }
        ],
        "advanced_examples": [
          {
            "title": "Querying documents",
            "code": "users = User.objects(age__gte=18)\nfor user in users:\n    print(user.name, user.age)",
            "explanation": "Fetches all users aged 18 or older using MongoEngine’s query syntax."
          },
          {
            "title": "Updating documents",
            "code": "User.objects(name='Alice').update(set__age=26)",
            "explanation": "Updates the age of users named 'Alice' to 26."
          },
          {
            "title": "Deleting documents",
            "code": "User.objects(name='Alice').delete()",
            "explanation": "Deletes all users with the name 'Alice'."
          },
          {
            "title": "Embedded documents",
            "code": "from mongoengine import EmbeddedDocument, EmbeddedDocumentField\n\nclass Address(EmbeddedDocument):\n    street = StringField()\n    city = StringField()\n\nclass User(Document):\n    name = StringField()\n    address = EmbeddedDocumentField(Address)",
            "explanation": "Shows how to define embedded documents to represent nested structures."
          },
          {
            "title": "Reference fields (relationships)",
            "code": "from mongoengine import ReferenceField\n\nclass Post(Document):\n    title = StringField()\n    author = ReferenceField(User)",
            "explanation": "Defines a relationship between `Post` and `User` documents using reference fields."
          }
        ],
        "best_practices": [
          "Use schema validation in your Document fields to prevent inconsistent data.",
          "Prefer query filters over iterating all documents for efficiency.",
          "Close the connection explicitly in long-running scripts using `disconnect()` if needed.",
          "Use indexes for frequently queried fields to improve performance.",
          "Leverage embedded documents for tightly coupled data and references for loosely coupled relationships."
        ],
        "error_handling": [
          {
            "error": "ValidationError",
            "solution": "Occurs when a document fails field validation. Check field types, required fields, and constraints."
          },
          {
            "error": "NotUniqueError",
            "solution": "Raised when attempting to insert a document with a value that violates a unique constraint."
          },
          {
            "error": "DoesNotExist",
            "solution": "Thrown when querying for a document that does not exist. Use `.first()` or handle exceptions."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.mongoengine.org/",
        "github": "https://github.com/MongoEngine/mongoengine"
      }
    },
    {
      "id": "paramiko",
      "name": "Paramiko",
      "category": "Networking/CLI",
      "description": "Paramiko is a Python library for SSH2 protocol, providing both client and server functionality. It allows you to securely connect to remote machines, execute commands, transfer files over SFTP, and manage SSH sessions programmatically.",
      "story": "Paramiko was created by Robey Pointer in 2003 to provide a pure-Python implementation of the SSHv2 protocol. It became a popular tool for automating server administration, remote command execution, and secure file transfers in Python applications.",
      "installation": {
        "pip": "pip install paramiko",
        "conda": "conda install -c conda-forge paramiko"
      },
      "usage": {
        "overview": "Paramiko provides SSH client and server implementations. You can connect to remote servers, run shell commands, upload and download files using SFTP, and handle keys and authentication. It supports password and key-based authentication, as well as SSH agent integration.",
        "basic_examples": [
          {
            "title": "SSH Connection and Command Execution",
            "code": "import paramiko\n\nssh = paramiko.SSHClient()\nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\nssh.connect('example.com', username='user', password='pass')\nstdin, stdout, stderr = ssh.exec_command('ls -l')\nprint(stdout.read().decode())\nssh.close()",
            "explanation": "Connects to a remote server via SSH, executes the `ls -l` command, prints the output, and closes the connection."
          },
          {
            "title": "Using Key-Based Authentication",
            "code": "import paramiko\n\nssh = paramiko.SSHClient()\nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\nprivate_key = paramiko.RSAKey.from_private_key_file('/path/to/key.pem')\nssh.connect('example.com', username='user', pkey=private_key)\nstdin, stdout, stderr = ssh.exec_command('uptime')\nprint(stdout.read().decode())\nssh.close()",
            "explanation": "Uses an RSA private key for authentication instead of a password to connect to a remote server."
          }
        ],
        "advanced_examples": [
          {
            "title": "SFTP File Transfer",
            "code": "import paramiko\n\ntransport = paramiko.Transport(('example.com', 22))\ntransport.connect(username='user', password='pass')\nsftp = paramiko.SFTPClient.from_transport(transport)\nsftp.put('local_file.txt', 'remote_file.txt')\nsftp.get('remote_file.txt', 'local_copy.txt')\nsftp.close()\ntransport.close()",
            "explanation": "Uploads a local file to a remote server and downloads a file back using SFTP."
          },
          {
            "title": "SSH with Context Manager",
            "code": "import paramiko\n\nwith paramiko.SSHClient() as ssh:\n    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    ssh.connect('example.com', username='user', password='pass')\n    stdin, stdout, stderr = ssh.exec_command('whoami')\n    print(stdout.read().decode())",
            "explanation": "Uses a context manager to automatically handle SSH connection closing."
          },
          {
            "title": "Using SSH Agent",
            "code": "import paramiko\nagent = paramiko.Agent()\nkeys = agent.get_keys()\nssh = paramiko.SSHClient()\nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\nssh.connect('example.com', username='user', pkey=keys[0])",
            "explanation": "Uses keys from an SSH agent for authentication."
          }
        ],
        "best_practices": [
          "Always handle missing host keys with `AutoAddPolicy()` or manually add known hosts.",
          "Prefer key-based authentication over passwords for better security.",
          "Close SSH and SFTP connections properly to release resources.",
          "Use paramiko logging to debug connection and authentication issues.",
          "For long-running scripts, handle network interruptions and reconnections."
        ],
        "error_handling": [
          {
            "error": "AuthenticationException",
            "solution": "Raised when authentication fails. Verify username, password, and key files."
          },
          {
            "error": "SSHException",
            "solution": "General SSH error. Check server status and compatibility with Paramiko."
          },
          {
            "error": "NoValidConnectionsError",
            "solution": "Occurs when unable to connect to the specified host/port. Ensure the server is accessible."
          }
        ]
      },
      "references": {
        "official_docs": "http://docs.paramiko.org/",
        "github": "https://github.com/paramiko/paramiko"
      }
    },
    {
      "id": "asyncio",
      "name": "Asyncio",
      "category": "CLI/Utils",
      "description": "Asyncio is Python's standard library for writing concurrent code using the async/await syntax. It provides an event loop, coroutines, tasks, and futures to facilitate asynchronous programming and I/O-bound operations.",
      "story": "Asyncio was introduced in Python 3.4 (2014) to provide a built-in framework for asynchronous programming, inspired by frameworks like Twisted and Tornado. It enables efficient handling of I/O-bound tasks, networking, and high-performance applications without using traditional threading or multiprocessing.",
      "installation": {
        "pip": "Included in Python standard library (Python 3.4+)",
        "conda": "Included in Python standard library"
      },
      "usage": {
        "overview": "Asyncio allows you to define coroutines with `async def`, schedule them for execution, and manage asynchronous tasks. It is ideal for network operations, file I/O, concurrency, and writing scalable applications.",
        "basic_examples": [
          {
            "title": "Simple coroutine",
            "code": "import asyncio\n\nasync def say_hello():\n    print('Hello')\n    await asyncio.sleep(1)\n    print('World')\n\nasyncio.run(say_hello())",
            "explanation": "Defines a coroutine using `async def` and runs it with `asyncio.run()`. Demonstrates non-blocking sleep."
          },
          {
            "title": "Running multiple coroutines concurrently",
            "code": "import asyncio\n\nasync def task(name, delay):\n    await asyncio.sleep(delay)\n    print(f'Task {name} completed')\n\nasync def main():\n    await asyncio.gather(task('A', 2), task('B', 1))\n\nasyncio.run(main())",
            "explanation": "Uses `asyncio.gather` to run multiple coroutines concurrently, printing output when each finishes."
          }
        ],
        "advanced_examples": [
          {
            "title": "Creating tasks",
            "code": "import asyncio\n\nasync def my_task():\n    await asyncio.sleep(1)\n    print('Task done')\n\ntask = asyncio.create_task(my_task())\nasyncio.run(task)",
            "explanation": "Wraps a coroutine in a Task, allowing it to run in the background."
          },
          {
            "title": "Using async context managers",
            "code": "import asyncio\n\nclass AsyncResource:\n    async def __aenter__(self):\n        print('Enter')\n        return self\n    async def __aexit__(self, exc_type, exc, tb):\n        print('Exit')\n\nasync def main():\n    async with AsyncResource():\n        print('Inside context')\n\nasyncio.run(main())",
            "explanation": "Demonstrates the use of async context managers to manage resources asynchronously."
          },
          {
            "title": "Networking with asyncio",
            "code": "import asyncio\n\nasync def tcp_echo_client(message):\n    reader, writer = await asyncio.open_connection('127.0.0.1', 8888)\n    writer.write(message.encode())\n    await writer.drain()\n    data = await reader.read(100)\n    print(f'Received: {data.decode()}')\n    writer.close()\n    await writer.wait_closed()\n\nasyncio.run(tcp_echo_client('Hello'))",
            "explanation": "Shows a simple TCP client using asyncio for asynchronous network I/O."
          },
          {
            "title": "Scheduling periodic tasks",
            "code": "import asyncio\n\nasync def periodic():\n    while True:\n        print('Tick')\n        await asyncio.sleep(1)\n\nasyncio.run(periodic())",
            "explanation": "Runs a coroutine repeatedly at fixed intervals using a loop with `await asyncio.sleep()`."
          }
        ],
        "best_practices": [
          "Prefer `asyncio.run()` for top-level entry points in Python 3.7+.",
          "Use `async/await` syntax instead of `@asyncio.coroutine` for readability.",
          "Leverage `asyncio.gather()` for running multiple coroutines concurrently.",
          "Use Tasks for background execution and long-running operations.",
          "Avoid blocking calls in async functions; use non-blocking I/O libraries."
        ],
        "error_handling": [
          {
            "error": "RuntimeError: Event loop is closed",
            "solution": "Ensure you are not calling `asyncio.run()` from within an already running event loop."
          },
          {
            "error": "CancelledError",
            "solution": "Occurs when a task is cancelled. Handle with try/except around awaited tasks."
          },
          {
            "error": "TimeoutError",
            "solution": "Use `asyncio.wait_for()` or `asyncio.timeout()` to limit the duration of coroutines safely."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.python.org/3/library/asyncio.html",
        "github": "https://github.com/python/asyncio"
      }
    },
    {
      "id": "twisted",
      "name": "Twisted",
      "category": "Networking/CLI",
      "description": "Twisted is an event-driven networking engine written in Python. It provides a robust framework for building asynchronous networked applications, including servers, clients, and protocols for TCP, UDP, SSL/TLS, and more.",
      "story": "Twisted was created by Glyph Lefkowitz in 2002 to simplify the development of networked applications in Python. It focuses on asynchronous I/O, making it suitable for high-performance network servers and clients. Twisted supports multiple protocols out-of-the-box and has a flexible architecture for custom protocol implementation.",
      "installation": {
        "pip": "pip install twisted",
        "conda": "conda install -c conda-forge twisted"
      },
      "usage": {
        "overview": "Twisted uses an event-driven programming model where the reactor loop manages asynchronous events. Developers define protocols and factories to handle network events, such as connections, data received, and errors.",
        "basic_examples": [
          {
            "title": "Simple TCP server",
            "code": "from twisted.internet import reactor, protocol\n\nclass Echo(protocol.Protocol):\n    def dataReceived(self, data):\n        self.transport.write(data)\n\nclass EchoFactory(protocol.Factory):\n    def buildProtocol(self, addr):\n        return Echo()\n\nreactor.listenTCP(8000, EchoFactory())\nreactor.run()",
            "explanation": "Creates a TCP server on port 8000 that echoes back any data received."
          },
          {
            "title": "Simple TCP client",
            "code": "from twisted.internet import reactor, protocol\n\nclass EchoClient(protocol.Protocol):\n    def connectionMade(self):\n        self.transport.write(b'Hello, world!')\n    def dataReceived(self, data):\n        print('Server said:', data)\n        self.transport.loseConnection()\n\nclass EchoFactory(protocol.ClientFactory):\n    def buildProtocol(self, addr):\n        return EchoClient()\n    def clientConnectionFailed(self, connector, reason):\n        print('Connection failed')\n        reactor.stop()\n    def clientConnectionLost(self, connector, reason):\n        reactor.stop()\n\nreactor.connectTCP('localhost', 8000, EchoFactory())\nreactor.run()",
            "explanation": "Connects to a TCP server, sends a message, prints the response, and closes the connection."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using Deferreds",
            "code": "from twisted.internet import reactor, defer\n\ndef got_result(result):\n    print('Result:', result)\n    reactor.stop()\n\nd = defer.Deferred()\nd.addCallback(got_result)\nd.callback('Hello Twisted')\nreactor.run()",
            "explanation": "Demonstrates the use of Deferred objects for handling asynchronous results and callbacks."
          },
          {
            "title": "HTTP client request",
            "code": "from twisted.web.client import getPage\nfrom twisted.internet import reactor\n\ndef print_result(result):\n    print(result)\n    reactor.stop()\n\ngetPage(b'http://httpbin.org/get').addCallback(print_result)\nreactor.run()",
            "explanation": "Performs an asynchronous HTTP GET request and prints the page content."
          },
          {
            "title": "Using SSL/TLS",
            "code": "from twisted.internet import ssl, reactor\nfrom twisted.internet.protocol import Protocol, ClientFactory\n\nclass SecureClient(Protocol):\n    def connectionMade(self):\n        self.transport.write(b'Secure Hello')\n    def dataReceived(self, data):\n        print('Received:', data)\n        self.transport.loseConnection()\n\nclass SecureFactory(ClientFactory):\n    def buildProtocol(self, addr):\n        return SecureClient()\n\nreactor.connectSSL('localhost', 8000, SecureFactory(), ssl.ClientContextFactory())\nreactor.run()",
            "explanation": "Shows how to establish a secure SSL/TLS client connection using Twisted."
          }
        ],
        "best_practices": [
          "Use the reactor loop for all asynchronous operations.",
          "Leverage Deferreds for handling asynchronous callbacks and chaining operations.",
          "Use Factories to manage protocol instances and connections.",
          "Avoid blocking calls inside Twisted protocols; use threads or deferToThread for blocking operations.",
          "Use Twisted’s built-in protocols and utilities to simplify network programming."
        ],
        "error_handling": [
          {
            "error": "ConnectionRefusedError",
            "solution": "Ensure the server is running and reachable at the specified host and port."
          },
          {
            "error": "twisted.internet.error.ReactorNotRunning",
            "solution": "Check that reactor.run() has been called and not stopped prematurely."
          },
          {
            "error": "TimeoutError",
            "solution": "Use Twisted’s timeout mechanisms or Deferred timeouts to handle slow connections."
          }
        ]
      },
      "references": {
        "official_docs": "https://twistedmatrix.com/documents/current/",
        "github": "https://github.com/twisted/twisted"
      }
    },
    {
      "id": "pathlib",
      "name": "Pathlib",
      "category": "CLI/Utils",
      "description": "Pathlib is a Python standard library module that provides an object-oriented interface for working with filesystem paths. It simplifies file and directory manipulations across different operating systems.",
      "story": "Pathlib was introduced in Python 3.4 to offer a more intuitive, object-oriented approach to handling filesystem paths compared to the traditional `os.path` module. It unifies the handling of files and directories, making code cleaner, more readable, and portable.",
      "installation": {
        "pip": "Included in Python standard library (Python 3.4+)",
        "conda": "Included in Python standard library"
      },
      "usage": {
        "overview": "Pathlib allows you to create, manipulate, and query file paths using Path objects. It supports operations like checking existence, reading/writing files, creating directories, iterating over directories, and handling path joins in a platform-independent way.",
        "basic_examples": [
          {
            "title": "Creating a Path object",
            "code": "from pathlib import Path\npath = Path('/home/user/docs')\nprint(path.exists())",
            "explanation": "Creates a Path object pointing to a directory and checks whether it exists."
          },
          {
            "title": "Joining paths",
            "code": "from pathlib import Path\npath = Path('/home/user') / 'docs' / 'file.txt'\nprint(path)",
            "explanation": "Joins path components using the `/` operator in a platform-independent way."
          },
          {
            "title": "Iterating over files in a directory",
            "code": "from pathlib import Path\npath = Path('/home/user/docs')\nfor file in path.iterdir():\n    print(file.name)",
            "explanation": "Iterates over all files and directories inside the given path."
          }
        ],
        "advanced_examples": [
          {
            "title": "Reading and writing files",
            "code": "from pathlib import Path\npath = Path('example.txt')\npath.write_text('Hello, Pathlib!')\ncontent = path.read_text()\nprint(content)",
            "explanation": "Writes text to a file and then reads it back using Path methods."
          },
          {
            "title": "Creating directories",
            "code": "from pathlib import Path\npath = Path('new_folder')\npath.mkdir(exist_ok=True)",
            "explanation": "Creates a new directory. The `exist_ok=True` argument prevents errors if the directory already exists."
          },
          {
            "title": "Checking file properties",
            "code": "from pathlib import Path\npath = Path('example.txt')\nprint(path.is_file())\nprint(path.is_dir())\nprint(path.suffix)",
            "explanation": "Checks if the path is a file or directory and prints the file extension."
          },
          {
            "title": "Glob pattern matching",
            "code": "from pathlib import Path\npath = Path('/home/user/docs')\nfor txt_file in path.glob('*.txt'):\n    print(txt_file)",
            "explanation": "Finds all `.txt` files in the specified directory using glob patterns."
          },
          {
            "title": "Recursive globbing",
            "code": "from pathlib import Path\npath = Path('/home/user/docs')\nfor py_file in path.rglob('*.py'):\n    print(py_file)",
            "explanation": "Recursively searches for all `.py` files in the directory and its subdirectories."
          }
        ],
        "best_practices": [
          "Prefer Path objects over string paths for cleaner and safer code.",
          "Use `/` operator to join paths instead of `os.path.join()` for readability.",
          "Leverage `exists()`, `is_file()`, and `is_dir()` to validate paths before operations.",
          "Use `mkdir(exist_ok=True, parents=True)` for creating nested directories safely.",
          "Combine Pathlib with `shutil` for advanced file operations like copy and move."
        ],
        "error_handling": [
          {
            "error": "FileNotFoundError",
            "solution": "Ensure the file or directory exists before attempting to read or modify it."
          },
          {
            "error": "PermissionError",
            "solution": "Check that the program has the necessary permissions to read/write the file or directory."
          },
          {
            "error": "IsADirectoryError / NotADirectoryError",
            "solution": "Verify whether the path is a file or a directory before performing file-specific or directory-specific operations."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.python.org/3/library/pathlib.html",
        "github": "https://github.com/python/cpython"
      }
    },
    {
      "id": "pendulum",
      "name": "Pendulum",
      "category": "Date & Time",
      "description": "Pendulum is a Python library for handling dates, times, and time zones. It provides a cleaner and more intuitive API than the standard `datetime` module, with precise parsing, formatting, and manipulation of date and time objects.",
      "story": "Pendulum was created by Sébastien Règne to address the limitations and complexities of Python’s built-in `datetime` module. It focuses on simplicity, correctness, and timezone awareness, making it suitable for applications where robust date and time handling is critical.",
      "installation": {
        "pip": "pip install pendulum",
        "conda": "conda install -c conda-forge pendulum"
      },
      "usage": {
        "overview": "Pendulum allows creating and manipulating dates and times, handling time zones, formatting, parsing strings, and performing arithmetic with durations. It is fully compatible with Python's `datetime` module but offers additional convenience methods and immutability.",
        "basic_examples": [
          {
            "title": "Creating a datetime",
            "code": "import pendulum\nnow = pendulum.now()\nprint(now)",
            "explanation": "Gets the current date and time with timezone awareness."
          },
          {
            "title": "Creating a specific datetime",
            "code": "import pendulum\ndt = pendulum.datetime(2025, 8, 21, 15, 30)\nprint(dt)",
            "explanation": "Creates a specific datetime object for 21st August 2025 at 15:30."
          },
          {
            "title": "Parsing a datetime string",
            "code": "import pendulum\ndt = pendulum.parse('2025-08-21T15:30:00')\nprint(dt)",
            "explanation": "Parses an ISO-8601 formatted string into a Pendulum datetime object."
          }
        ],
        "advanced_examples": [
          {
            "title": "Time zone conversion",
            "code": "import pendulum\nnow = pendulum.now('UTC')\nny = now.in_tz('America/New_York')\nprint(ny)",
            "explanation": "Converts a UTC datetime to another timezone (New York)."
          },
          {
            "title": "Date arithmetic",
            "code": "import pendulum\nnow = pendulum.now()\nlater = now.add(days=5, hours=3)\nprint(later)\nprevious = now.subtract(weeks=2)\nprint(previous)",
            "explanation": "Adds or subtracts time intervals to perform date arithmetic easily."
          },
          {
            "title": "Durations",
            "code": "import pendulum\nduration = pendulum.duration(days=2, hours=3)\nprint(duration.in_hours())",
            "explanation": "Creates a duration and converts it into hours."
          },
          {
            "title": "Formatting dates",
            "code": "import pendulum\nnow = pendulum.now()\nprint(now.to_iso8601_string())\nprint(now.format('dddd, MMMM D, YYYY'))",
            "explanation": "Formats datetime objects into ISO 8601 strings or human-readable formats."
          },
          {
            "title": "Difference between two dates",
            "code": "import pendulum\nd1 = pendulum.date(2025, 8, 21)\nd2 = pendulum.date(2025, 9, 1)\nprint(d2 - d1)\nprint((d2 - d1).in_days())",
            "explanation": "Calculates the difference between two dates and converts it into days."
          }
        ],
        "best_practices": [
          "Prefer `pendulum.now()` over `datetime.now()` for timezone-aware datetimes.",
          "Use immutable datetime objects to avoid accidental modifications.",
          "Leverage human-friendly formatting for logging and reporting.",
          "Always specify a timezone when creating or converting datetime objects.",
          "Use duration objects for arithmetic instead of manual calculations."
        ],
        "error_handling": [
          {
            "error": "pendulum.parsing.exceptions.ParserError",
            "solution": "Ensure the datetime string matches the expected format when parsing."
          },
          {
            "error": "ValueError",
            "solution": "Check that date and time components are within valid ranges (e.g., month 1-12, day 1-31)."
          }
        ]
      },
      "references": {
        "official_docs": "https://pendulum.eustace.io/docs/",
        "github": "https://github.com/sdispater/pendulum"
      }
    },
    {
      "id": "arrow",
      "name": "Arrow",
      "category": "Date & Time",
      "description": "Arrow is a Python library that provides a sensible, human-friendly approach to creating, manipulating, formatting, and converting dates and times. It simplifies working with time zones and datetime arithmetic.",
      "story": "Arrow was created by Chris Smith to address the limitations of Python's standard `datetime` module. It focuses on simplicity, readability, and human-friendly operations, enabling developers to handle date and time in an intuitive manner.",
      "installation": {
        "pip": "pip install arrow",
        "conda": "conda install -c conda-forge arrow"
      },
      "usage": {
        "overview": "Arrow allows you to create datetime objects, shift them by time intervals, convert between time zones, format and parse strings, and perform human-readable operations.",
        "basic_examples": [
          {
            "title": "Getting the current time",
            "code": "import arrow\nnow = arrow.now()\nprint(now)",
            "explanation": "Retrieves the current local time as an Arrow object."
          },
          {
            "title": "Creating a specific datetime",
            "code": "import arrow\ndt = arrow.get('2025-08-21 15:30', 'YYYY-MM-DD HH:mm')\nprint(dt)",
            "explanation": "Parses a string to create a specific datetime using a format string."
          },
          {
            "title": "Shifting time",
            "code": "import arrow\nnow = arrow.now()\nfuture = now.shift(days=+5, hours=+3)\nprint(future)",
            "explanation": "Shifts the datetime forward by 5 days and 3 hours."
          }
        ],
        "advanced_examples": [
          {
            "title": "Time zone conversion",
            "code": "import arrow\nnow = arrow.now('UTC')\nny = now.to('America/New_York')\nprint(ny)",
            "explanation": "Converts a UTC datetime to another timezone, e.g., New York."
          },
          {
            "title": "Formatting dates",
            "code": "import arrow\nnow = arrow.now()\nprint(now.format('YYYY-MM-DD HH:mm:ss'))",
            "explanation": "Formats the Arrow object into a human-readable string."
          },
          {
            "title": "Humanized differences",
            "code": "import arrow\npast = arrow.get('2025-08-01')\nnow = arrow.now()\nprint(past.humanize(now))",
            "explanation": "Shows the difference between two datetimes in a human-friendly way, e.g., '3 weeks ago'."
          },
          {
            "title": "Parsing and formatting multiple formats",
            "code": "import arrow\ndt = arrow.get('21/08/2025', 'DD/MM/YYYY')\nprint(dt.format('YYYY-MM-DD'))",
            "explanation": "Parses a date string with a custom format and converts it into another format."
          }
        ],
        "best_practices": [
          "Use Arrow objects instead of Python datetime objects for simplicity and readability.",
          "Always specify a timezone when working with global applications.",
          "Use humanize for user-friendly time displays.",
          "Prefer `shift()` over manual datetime arithmetic.",
          "Use Arrow for parsing, formatting, and conversion to reduce boilerplate code."
        ],
        "error_handling": [
          {
            "error": "ParserError",
            "solution": "Ensure the input string matches the provided format string when parsing."
          },
          {
            "error": "ValueError",
            "solution": "Check that date and time components are valid and within acceptable ranges."
          }
        ]
      },
      "references": {
        "official_docs": "https://arrow.readthedocs.io/",
        "github": "https://github.com/arrow-py/arrow"
      }
    },
    {
      "id": "pyyaml",
      "name": "PyYAML",
      "category": "CLI/Utils",
      "description": "PyYAML is a Python library for parsing and writing YAML (YAML Ain’t Markup Language) files. It allows you to read YAML data into Python objects and serialize Python objects back into YAML format.",
      "story": "PyYAML was created by Kirill Simonov in 2006 to provide a simple, Pythonic way to work with YAML. YAML is a human-readable data serialization format commonly used for configuration files, data exchange, and application settings. PyYAML quickly became the standard library for YAML processing in Python.",
      "installation": {
        "pip": "pip install pyyaml",
        "conda": "conda install -c conda-forge pyyaml"
      },
      "usage": {
        "overview": "PyYAML provides functions `yaml.load()` and `yaml.safe_load()` to parse YAML into Python objects, and `yaml.dump()` to serialize Python objects into YAML. `safe_load()` is recommended for untrusted input to avoid executing arbitrary Python objects.",
        "basic_examples": [
          {
            "title": "Loading YAML from a string",
            "code": "import yaml\nyaml_str = 'name: Alice\\nage: 30\\ncity: New York'\ndata = yaml.safe_load(yaml_str)\nprint(data)",
            "explanation": "Parses a YAML string into a Python dictionary safely."
          },
          {
            "title": "Loading YAML from a file",
            "code": "import yaml\nwith open('config.yaml', 'r') as file:\n    data = yaml.safe_load(file)\nprint(data)",
            "explanation": "Reads a YAML file and converts it into a Python object (usually a dictionary)."
          }
        ],
        "advanced_examples": [
          {
            "title": "Dumping Python object to YAML string",
            "code": "import yaml\ndata = {'name': 'Alice', 'age': 30, 'city': 'New York'}\nyaml_str = yaml.dump(data)\nprint(yaml_str)",
            "explanation": "Serializes a Python dictionary into a YAML-formatted string."
          },
          {
            "title": "Writing YAML to a file",
            "code": "import yaml\ndata = {'name': 'Alice', 'age': 30, 'city': 'New York'}\nwith open('output.yaml', 'w') as file:\n    yaml.dump(data, file)",
            "explanation": "Writes Python data structures to a YAML file."
          },
          {
            "title": "Using custom YAML tags",
            "code": "import yaml\nclass User:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\ndef user_representer(dumper, data):\n    return dumper.represent_mapping('!User', {'name': data.name, 'age': data.age})\n\nyaml.add_representer(User, user_representer)\nuser = User('Alice', 30)\nprint(yaml.dump(user))",
            "explanation": "Demonstrates defining custom YAML tags and serializing Python objects with PyYAML."
          },
          {
            "title": "Loading multiple documents",
            "code": "import yaml\nyaml_str = '---\\nname: Alice\\n---\\nname: Bob'\ndocs = list(yaml.safe_load_all(yaml_str))\nprint(docs)",
            "explanation": "Loads multiple YAML documents from a single string or file using `safe_load_all()`."
          }
        ],
        "best_practices": [
          "Use `safe_load()` instead of `load()` when processing untrusted YAML input.",
          "Serialize Python objects explicitly using `dump()` with custom representers if needed.",
          "Keep YAML files human-readable and simple for maintainability.",
          "Validate parsed YAML data before using it in your application.",
          "Use `load_all()` to handle multi-document YAML files safely."
        ],
        "error_handling": [
          {
            "error": "yaml.YAMLError",
            "solution": "Raised for any parsing or syntax errors. Check your YAML format for indentation and correct syntax."
          },
          {
            "error": "ConstructorError",
            "solution": "Occurs when a custom tag cannot be constructed. Define custom constructors or avoid unsafe tags."
          },
          {
            "error": "ScannerError",
            "solution": "Indicates malformed YAML. Ensure correct indentation, colons, and spacing."
          }
        ]
      },
      "references": {
        "official_docs": "https://pyyaml.org/wiki/PyYAMLDocumentation",
        "github": "https://github.com/yaml/pyyaml"
      }
    },
    {
      "id": "jsonschema",
      "name": "JSONSchema",
      "category": "CLI/Utils",
      "description": "JSONSchema is a Python library for validating JSON data against a schema. It allows developers to ensure that JSON objects conform to a defined structure, including types, required properties, and value constraints.",
      "story": "JSONSchema was created to provide a standard way of validating JSON data in Python. It is widely used in API development, configuration validation, and data exchange scenarios where ensuring consistent JSON structure is critical. It adheres to the JSON Schema standard (drafts 4, 6, and 7).",
      "installation": {
        "pip": "pip install jsonschema",
        "conda": "conda install -c conda-forge jsonschema"
      },
      "usage": {
        "overview": "JSONSchema allows you to define schemas using Python dictionaries and validate JSON-like data structures. It supports type checking, pattern validation, required properties, nested structures, and custom validation functions.",
        "basic_examples": [
          {
            "title": "Validating a simple JSON object",
            "code": "from jsonschema import validate, ValidationError\n\nschema = {\n    'type': 'object',\n    'properties': {\n        'name': {'type': 'string'},\n        'age': {'type': 'number'},\n    },\n    'required': ['name', 'age']\n}\ndata = {'name': 'Alice', 'age': 30}\n\ntry:\n    validate(instance=data, schema=schema)\n    print('JSON is valid')\nexcept ValidationError as e:\n    print('JSON is invalid:', e)",
            "explanation": "Validates a Python dictionary against a schema specifying required properties and their types."
          },
          {
            "title": "Invalid JSON object",
            "code": "data = {'name': 'Alice'}\ntry:\n    validate(instance=data, schema=schema)\nexcept ValidationError as e:\n    print('Validation error:', e.message)",
            "explanation": "Demonstrates handling validation errors when required properties are missing."
          }
        ],
        "advanced_examples": [
          {
            "title": "Nested JSON validation",
            "code": "schema = {\n    'type': 'object',\n    'properties': {\n        'user': {\n            'type': 'object',\n            'properties': {\n                'id': {'type': 'integer'},\n                'name': {'type': 'string'}\n            },\n            'required': ['id', 'name']\n        }\n    },\n    'required': ['user']\n}\ndata = {'user': {'id': 1, 'name': 'Alice'}}\nvalidate(instance=data, schema=schema)",
            "explanation": "Validates nested dictionaries, ensuring inner objects also conform to a schema."
          },
          {
            "title": "Using pattern validation",
            "code": "schema = {\n    'type': 'object',\n    'properties': {\n        'email': {'type': 'string', 'pattern': r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'}\n    },\n    'required': ['email']\n}\ndata = {'email': 'alice@example.com'}\nvalidate(instance=data, schema=schema)",
            "explanation": "Ensures that string fields match a regular expression pattern, e.g., validating an email address."
          },
          {
            "title": "Enum validation",
            "code": "schema = {\n    'type': 'object',\n    'properties': {\n        'role': {'type': 'string', 'enum': ['admin', 'user', 'guest']}\n    },\n    'required': ['role']\n}\ndata = {'role': 'admin'}\nvalidate(instance=data, schema=schema)",
            "explanation": "Restricts a property to a set of predefined values using the `enum` keyword."
          },
          {
            "title": "Array validation",
            "code": "schema = {\n    'type': 'object',\n    'properties': {\n        'tags': {'type': 'array', 'items': {'type': 'string'}, 'minItems': 1}\n    },\n    'required': ['tags']\n}\ndata = {'tags': ['python', 'json']}\nvalidate(instance=data, schema=schema)",
            "explanation": "Validates array types, item types, and minimum number of items in the array."
          },
          {
            "title": "Custom validator",
            "code": "from jsonschema import Draft7Validator\n\ndef is_positive(validator, value, instance, schema):\n    if instance <= 0:\n        yield ValidationError('Value must be positive')\n\nvalidator = Draft7Validator(schema={'type': 'number'}, validators={'positive': is_positive})\nfor error in validator.iter_errors(-5):\n    print(error.message)",
            "explanation": "Demonstrates creating a custom validation function for specific constraints."
          }
        ],
        "best_practices": [
          "Define schemas as Python dictionaries or load from JSON files.",
          "Use Draft7Validator or later for more advanced schema features.",
          "Validate user inputs in APIs and configurations to prevent errors.",
          "Combine with try/except blocks to handle invalid data gracefully.",
          "Use patterns, enums, and `required` properties to enforce strict data validation."
        ],
        "error_handling": [
          {
            "error": "jsonschema.exceptions.ValidationError",
            "solution": "Raised when the instance does not conform to the schema. Check the error message to identify which property is invalid."
          },
          {
            "error": "jsonschema.exceptions.SchemaError",
            "solution": "Raised when the schema itself is invalid. Ensure the schema follows the JSON Schema specification."
          }
        ]
      },
      "references": {
        "official_docs": "https://python-jsonschema.readthedocs.io/en/stable/",
        "github": "https://github.com/Julian/jsonschema"
      }
    },
    {
      "id": "snscrape",
      "name": "SNScrape",
      "category": "Web",
      "description": "SNScrape is a Python library for scraping social networking services such as Twitter, Facebook, Reddit, and more. It allows fetching posts, comments, tweets, user profiles, and other social data without using official APIs.",
      "story": "SNScrape was created to provide a simple and reliable way to extract social media content without relying on official APIs, which often have rate limits or require authentication. It has become popular among data analysts, researchers, and developers for social media mining and analysis.",
      "installation": {
        "pip": "pip install snscrape",
        "conda": "conda install -c conda-forge snscrape"
      },
      "usage": {
        "overview": "SNScrape can scrape posts, tweets, users, and hashtags from multiple social platforms. It supports filtering by date, keyword, or user, and outputs data in JSON, CSV, or other formats.",
        "basic_examples": [
          {
            "title": "Scraping tweets from a user",
            "code": "import snscrape.modules.twitter as sntwitter\n\nfor i, tweet in enumerate(sntwitter.TwitterUserScraper('twitter').get_items()):\n    if i > 5:\n        break\n    print(tweet.date, tweet.content)",
            "explanation": "Scrapes the latest 5 tweets from a specified Twitter user and prints their date and content."
          },
          {
            "title": "Scraping tweets by hashtag",
            "code": "import snscrape.modules.twitter as sntwitter\n\nfor i, tweet in enumerate(sntwitter.TwitterHashtagScraper('#Python').get_items()):\n    if i > 5:\n        break\n    print(tweet.date, tweet.content)",
            "explanation": "Fetches the latest 5 tweets containing the hashtag #Python."
          }
        ],
        "advanced_examples": [
          {
            "title": "Saving tweets to CSV",
            "code": "import snscrape.modules.twitter as sntwitter\nimport pandas as pd\n\ntweets = []\nfor i, tweet in enumerate(sntwitter.TwitterSearchScraper('Python since:2025-01-01 until:2025-01-31').get_items()):\n    if i > 50:\n        break\n    tweets.append([tweet.date, tweet.user.username, tweet.content])\ndf = pd.DataFrame(tweets, columns=['Date','User','Content'])\ndf.to_csv('tweets.csv', index=False)",
            "explanation": "Scrapes up to 50 tweets containing 'Python' in January 2025 and saves them to a CSV file."
          },
          {
            "title": "Scraping Reddit posts",
            "code": "import snscrape.modules.reddit as snreddit\n\nfor post in snreddit.RedditSearchScraper('Python').get_items():\n    print(post.title, post.url)",
            "explanation": "Scrapes Reddit posts containing the keyword 'Python' and prints the post titles and URLs."
          },
          {
            "title": "Filtering by date range",
            "code": "import snscrape.modules.twitter as sntwitter\n\nfor tweet in sntwitter.TwitterSearchScraper('Python since:2025-08-01 until:2025-08-21').get_items():\n    print(tweet.date, tweet.content)",
            "explanation": "Scrapes tweets containing 'Python' posted between 1st and 21st August 2025."
          }
        ],
        "best_practices": [
          "Limit the number of items to scrape to avoid excessive requests.",
          "Use pandas DataFrame or CSV to store and analyze scraped data efficiently.",
          "Be mindful of platform usage terms to avoid scraping sensitive or restricted data.",
          "Combine with Python date filters to scrape relevant time periods.",
          "Use try/except to handle exceptions and network issues."
        ],
        "error_handling": [
          {
            "error": "HTTPError / ConnectionError",
            "solution": "Check network connectivity or retry after a short delay."
          },
          {
            "error": "ValueError: invalid query",
            "solution": "Ensure the search query syntax matches the scraper's supported format."
          }
        ]
      },
      "references": {
        "official_docs": "https://snscrape.readthedocs.io/",
        "github": "https://github.com/JustAnotherArchivist/snscrape"
      }
    },
    {
      "id": "social-post-api",
      "name": "Social Post API",
      "category": "Web",
      "description": "Social Post API is a Python library for interacting with various social media platforms to post updates, retrieve feeds, and manage user content programmatically. It provides a unified interface to handle multiple platforms like Twitter, Facebook, LinkedIn, and Instagram.",
      "story": "Social Post API was created to simplify the process of posting and managing social media content without needing to manually interact with platform-specific APIs. It is particularly useful for automation, social media management, and analytics applications.",
      "installation": {
        "pip": "pip install social-post-api",
        "conda": "conda install -c conda-forge social-post-api"
      },
      "usage": {
        "overview": "Social Post API provides functions to authenticate users, post content, retrieve feeds, and schedule posts. It abstracts platform-specific details into a unified API for ease of use.",
        "basic_examples": [
          {
            "title": "Posting a tweet",
            "code": "from social_post_api import SocialClient\nclient = SocialClient(platform='twitter', api_key='YOUR_API_KEY')\nclient.post('Hello World from Social Post API!')",
            "explanation": "Authenticates to Twitter using an API key and posts a simple tweet."
          },
          {
            "title": "Fetching recent posts",
            "code": "posts = client.get_recent_posts(user='example_user', limit=5)\nfor post in posts:\n    print(post.content, post.date)",
            "explanation": "Fetches the 5 most recent posts from a user and prints the content and date."
          }
        ],
        "advanced_examples": [
          {
            "title": "Scheduling posts",
            "code": "from datetime import datetime, timedelta\nschedule_time = datetime.now() + timedelta(hours=1)\nclient.schedule_post('Scheduled post', schedule_time)",
            "explanation": "Schedules a post to be published one hour from the current time."
          },
          {
            "title": "Posting to multiple platforms",
            "code": "clients = [\n    SocialClient(platform='twitter', api_key='TWITTER_KEY'),\n    SocialClient(platform='linkedin', api_key='LINKEDIN_KEY')\n]\nfor c in clients:\n    c.post('Hello social media!')",
            "explanation": "Posts the same message to multiple social media platforms using separate client instances."
          },
          {
            "title": "Handling media attachments",
            "code": "client.post('Check out this image!', media='image.jpg')",
            "explanation": "Posts content along with a media attachment, such as an image or video."
          }
        ],
        "best_practices": [
          "Use environment variables to store API keys and secrets securely.",
          "Respect platform rate limits to avoid temporary bans.",
          "Use try/except blocks to handle network or API errors gracefully.",
          "Cache authentication tokens when possible for efficiency.",
          "Test posts on sandbox or development accounts before posting to live accounts."
        ],
        "error_handling": [
          {
            "error": "AuthenticationError",
            "solution": "Verify API keys, tokens, and permissions for the respective platform."
          },
          {
            "error": "RateLimitError",
            "solution": "Wait for the specified cooldown period or reduce the number of API calls."
          },
          {
            "error": "NetworkError",
            "solution": "Check your internet connection and retry requests as necessary."
          }
        ]
      },
      "references": {
        "official_docs": "https://social-post-api.readthedocs.io/",
        "github": "https://github.com/example/social-post-api"
      }
    },
    {
      "id": "tweepy",
      "name": "Tweepy",
      "category": "Web",
      "description": "Tweepy is a Python library for accessing the Twitter API easily. It provides a convenient interface to retrieve tweets, post updates, manage followers, and interact with Twitter data programmatically.",
      "story": "Tweepy was created by Joshua Roesslein in 2009 to simplify interaction with the Twitter API. It abstracts authentication, request handling, and rate limits, enabling developers to focus on building applications and collecting social media data without dealing with raw HTTP requests.",
      "installation": {
        "pip": "pip install tweepy",
        "conda": "conda install -c conda-forge tweepy"
      },
      "usage": {
        "overview": "Tweepy allows you to authenticate with Twitter, access timelines, post tweets, search for tweets, follow users, and stream live data. It supports both the REST API and the streaming API with Pythonic syntax.",
        "basic_examples": [
          {
            "title": "Authentication with API keys",
            "code": "import tweepy\n\nconsumer_key = 'YOUR_CONSUMER_KEY'\nconsumer_secret = 'YOUR_CONSUMER_SECRET'\naccess_token = 'YOUR_ACCESS_TOKEN'\naccess_token_secret = 'YOUR_ACCESS_TOKEN_SECRET'\n\nauth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)\napi = tweepy.API(auth)\nprint('Authentication successful')",
            "explanation": "Shows how to authenticate with Twitter using API keys and access tokens."
          },
          {
            "title": "Posting a tweet",
            "code": "api.update_status('Hello Tweepy!')",
            "explanation": "Posts a simple tweet to your authenticated Twitter account."
          }
        ],
        "advanced_examples": [
          {
            "title": "Fetching user timeline",
            "code": "tweets = api.user_timeline(screen_name='twitter', count=5)\nfor tweet in tweets:\n    print(tweet.text)",
            "explanation": "Retrieves the last 5 tweets from a specified user and prints their text."
          },
          {
            "title": "Searching tweets",
            "code": "for tweet in tweepy.Cursor(api.search_tweets, q='Python', lang='en').items(10):\n    print(tweet.created_at, tweet.text)",
            "explanation": "Searches for 10 recent English tweets containing the keyword 'Python'."
          },
          {
            "title": "Streaming live tweets",
            "code": "class MyStream(tweepy.Stream):\n    def on_status(self, status):\n        print(status.text)\n\nstream = MyStream(consumer_key, consumer_secret, access_token, access_token_secret)\nstream.filter(track=['Python'], languages=['en'])",
            "explanation": "Streams live tweets containing the word 'Python' in English and prints them as they arrive."
          },
          {
            "title": "Following a user",
            "code": "api.create_friendship(screen_name='twitter')",
            "explanation": "Follows a specified Twitter user."
          },
          {
            "title": "Handling rate limits",
            "code": "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)",
            "explanation": "Automatically waits and notifies when hitting Twitter API rate limits to prevent exceptions."
          }
        ],
        "best_practices": [
          "Keep API keys and access tokens secure using environment variables.",
          "Use cursors for paginated endpoints to handle large datasets efficiently.",
          "Handle exceptions for rate limits and network errors gracefully.",
          "Use streaming API for real-time tweet collection and REST API for historical data.",
          "Respect Twitter’s terms of service and rate limits to avoid suspension."
        ],
        "error_handling": [
          {
            "error": "tweepy.errors.TweepyException",
            "solution": "Catch general exceptions related to Twitter API requests."
          },
          {
            "error": "tweepy.errors.RateLimitError",
            "solution": "Wait until rate limits reset or use the `wait_on_rate_limit` parameter."
          },
          {
            "error": "tweepy.errors.Unauthorized",
            "solution": "Check that your API keys, access tokens, and permissions are correct."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.tweepy.org/en/stable/",
        "github": "https://github.com/tweepy/tweepy"
      }
    },
    {
      "id": "python-twitter",
      "name": "python-twitter",
      "category": "Web",
      "description": "python-twitter is a Python wrapper around the Twitter API, providing a simple interface to access Twitter data, post tweets, and manage accounts programmatically.",
      "story": "python-twitter was created to simplify interaction with the Twitter API for Python developers. It abstracts API authentication, rate limits, and request handling, enabling developers to focus on building applications that interact with Twitter.",
      "installation": {
        "pip": "pip install python-twitter",
        "conda": "conda install -c conda-forge python-twitter"
      },
      "usage": {
        "overview": "python-twitter allows you to authenticate with Twitter using API credentials, read timelines, search tweets, post updates, manage followers, and interact with Twitter accounts via Python.",
        "basic_examples": [
          {
            "title": "Authentication with API keys",
            "code": "import twitter\napi = twitter.Api(consumer_key='YOUR_CONSUMER_KEY',\n                  consumer_secret='YOUR_CONSUMER_SECRET',\n                  access_token_key='YOUR_ACCESS_TOKEN',\n                  access_token_secret='YOUR_ACCESS_TOKEN_SECRET')\nprint(api.VerifyCredentials())",
            "explanation": "Authenticates with Twitter using API credentials and verifies the account."
          },
          {
            "title": "Posting a tweet",
            "code": "status = api.PostUpdate('Hello Twitter!')\nprint(status.text)",
            "explanation": "Posts a tweet with the text 'Hello Twitter!' from the authenticated account."
          }
        ],
        "advanced_examples": [
          {
            "title": "Reading the home timeline",
            "code": "timeline = api.GetHomeTimeline(count=5)\nfor tweet in timeline:\n    print(tweet.user.name, tweet.text)",
            "explanation": "Fetches the latest 5 tweets from the authenticated user's home timeline."
          },
          {
            "title": "Searching tweets",
            "code": "search_results = api.GetSearch(term='Python', count=10)\nfor tweet in search_results:\n    print(tweet.user.screen_name, tweet.text)",
            "explanation": "Searches for 10 recent tweets containing the keyword 'Python'."
          },
          {
            "title": "Retrieving user timeline",
            "code": "user_timeline = api.GetUserTimeline(screen_name='twitter', count=5)\nfor tweet in user_timeline:\n    print(tweet.text)",
            "explanation": "Retrieves the last 5 tweets from a specified user's timeline."
          },
          {
            "title": "Getting followers",
            "code": "followers = api.GetFollowers(screen_name='twitter')\nfor user in followers:\n    print(user.screen_name)",
            "explanation": "Fetches followers of a specific Twitter user and prints their screen names."
          },
          {
            "title": "Direct messages",
            "code": "dms = api.GetDirectMessages(count=5)\nfor dm in dms:\n    print(dm.sender.screen_name, dm.text)",
            "explanation": "Retrieves the latest 5 direct messages received by the authenticated account."
          }
        ],
        "best_practices": [
          "Keep API keys and tokens secure using environment variables.",
          "Use Python-twitter’s built-in methods for pagination to handle large datasets.",
          "Respect Twitter rate limits to prevent temporary bans.",
          "Use try/except blocks to handle network or API errors gracefully.",
          "Test code on development or test accounts before posting to live accounts."
        ],
        "error_handling": [
          {
            "error": "twitter.TwitterError",
            "solution": "Catch exceptions for failed API requests and inspect the error message for troubleshooting."
          },
          {
            "error": "HTTPError",
            "solution": "Ensure network connectivity and correct endpoint usage."
          },
          {
            "error": "RateLimitError",
            "solution": "Wait until rate limits reset or reduce API request frequency."
          }
        ]
      },
      "references": {
        "official_docs": "https://python-twitter.readthedocs.io/",
        "github": "https://github.com/bear/python-twitter"
      }
    },
    {
      "id": "instaloader",
      "name": "Instaloader",
      "category": "Web",
      "description": "Instaloader is a Python library to download Instagram photos, videos, stories, IGTV, and profiles. It allows you to scrape Instagram content programmatically for personal or research purposes.",
      "story": "Instaloader was created by Thilo Planz to provide a simple and efficient tool for downloading content from Instagram without using the official API. It handles login, private profiles, hashtags, and profiles with ease, and can save metadata like captions, likes, and comments.",
      "installation": {
        "pip": "pip install instaloader",
        "conda": "conda install -c conda-forge instaloader"
      },
      "usage": {
        "overview": "Instaloader can download posts, stories, profiles, or hashtags using Python scripts or command-line interface. It supports login for private profiles, filtering by date, and storing metadata in JSON files.",
        "basic_examples": [
          {
            "title": "Download a profile",
            "code": "import instaloader\nL = instaloader.Instaloader()\nL.download_profile('instagram_username', profile_pic=True)",
            "explanation": "Downloads all posts and profile picture of the specified Instagram user."
          },
          {
            "title": "Download stories",
            "code": "import instaloader\nL = instaloader.Instaloader()\nL.download_stories(userids=['instagram_user_id'])",
            "explanation": "Downloads active stories for the specified user IDs."
          }
        ],
        "advanced_examples": [
          {
            "title": "Login and download private profile",
            "code": "import instaloader\nL = instaloader.Instaloader()\nL.login('your_username', 'your_password')\nL.download_profile('private_user', profile_pic=True)",
            "explanation": "Logs in with your credentials to download posts from a private account you follow."
          },
          {
            "title": "Download posts by hashtag",
            "code": "import instaloader\nL = instaloader.Instaloader()\nfor post in instaloader.Hashtag.from_name(L.context, 'python').get_posts():\n    L.download_post(post, target='#python')",
            "explanation": "Downloads all posts tagged with #python into a folder named '#python'."
          },
          {
            "title": "Save metadata",
            "code": "import instaloader\nL = instaloader.Instaloader(download_comments=False, save_metadata=True)\nL.download_profile('instagram_username')",
            "explanation": "Saves JSON metadata for each post, including captions, likes, and comments."
          },
          {
            "title": "Filter posts by date",
            "code": "import instaloader\nimport datetime\nL = instaloader.Instaloader()\nPROFILE = instaloader.Profile.from_username(L.context, 'instagram_username')\nfor post in PROFILE.get_posts():\n    if post.date > datetime.datetime(2025,1,1):\n        L.download_post(post, target=PROFILE.username)",
            "explanation": "Downloads posts from the profile after January 1, 2025."
          }
        ],
        "best_practices": [
          "Respect Instagram’s terms of service and avoid excessive scraping.",
          "Use login for private content responsibly and only for accounts you have access to.",
          "Handle exceptions for network issues or blocked content.",
          "Save metadata and use structured directories for organization.",
          "Rate-limit requests to avoid temporary bans or throttling."
        ],
        "error_handling": [
          {
            "error": "instaloader.exceptions.LoginRequiredException",
            "solution": "Login using L.login('username', 'password') to access private content."
          },
          {
            "error": "instaloader.exceptions.ProfileNotExistsException",
            "solution": "Verify that the Instagram username exists and is spelled correctly."
          },
          {
            "error": "instaloader.exceptions.ConnectionException",
            "solution": "Check network connectivity and Instagram server availability."
          }
        ]
      },
      "references": {
        "official_docs": "https://instaloader.github.io/",
        "github": "https://github.com/instaloader/instaloader"
      }
    },
    {
      "id": "instagrapi",
      "name": "Instagrapi",
      "category": "Web",
      "description": "Instagrapi is a modern Python library for Instagram automation. It allows you to programmatically interact with Instagram, including posting photos and stories, managing followers, reading feeds, and downloading media.",
      "story": "Instagrapi was created to provide an easy-to-use and fast Python interface for Instagram automation. Unlike the official Instagram API, Instagrapi is lightweight, does not require app registration, and supports a wide range of Instagram features, making it popular among developers for personal projects, analytics, and social media automation.",
      "installation": {
        "pip": "pip install instagrapi",
        "conda": "conda install -c conda-forge instagrapi"
      },
      "usage": {
        "overview": "Instagrapi provides methods for logging in, uploading media, interacting with followers, downloading stories, and analyzing Instagram data. It supports both personal and business accounts and includes features for handling reels, IGTV, and metadata.",
        "basic_examples": [
          {
            "title": "Login to Instagram",
            "code": "from instagrapi import Client\nclient = Client()\nclient.login('your_username', 'your_password')",
            "explanation": "Authenticates your Instagram account using username and password."
          },
          {
            "title": "Get user followers",
            "code": "followers = client.user_followers('user_id')\nfor uid, user in followers.items():\n    print(user.username)",
            "explanation": "Retrieves and prints the list of followers for a specific user ID."
          },
          {
            "title": "Upload a photo",
            "code": "client.photo_upload('image.jpg', 'Caption for the photo')",
            "explanation": "Uploads a photo to your Instagram account with the specified caption."
          }
        ],
        "advanced_examples": [
          {
            "title": "Download stories",
            "code": "stories = client.user_stories('user_id')\nfor story in stories:\n    client.story_download(story.pk, f'{story.pk}.jpg')",
            "explanation": "Downloads all active stories for a user and saves them locally."
          },
          {
            "title": "Post a story",
            "code": "client.photo_story('story_image.jpg', 'Story caption')",
            "explanation": "Uploads a photo as a story to your Instagram account."
          },
          {
            "title": "Get user feed",
            "code": "medias = client.user_medias('user_id', 10)\nfor media in medias:\n    print(media.caption_text)",
            "explanation": "Retrieves the latest 10 posts from a user and prints the captions."
          },
          {
            "title": "Follow a user",
            "code": "client.user_follow('user_id')",
            "explanation": "Follows the specified user by user ID."
          },
          {
            "title": "Unfollow a user",
            "code": "client.user_unfollow('user_id')",
            "explanation": "Unfollows the specified user by user ID."
          }
        ],
        "best_practices": [
          "Use environment variables to store login credentials securely.",
          "Respect Instagram’s terms of service and avoid aggressive automation.",
          "Use try/except to handle network errors and account restrictions.",
          "Rate-limit requests to prevent temporary account blocks.",
          "Keep session files to maintain login and reduce repeated authentication."
        ],
        "error_handling": [
          {
            "error": "ClientLoginRequired",
            "solution": "Ensure you are logged in before making requests or refresh the session."
          },
          {
            "error": "RateLimitError",
            "solution": "Avoid sending too many requests in a short period; implement delays."
          },
          {
            "error": "MediaNotFound",
            "solution": "Verify the media ID exists and is accessible for the logged-in account."
          }
        ]
      },
      "references": {
        "official_docs": "https://adw0rd.github.io/instagrapi/",
        "github": "https://github.com/adw0rd/instagrapi"
      }
    },
    {
      "id": "facebook-sdk",
      "name": "Facebook SDK for Python",
      "category": "Web",
      "description": "The Facebook SDK for Python is a library that allows developers to interact with the Facebook Graph API. It provides tools for posting content, retrieving user data, managing pages, and working with Facebook Ads programmatically.",
      "story": "The Facebook SDK for Python was developed to make it easier for Python developers to integrate Facebook services into their applications. It abstracts HTTP requests to the Graph API and handles authentication, permissions, and API responses in a Pythonic way, enabling social media integrations, analytics, and automation tasks.",
      "installation": {
        "pip": "pip install facebook-sdk",
        "conda": "conda install -c conda-forge facebook-sdk"
      },
      "usage": {
        "overview": "The SDK allows you to authenticate with Facebook, send requests to the Graph API, post to pages or timelines, read user or page data, and handle responses. It supports OAuth 2.0 authentication and can be used for apps, bots, or analytics.",
        "basic_examples": [
          {
            "title": "Initializing the Graph API client",
            "code": "import facebook\naccess_token = 'YOUR_ACCESS_TOKEN'\ngraph = facebook.GraphAPI(access_token=access_token, version='3.1')",
            "explanation": "Creates a GraphAPI client instance using your access token to authenticate requests."
          },
          {
            "title": "Fetching user profile",
            "code": "profile = graph.get_object('me')\nprint(profile)",
            "explanation": "Retrieves the authenticated user's profile information from Facebook."
          },
          {
            "title": "Posting a status update",
            "code": "graph.put_object(parent_object='me', connection_name='feed', message='Hello Facebook!')",
            "explanation": "Posts a simple status message to the authenticated user's timeline."
          }
        ],
        "advanced_examples": [
          {
            "title": "Posting a photo",
            "code": "graph.put_photo(image=open('photo.jpg', 'rb'), message='Check out this photo!')",
            "explanation": "Uploads an image to the authenticated user's timeline with a caption."
          },
          {
            "title": "Reading page feed",
            "code": "page_feed = graph.get_connections('your_page_id', 'feed')\nfor post in page_feed['data']:\n    print(post['message'])",
            "explanation": "Retrieves posts from a Facebook page's feed and prints their messages."
          },
          {
            "title": "Handling paginated results",
            "code": "feed = graph.get_connections('me', 'feed')\nwhile True:\n    for post in feed['data']:\n        print(post['message'])\n    if 'next' in feed.get('paging', {}):\n        feed = requests.get(feed['paging']['next']).json()\n    else:\n        break",
            "explanation": "Iterates through paginated results to process all items in a feed."
          },
          {
            "title": "Deleting a post",
            "code": "graph.delete_object('post_id')",
            "explanation": "Deletes a specific post by its ID."
          },
          {
            "title": "Using app secret proof for security",
            "code": "import hmac, hashlib\napp_secret = 'YOUR_APP_SECRET'\nappsecret_proof = hmac.new(app_secret.encode('utf-8'), access_token.encode('utf-8'), hashlib.sha256).hexdigest()\ngraph.get_object('me', appsecret_proof=appsecret_proof)",
            "explanation": "Adds an extra layer of security when making API calls by using appsecret_proof."
          }
        ],
        "best_practices": [
          "Use long-lived access tokens for server-side applications.",
          "Handle API rate limits gracefully and implement retries.",
          "Use proper permissions scopes to access the data needed.",
          "Keep your app secret and access tokens secure using environment variables.",
          "Validate all responses and handle exceptions to prevent runtime errors."
        ],
        "error_handling": [
          {
            "error": "facebook.GraphAPIError",
            "solution": "Catch exceptions raised by the Graph API client and inspect error messages and codes."
          },
          {
            "error": "OAuthException",
            "solution": "Occurs when access token is invalid or expired. Refresh tokens or obtain a new access token."
          },
          {
            "error": "HTTPError",
            "solution": "Check network connectivity and verify API endpoint URLs."
          }
        ]
      },
      "references": {
        "official_docs": "https://facebook-sdk.readthedocs.io/",
        "github": "https://github.com/mobolic/facebook-sdk"
      }
    },
    {
      "id": "pyfacebook",
      "name": "PyFacebook",
      "category": "Web",
      "description": "PyFacebook is a Python SDK for interacting with the Facebook Graph API. It allows developers to manage Facebook pages, post content, retrieve insights, and handle user and page data programmatically.",
      "story": "PyFacebook was created to simplify working with the Facebook Graph API in Python. It abstracts the complexities of HTTP requests, authentication, and response handling, enabling developers to build social media management tools, analytics applications, and automation scripts with ease.",
      "installation": {
        "pip": "pip install pyfacebook",
        "conda": "conda install -c conda-forge pyfacebook"
      },
      "usage": {
        "overview": "PyFacebook allows you to authenticate with Facebook, send requests to the Graph API, manage pages, retrieve posts, comments, insights, and more. It supports both user and page access tokens and provides Pythonic interfaces for various endpoints.",
        "basic_examples": [
          {
            "title": "Initializing the client",
            "code": "from pyfacebook import GraphAPI\napi = GraphAPI(app_id='YOUR_APP_ID', app_secret='YOUR_APP_SECRET', short_token='USER_ACCESS_TOKEN')",
            "explanation": "Creates a PyFacebook client instance using your app credentials and a user access token."
          },
          {
            "title": "Getting user profile",
            "code": "profile = api.get_user('me')\nprint(profile)",
            "explanation": "Retrieves the authenticated user's profile information."
          },
          {
            "title": "Posting to a page",
            "code": "api.post_page_feed(page_id='PAGE_ID', message='Hello from PyFacebook!')",
            "explanation": "Posts a message to a Facebook page using a page access token."
          }
        ],
        "advanced_examples": [
          {
            "title": "Retrieving page insights",
            "code": "insights = api.get_page_insights(page_id='PAGE_ID', metric=['page_impressions','page_engaged_users'])\nprint(insights)",
            "explanation": "Fetches analytics data (like impressions and engagement) for a specific Facebook page."
          },
          {
            "title": "Fetching comments on a post",
            "code": "comments = api.get_post_comments(post_id='POST_ID')\nfor comment in comments['data']:\n    print(comment['from']['name'], comment['message'])",
            "explanation": "Retrieves comments from a specific post and prints the author and message."
          },
          {
            "title": "Handling pagination",
            "code": "posts = api.get_page_feed(page_id='PAGE_ID')\nwhile 'paging' in posts and 'next' in posts['paging']:\n    for post in posts['data']:\n        print(post['message'])\n    posts = api.get_next_page(posts)",
            "explanation": "Iterates through all posts on a page using pagination."
          },
          {
            "title": "Updating a post",
            "code": "api.update_post(post_id='POST_ID', message='Updated message')",
            "explanation": "Updates the message of an existing post on a page."
          },
          {
            "title": "Deleting a post",
            "code": "api.delete_post(post_id='POST_ID')",
            "explanation": "Deletes a specific post from a page."
          }
        ],
        "best_practices": [
          "Keep app secrets and access tokens secure using environment variables.",
          "Use page access tokens for page management and user access tokens for user data.",
          "Handle rate limits and exceptions gracefully with try/except blocks.",
          "Paginate through results to handle large datasets efficiently.",
          "Test actions on a development page or test user before using live accounts."
        ],
        "error_handling": [
          {
            "error": "GraphAPIError",
            "solution": "Catch exceptions returned by the API and inspect error messages for troubleshooting."
          },
          {
            "error": "OAuthException",
            "solution": "Occurs when access tokens are invalid or expired. Refresh tokens or generate new ones."
          },
          {
            "error": "HTTPError",
            "solution": "Check network connectivity and API endpoint correctness."
          }
        ]
      },
      "references": {
        "official_docs": "https://pyfacebook.readthedocs.io/",
        "github": "https://github.com/sciyoshi/pyfacebook"
      }
    },
    {
      "id": "python-telegram-bot",
      "name": "python-telegram-bot",
      "category": "Web",
      "description": "python-telegram-bot is a Python library that provides a pure Python interface for the Telegram Bot API. It allows developers to build bots to interact with Telegram users, send messages, handle commands, and integrate with other services.",
      "story": "python-telegram-bot was created to simplify Telegram bot development using Python. It abstracts HTTP requests to Telegram servers, provides a convenient object-oriented interface, and supports asynchronous programming, making it one of the most popular libraries for Telegram bot development.",
      "installation": {
        "pip": "pip install python-telegram-bot --upgrade",
        "conda": "conda install -c conda-forge python-telegram-bot"
      },
      "usage": {
        "overview": "The library allows you to create bots that respond to messages, commands, and callbacks. It supports inline keyboards, custom keyboards, message formatting, handling updates, and asynchronous execution.",
        "basic_examples": [
          {
            "title": "Simple bot that replies to /start",
            "code": "from telegram import Update\nfrom telegram.ext import Updater, CommandHandler, CallbackContext\n\nTOKEN = 'YOUR_BOT_TOKEN'\n\ndef start(update: Update, context: CallbackContext):\n    update.message.reply_text('Hello! I am your bot.')\n\nupdater = Updater(TOKEN)\nupdater.dispatcher.add_handler(CommandHandler('start', start))\nupdater.start_polling()\nupdater.idle()",
            "explanation": "Creates a Telegram bot that replies 'Hello! I am your bot.' when a user sends the /start command."
          },
          {
            "title": "Sending a message to a chat",
            "code": "from telegram import Bot\nBOT_TOKEN = 'YOUR_BOT_TOKEN'\nbot = Bot(BOT_TOKEN)\nbot.send_message(chat_id=123456789, text='Hello from bot!')",
            "explanation": "Sends a message to a specific chat using the bot token."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using inline keyboards",
            "code": "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\nfrom telegram.ext import Updater, CommandHandler, CallbackQueryHandler\n\nTOKEN = 'YOUR_BOT_TOKEN'\n\ndef start(update, context):\n    keyboard = [[InlineKeyboardButton('Option 1', callback_data='1'),\n                 InlineKeyboardButton('Option 2', callback_data='2')]]\n    reply_markup = InlineKeyboardMarkup(keyboard)\n    update.message.reply_text('Choose:', reply_markup=reply_markup)\n\ndef button(update, context):\n    query = update.callback_query\n    query.answer()\n    query.edit_message_text(text=f'Selected option: {query.data}')\n\nupdater = Updater(TOKEN)\nupdater.dispatcher.add_handler(CommandHandler('start', start))\nupdater.dispatcher.add_handler(CallbackQueryHandler(button))\nupdater.start_polling()\nupdater.idle()",
            "explanation": "Creates a bot with an inline keyboard, and edits the message based on the user selection."
          },
          {
            "title": "Echo bot for text messages",
            "code": "from telegram.ext import MessageHandler, Filters\n\ndef echo(update, context):\n    update.message.reply_text(update.message.text)\n\nupdater.dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))",
            "explanation": "Replies with the same message text sent by the user, ignoring commands."
          },
          {
            "title": "Handling multiple commands",
            "code": "def help_command(update, context):\n    update.message.reply_text('This is a help message.')\n\nupdater.dispatcher.add_handler(CommandHandler('help', help_command))",
            "explanation": "Adds another command handler to respond to /help with a custom message."
          },
          {
            "title": "Asynchronous bot with asyncio",
            "code": "import asyncio\nfrom telegram import Update\nfrom telegram.ext import ApplicationBuilder, CommandHandler\n\nasync def start(update: Update, context):\n    await update.message.reply_text('Hello async bot!')\n\napp = ApplicationBuilder().token('YOUR_BOT_TOKEN').build()\napp.add_handler(CommandHandler('start', start))\nasyncio.run(app.run_polling())",
            "explanation": "Demonstrates creating an asynchronous bot using the latest ApplicationBuilder and asyncio support."
          }
        ],
        "best_practices": [
          "Store your bot token securely using environment variables.",
          "Use CommandHandlers for specific commands and MessageHandlers for general text.",
          "Keep your bot responsive by using async features for I/O-heavy tasks.",
          "Handle exceptions in handlers to prevent the bot from crashing.",
          "Use logging to monitor bot activity and errors."
        ],
        "error_handling": [
          {
            "error": "telegram.error.TelegramError",
            "solution": "Catch general exceptions for API requests and handle network or HTTP errors."
          },
          {
            "error": "telegram.error.Unauthorized",
            "solution": "Check your bot token and make sure the bot has permissions to interact with the chat."
          },
          {
            "error": "telegram.error.NetworkError",
            "solution": "Retry requests or handle transient network issues gracefully."
          }
        ]
      },
      "references": {
        "official_docs": "https://python-telegram-bot.org/",
        "github": "https://github.com/python-telegram-bot/python-telegram-bot"
      }
    },
    {
      "id": "telethon",
      "name": "Telethon",
      "category": "Web",
      "description": "Telethon is a Python library to interact with Telegram’s API as a user or bot. It allows you to send messages, manage groups, channels, and perform a wide range of Telegram actions programmatically.",
      "story": "Telethon was created by Lonami to provide a pure Python interface to the Telegram API. Unlike bot-only libraries, Telethon can log in as a real user, enabling access to features that bots cannot use. It supports both synchronous and asynchronous operations and is widely used for automation, scraping, and advanced bot functionalities.",
      "installation": {
        "pip": "pip install telethon",
        "conda": "conda install -c conda-forge telethon"
      },
      "usage": {
        "overview": "Telethon allows you to log in using API ID and hash, send and receive messages, manage chats, retrieve users and groups, and handle media. It provides both synchronous and asynchronous clients, supports event handlers, and works with Telegram’s full API.",
        "basic_examples": [
          {
            "title": "Connecting to Telegram",
            "code": "from telethon import TelegramClient\n\napi_id = 123456\napi_hash = 'your_api_hash'\nclient = TelegramClient('session_name', api_id, api_hash)\nclient.start()",
            "explanation": "Initializes a Telethon client and starts a session. You will be prompted to enter your phone number and verification code."
          },
          {
            "title": "Sending a message",
            "code": "client.send_message('username_or_chat_id', 'Hello from Telethon!')",
            "explanation": "Sends a text message to a specified user or chat."
          },
          {
            "title": "Getting chat participants",
            "code": "participants = client.get_participants('chat_name')\nfor user in participants:\n    print(user.id, user.username)",
            "explanation": "Retrieves a list of participants from a chat and prints their IDs and usernames."
          }
        ],
        "advanced_examples": [
          {
            "title": "Asynchronous client example",
            "code": "from telethon import TelegramClient, events\n\nasync def main():\n    async with TelegramClient('session_name', api_id, api_hash) as client:\n        await client.send_message('username_or_chat_id', 'Hello async world!')\n\nimport asyncio\nasyncio.run(main())",
            "explanation": "Demonstrates sending a message using Telethon’s asynchronous client."
          },
          {
            "title": "Handling new messages with events",
            "code": "from telethon import events\n\n@client.on(events.NewMessage(pattern='hello'))\nasync def handler(event):\n    await event.reply('Hi!')\n\nclient.run_until_disconnected()",
            "explanation": "Replies 'Hi!' automatically whenever a new message containing 'hello' is received."
          },
          {
            "title": "Downloading media",
            "code": "from telethon.tl.types import InputMessagesFilterPhotos\nmessages = client.get_messages('chat_name', limit=10, filter=InputMessagesFilterPhotos)\nfor msg in messages:\n    client.download_media(msg)",
            "explanation": "Downloads the last 10 photo messages from a chat."
          },
          {
            "title": "Iterating through dialogs",
            "code": "for dialog in client.iter_dialogs():\n    print(dialog.name, dialog.id)",
            "explanation": "Lists all dialogs (chats, groups, channels) accessible to the user."
          },
          {
            "title": "Forwarding messages",
            "code": "client.forward_messages('target_chat', messages=12345, from_peer='source_chat')",
            "explanation": "Forwards a message with ID 12345 from a source chat to a target chat."
          }
        ],
        "best_practices": [
          "Store your API ID and hash securely using environment variables.",
          "Use Telethon’s asynchronous client for IO-heavy tasks to improve performance.",
          "Handle session files carefully to avoid repeated login prompts.",
          "Respect Telegram's terms of service and avoid sending spam messages.",
          "Use event handlers for reactive automation instead of polling."
        ],
        "error_handling": [
          {
            "error": "telethon.errors.SessionPasswordNeededError",
            "solution": "Occurs when two-factor authentication is enabled. Provide your 2FA password to continue."
          },
          {
            "error": "telethon.errors.FloodWaitError",
            "solution": "Occurs when performing too many requests. Wait for the specified duration before retrying."
          },
          {
            "error": "telethon.errors.RPCError",
            "solution": "Handle specific RPC errors like PeerIdInvalid or UserIsBlocked based on the error code."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.telethon.dev/",
        "github": "https://github.com/LonamiWebs/Telethon"
      }
    },
    {
      "id": "aiogram",
      "name": "Aiogram",
      "category": "Web",
      "description": "Aiogram is a modern and fully asynchronous Python framework for building Telegram bots. It leverages Python’s asyncio capabilities to provide high-performance, scalable, and efficient bot development.",
      "story": "Aiogram was created to provide developers with a fast, asynchronous, and type-annotated framework for building Telegram bots. It focuses on simplicity, performance, and the latest Python features, making it ideal for both small and large-scale bot projects.",
      "installation": {
        "pip": "pip install aiogram",
        "conda": "conda install -c conda-forge aiogram"
      },
      "usage": {
        "overview": "Aiogram allows you to create Telegram bots that handle messages, commands, inline queries, callback queries, and more. It supports middlewares, FSM (Finite State Machines) for complex conversations, and robust error handling.",
        "basic_examples": [
          {
            "title": "Simple bot responding to /start",
            "code": "from aiogram import Bot, Dispatcher, types\nfrom aiogram.utils import executor\n\nTOKEN = 'YOUR_BOT_TOKEN'\nbot = Bot(token=TOKEN)\ndp = Dispatcher(bot)\n\n@dp.message_handler(commands=['start'])\nasync def start_handler(message: types.Message):\n    await message.reply('Hello! I am your Aiogram bot.')\n\nif __name__ == '__main__':\n    executor.start_polling(dp, skip_updates=True)",
            "explanation": "Creates a bot that responds with a greeting when a user sends the /start command."
          },
          {
            "title": "Sending a message",
            "code": "await bot.send_message(chat_id=123456789, text='Hello from Aiogram!')",
            "explanation": "Sends a message to a specific chat using the bot instance."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using inline keyboards",
            "code": "from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup\nkeyboard = InlineKeyboardMarkup()\nkeyboard.add(InlineKeyboardButton('Click me', callback_data='button_click'))\nawait message.reply('Choose an option:', reply_markup=keyboard)",
            "explanation": "Adds an inline keyboard to a message and handles user interactions via callback data."
          },
          {
            "title": "Handling callback queries",
            "code": "@dp.callback_query_handler(lambda c: c.data == 'button_click')\nasync def process_callback(callback_query: types.CallbackQuery):\n    await bot.answer_callback_query(callback_query.id)\n    await bot.send_message(callback_query.from_user.id, 'Button clicked!')",
            "explanation": "Processes user clicks on inline buttons and sends a response message."
          },
          {
            "title": "Finite State Machine example",
            "code": "from aiogram.dispatcher.filters.state import State, StatesGroup\nfrom aiogram.contrib.fsm_storage.memory import MemoryStorage\nstorage = MemoryStorage()\n\nclass Form(StatesGroup):\n    name = State()\n    age = State()",
            "explanation": "Defines states for managing multi-step conversations in a Telegram bot using FSM."
          },
          {
            "title": "Middleware usage",
            "code": "from aiogram.dispatcher.middlewares import BaseMiddleware\n\nclass LoggingMiddleware(BaseMiddleware):\n    async def on_pre_process_message(self, message, data):\n        print(f'Received message: {message.text}')",
            "explanation": "Demonstrates how to create a middleware to log messages before processing."
          },
          {
            "title": "Error handling",
            "code": "from aiogram.utils.exceptions import BotBlocked\ntry:\n    await bot.send_message(user_id, 'Hello!')\nexcept BotBlocked:\n    print('Bot was blocked by the user')",
            "explanation": "Handles exceptions like when the bot is blocked by a user."
          }
        ],
        "best_practices": [
          "Use FSM for multi-step conversations to maintain state cleanly.",
          "Leverage middlewares for logging, validation, and preprocessing messages.",
          "Handle exceptions for blocked users or network errors.",
          "Keep the bot fully asynchronous to maximize performance.",
          "Use proper token and environment variable management for security."
        ],
        "error_handling": [
          {
            "error": "BotBlocked",
            "solution": "Occurs when a user blocks the bot. Handle gracefully and log the incident."
          },
          {
            "error": "RetryAfter",
            "solution": "Occurs when hitting Telegram’s rate limits. Implement retry mechanisms or delays."
          },
          {
            "error": "NetworkError",
            "solution": "Retry the request and handle transient network issues appropriately."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.aiogram.dev/en/latest/",
        "github": "https://github.com/aiogram/aiogram"
      }
    },
    {
      "id": "discord-py",
      "name": "discord.py",
      "category": "Web",
      "description": "discord.py is a Python library for interacting with the Discord API. It allows developers to create bots that can interact with Discord servers, send and receive messages, manage roles, and respond to events programmatically.",
      "story": "discord.py was created by Rapptz to provide a Pythonic interface to the Discord API. It abstracts HTTP requests and WebSocket connections, allowing developers to focus on bot logic and automation. It supports both synchronous and asynchronous programming, enabling scalable and responsive bots.",
      "installation": {
        "pip": "pip install discord.py",
        "conda": "conda install -c conda-forge discord.py"
      },
      "usage": {
        "overview": "The library allows you to create bots that respond to messages, commands, reactions, and events. It supports creating commands with decorators, listening to events, handling permissions, and integrating with Discord servers seamlessly.",
        "basic_examples": [
          {
            "title": "Simple bot responding to messages",
            "code": "import discord\nfrom discord.ext import commands\n\nTOKEN = 'YOUR_BOT_TOKEN'\nbot = commands.Bot(command_prefix='!')\n\n@bot.event\nasync def on_ready():\n    print(f'Logged in as {bot.user}')\n\n@bot.command()\nasync def hello(ctx):\n    await ctx.send('Hello! I am your bot.')\n\nbot.run(TOKEN)",
            "explanation": "Creates a bot that responds to the command `!hello` with a greeting message."
          },
          {
            "title": "Sending a message to a channel",
            "code": "channel = bot.get_channel(CHANNEL_ID)\nawait channel.send('Hello, Discord!')",
            "explanation": "Sends a message to a specific channel using the bot instance."
          }
        ],
        "advanced_examples": [
          {
            "title": "Handling reactions",
            "code": "@bot.event\nasync def on_reaction_add(reaction, user):\n    if user != bot.user:\n        await reaction.message.channel.send(f'{user} reacted with {reaction.emoji}')",
            "explanation": "Replies with the reaction added by users, ignoring the bot’s own reactions."
          },
          {
            "title": "Creating embeds",
            "code": "from discord import Embed\nembed = Embed(title='Sample Embed', description='This is an embed', color=0x00ff00)\nawait ctx.send(embed=embed)",
            "explanation": "Creates a rich embedded message with title, description, and color."
          },
          {
            "title": "Listening to events",
            "code": "@bot.event\nasync def on_member_join(member):\n    await member.send('Welcome to the server!')",
            "explanation": "Sends a private welcome message to users when they join the server."
          },
          {
            "title": "Cog example for modular commands",
            "code": "from discord.ext import commands\n\nclass MyCog(commands.Cog):\n    def __init__(self, bot):\n        self.bot = bot\n\n    @commands.command()\n    async def ping(self, ctx):\n        await ctx.send('Pong!')\n\nbot.add_cog(MyCog(bot))",
            "explanation": "Organizes bot commands in a class (Cog) for modularity and clean code structure."
          },
          {
            "title": "Using asynchronous tasks",
            "code": "import asyncio\n\n@bot.event\nasync def on_ready():\n    while True:\n        print('Bot is running')\n        await asyncio.sleep(60)",
            "explanation": "Runs a repeating asynchronous task every 60 seconds when the bot is ready."
          }
        ],
        "best_practices": [
          "Use cogs to organize commands and events for larger bots.",
          "Handle exceptions in events and commands to prevent bot crashes.",
          "Use asynchronous programming to avoid blocking operations.",
          "Keep bot tokens secure using environment variables.",
          "Respect Discord rate limits to avoid being banned."
        ],
        "error_handling": [
          {
            "error": "discord.errors.LoginFailure",
            "solution": "Check that your bot token is correct and valid."
          },
          {
            "error": "discord.errors.Forbidden",
            "solution": "Ensure the bot has the necessary permissions to perform the action."
          },
          {
            "error": "discord.errors.HTTPException",
            "solution": "Handle network errors, invalid requests, or API limitations."
          }
        ]
      },
      "references": {
        "official_docs": "https://discordpy.readthedocs.io/",
        "github": "https://github.com/Rapptz/discord.py"
      }
    },
    {
      "id": "pycord",
      "name": "Pycord",
      "category": "Web",
      "description": "Pycord is a Python library for building Discord bots, providing an easy-to-use interface for interacting with Discord’s API. It allows developers to handle events, send messages, create commands, manage servers, and automate workflows within Discord.",
      "story": "Pycord was created as a community-maintained fork of discord.py to continue its development after discord.py became inactive for some time. It focuses on stability, ease of use, and compatibility with modern Python features, making it a popular choice for creating Discord bots.",
      "installation": {
        "pip": "pip install py-cord",
        "conda": "conda install -c conda-forge py-cord"
      },
      "usage": {
        "overview": "Pycord allows you to define bot commands, listen to events, manage servers and channels, interact with users, and build complex automation for Discord servers. It supports both synchronous and asynchronous programming.",
        "basic_examples": [
          {
            "title": "Simple bot responding to /hello",
            "code": "import discord\nfrom discord.ext import commands\n\nbot = commands.Bot(command_prefix='!')\n\n@bot.event\nasync def on_ready():\n    print(f'Logged in as {bot.user}')\n\n@bot.command()\nasync def hello(ctx):\n    await ctx.send('Hello! I am your Pycord bot.')\n\nbot.run('YOUR_BOT_TOKEN')",
            "explanation": "Creates a bot that responds with a greeting when the user sends the !hello command."
          },
          {
            "title": "Sending a direct message",
            "code": "user = await bot.fetch_user(USER_ID)\nawait user.send('Hello! This is a DM.')",
            "explanation": "Sends a private message to a specific user by their ID."
          }
        ],
        "advanced_examples": [
          {
            "title": "Using slash commands",
            "code": "from discord import Option\n\n@bot.slash_command(name='greet', description='Greet someone')\nasync def greet(ctx, name: Option(str, 'Enter a name')):\n    await ctx.respond(f'Hello {name}!')",
            "explanation": "Defines a slash command /greet with an input option 'name' that responds with a greeting."
          },
          {
            "title": "Handling reactions",
            "code": "@bot.event\nasync def on_reaction_add(reaction, user):\n    if user != bot.user:\n        await reaction.message.channel.send(f'{user.name} reacted with {reaction.emoji}')",
            "explanation": "Replies in the channel whenever a user reacts to a message."
          },
          {
            "title": "Embeds and rich messages",
            "code": "from discord import Embed\nembed = Embed(title='Sample Embed', description='This is an embed', color=0x00ff00)\nawait ctx.send(embed=embed)",
            "explanation": "Sends a rich embedded message with a title, description, and color."
          },
          {
            "title": "Cog for modular commands",
            "code": "from discord.ext import commands\n\nclass MyCog(commands.Cog):\n    def __init__(self, bot):\n        self.bot = bot\n\n    @commands.command()\n    async def ping(self, ctx):\n        await ctx.send('Pong!')\n\nbot.add_cog(MyCog(bot))",
            "explanation": "Organizes bot commands into a cog (class) for modularity and cleaner code structure."
          },
          {
            "title": "Using tasks for periodic events",
            "code": "from discord.ext import tasks\n\n@tasks.loop(minutes=1)\nasync def periodic_task():\n    channel = bot.get_channel(CHANNEL_ID)\n    await channel.send('This runs every minute!')\n\nperiodic_task.start()",
            "explanation": "Executes a task every minute and sends a message to a specified channel."
          }
        ],
        "best_practices": [
          "Use cogs to organize commands and events for maintainable bot code.",
          "Leverage asynchronous functions for better performance with multiple events.",
          "Secure your bot token using environment variables.",
          "Monitor your bot and handle exceptions to prevent crashes.",
          "Follow Discord’s API rate limits to avoid bans."
        ],
        "error_handling": [
          {
            "error": "discord.errors.LoginFailure",
            "solution": "Ensure your bot token is correct and valid."
          },
          {
            "error": "discord.errors.Forbidden",
            "solution": "Check that your bot has the necessary permissions to perform the action."
          },
          {
            "error": "discord.errors.HTTPException",
            "solution": "Handle network errors, invalid requests, or rate-limiting issues gracefully."
          }
        ]
      },
      "references": {
        "official_docs": "https://docs.pycord.dev/en/stable/",
        "github": "https://github.com/Pycord-Development/pycord"
      }
    },
    {
      "id": "hikari",
      "name": "Hikari",
      "category": "Web",
      "description": "Hikari is a modern, fast, and type-safe Python library for building Discord bots. It is designed for high performance, asynchronous execution, and full support of Discord API features.",
      "story": "Hikari was created to provide a highly performant and robust framework for building Discord bots in Python. It emphasizes type safety, concurrency, and modern Python async features. Developers use Hikari for building scalable, reliable, and feature-rich Discord bots.",
      "installation": {
        "pip": "pip install hikari",
        "conda": "conda install -c conda-forge hikari"
      },
      "usage": {
        "overview": "Hikari allows you to create bots that handle events, send messages, manage channels, and interact with Discord servers. It supports asynchronous programming, event-driven architecture, and integration with other libraries for commands, interactions, and more.",
        "basic_examples": [
          {
            "title": "Creating a simple bot",
            "code": "import hikari\n\nbot = hikari.GatewayBot(token='YOUR_BOT_TOKEN')\n\n@bot.listen()\nasync def on_ready(event: hikari.ShardReadyEvent):\n    print('Bot is ready!')\n\nbot.run()",
            "explanation": "Creates a basic Hikari bot that prints a message when the bot is ready."
          },
          {
            "title": "Sending a message",
            "code": "await bot.rest.create_message(channel=CHANNEL_ID, content='Hello from Hikari!')",
            "explanation": "Sends a message to a specific channel using the bot's REST client."
          }
        ],
        "advanced_examples": [
          {
            "title": "Listening to messages",
            "code": "@bot.listen(hikari.MessageCreateEvent)\nasync def on_message(event: hikari.MessageCreateEvent):\n    if event.content == '!ping':\n        await event.message.respond('Pong!')",
            "explanation": "Listens to new messages and responds to a '!ping' command with 'Pong!'."
          },
          {
            "title": "Using commands with Lightbulb",
            "code": "import lightbulb\n\nplugin = lightbulb.Plugin('example')\n\n@plugin.command()\n@lightbulb.command('hello', 'Say hello')\n@lightbulb.implements(lightbulb.SlashCommand)\nasync def hello(ctx):\n    await ctx.respond('Hello!')\n\nbot.add_plugin(plugin)",
            "explanation": "Demonstrates creating a slash command using the Lightbulb extension for Hikari."
          },
          {
            "title": "Handling reactions",
            "code": "@bot.listen(hikari.ReactionAddEvent)\nasync def on_reaction(event: hikari.ReactionAddEvent):\n    print(f'{event.user_id} reacted with {event.emoji}')",
            "explanation": "Logs whenever a user reacts to a message."
          },
          {
            "title": "Bot presence and status",
            "code": "await bot.update_presence(activity=hikari.Activity(name='with Hikari', type=hikari.ActivityType.PLAYING))",
            "explanation": "Updates the bot's presence to show a custom activity message."
          },
          {
            "title": "Working with guild members",
            "code": "member = await bot.rest.fetch_member(guild=GUILD_ID, user=USER_ID)\nprint(member.username)",
            "explanation": "Fetches information about a specific guild member."
          }
        ],
        "best_practices": [
          "Use async/await for all I/O operations to maintain performance.",
          "Leverage Lightbulb for command management and modularity.",
          "Handle exceptions in events to prevent bot crashes.",
          "Use environment variables for bot tokens and sensitive information.",
          "Monitor rate limits and respect Discord API constraints."
        ],
        "error_handling": [
          {
            "error": "hikari.errors.UnauthorizedError",
            "solution": "Occurs if the bot token is invalid or missing permissions. Check token and bot permissions."
          },
          {
            "error": "hikari.errors.RateLimitTooLongError",
            "solution": "Occurs when hitting Discord rate limits. Implement retry mechanisms or delays."
          },
          {
            "error": "hikari.errors.NotFoundError",
            "solution": "Occurs when a resource (channel, message, user) is not found. Verify IDs and availability."
          }
        ]
      },
      "references": {
        "official_docs": "https://www.hikari-py.dev/hikari/",
        "github": "https://github.com/hikari-py/hikari"
      }
    }
  ]